#include "omni.h"

#include "audition.h"
#include "common/common.h"
#include "common/sampling.h"
#include "ggml-alloc.h"
#include "ggml-backend.h"
#include "ggml-cpu.h"
#include "gguf.h"
#include "llama.h"
#include "omni-impl.h"
#include "token2wav/token2wav-impl.h"
#include "vision.h"

#ifdef GGML_USE_CUDA
#    include "ggml-cuda.h"
#endif

#define STB_IMAGE_IMPLEMENTATION
#include "stb/stb_image.h"

#include <signal.h>

#include <algorithm>
#include <atomic>
#include <cerrno>
#include <chrono>
#include <cmath>
#include <condition_variable>
#include <cstdarg>
#include <cstdio>
#include <cstdlib>
#include <cstring>
#include <fstream>
#include <iomanip>
#include <iostream>
#include <limits>
#include <memory>
#include <mutex>
#include <queue>
#include <random>
#include <set>
#include <sstream>
#include <thread>
#include <vector>

#ifdef _WIN32
#    include <direct.h>
#    include <io.h>
#    include <process.h>
#    include <sys/stat.h>
#    include <sys/types.h>
#    include <windows.h>
// Windows compatibility macros
#    define popen   _popen
#    define pclose  _pclose
#    define unlink  _unlink
#    define stat    _stat
#    define S_IFDIR _S_IFDIR
#else
#    include <dirent.h>
#    include <sys/stat.h>
#    include <sys/time.h>
#    include <sys/types.h>
#    include <sys/wait.h>
#    include <unistd.h>
#endif

// ============================================================
// Cross-platform helper: recursive directory creation
// Replaces "mkdir -p" shell command for Windows compatibility
// ============================================================
static bool cross_platform_mkdir_p(const std::string & path) {
    if (path.empty()) {
        return false;
    }

    std::string normalized = path;
#ifdef _WIN32
    for (char & c : normalized) {
        if (c == '/') {
            c = '\\';
        }
    }
    size_t pos = 0;
    if (normalized.size() >= 2 && normalized[1] == ':') {
        pos = 2;
        if (normalized.size() > 2 && normalized[2] == '\\') {
            pos = 3;
        }
    }
    while (pos < normalized.size() && normalized[pos] == '\\') {
        pos++;
    }

    while (pos < normalized.size()) {
        pos = normalized.find('\\', pos);
        if (pos == std::string::npos) {
            pos = normalized.size();
        }
        std::string sub = normalized.substr(0, pos);
        if (!sub.empty()) {
            struct _stat info;
            if (_stat(sub.c_str(), &info) != 0) {
                if (_mkdir(sub.c_str()) != 0 && errno != EEXIST) {
                    return false;
                }
            }
        }
        if (pos < normalized.size()) {
            pos++;
        }
    }
    return true;
#else
    for (char & c : normalized) {
        if (c == '\\') {
            c = '/';
        }
    }
    size_t pos = 0;
    if (!normalized.empty() && normalized[0] == '/') {
        pos = 1;
    }
    while (pos < normalized.size()) {
        pos = normalized.find('/', pos);
        if (pos == std::string::npos) {
            pos = normalized.size();
        }
        std::string sub = normalized.substr(0, pos);
        if (!sub.empty()) {
            struct stat info;
            if (::stat(sub.c_str(), &info) != 0) {
                if (mkdir(sub.c_str(), 0755) != 0 && errno != EEXIST) {
                    return false;
                }
            }
        }
        if (pos < normalized.size()) {
            pos++;
        }
    }
    return true;
#endif
}

// å‰å‘å£°æ˜ï¼šPython Token2Wav æœåŠ¡å‡½æ•°ï¼ˆå®šä¹‰åœ¨æ–‡ä»¶åé¢ï¼‰
static bool start_python_t2w_service(struct omni_context * ctx_omni);
static void stop_python_t2w_service(struct omni_context * ctx_omni);
static bool send_python_t2w_command(struct omni_context * ctx_omni,
                                    const std::string &   cmd_json,
                                    std::string &         response);
static bool init_python_t2w_model(struct omni_context * ctx_omni, const std::string & device);
static bool set_python_t2w_ref_audio(struct omni_context * ctx_omni, const std::string & ref_audio_path);
static bool process_python_t2w_tokens(struct omni_context *        ctx_omni,
                                      const std::vector<int32_t> & tokens,
                                      bool                         last_chunk,
                                      const std::string &          output_path,
                                      double &                     inference_time_ms,
                                      double &                     audio_duration);
static bool reset_python_t2w_cache(struct omni_context * ctx_omni);

//
// Forward declarations
//
void print_with_timestamp(const char * format, ...);

// ==================== ç‰¹æ®Š Token åˆ†ç±» ====================
//
// åŒå·¥æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹ç”Ÿæˆçš„ç‰¹æ®Š token åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼š
//
// 1. çŠ¶æ€åˆ‡æ¢ Token:
//    - <|speak|>: æ¨¡å‹å†³å®šå¼€å§‹è¯´è¯
//    - <|listen|>: æ¨¡å‹å†³å®šå¼€å§‹å¬ï¼ˆåŒå·¥ï¼‰
//
// 2. Chunk ç»ˆæ­¢ Token:
//    - <|chunk_eos|>: è¯­ä¹‰ chunk ç»“æŸï¼Œä»åœ¨åŒä¸€è½®å†…
//    - <|chunk_tts_eos|>: TTS chunk ç»“æŸï¼Œè§¦å‘ TTS å¤„ç†
//
// 3. è½®æ¬¡/åºåˆ—ç»ˆæ­¢ Token:
//    - <|turn_eos|>: å½“å‰è½®æ¬¡ç»“æŸï¼Œå¯åˆ‡æ¢å› listen
//    - <|tts_eos|>: æ—§ç‰ˆ TTS ç»“æŸï¼ˆå•å·¥æ¨¡å¼ï¼‰
//    - </s>: åºåˆ—å®Œå…¨ç»“æŸ
//
// Python å‚è€ƒ (MiniCPMODuplex):
//   CHUNK_EOS_TOKEN_ID = 128261
//   CHUNK_TTS_EOS_TOKEN_ID = 128268
//   TURN_EOS_TOKEN_ID = 128260
//   LISTEN_TOKEN_ID = 128267
//   SPEAK_TOKEN_ID = 128266

enum class OmniTokenType {
    NORMAL,         // æ™®é€š token (æ–‡æœ¬ã€audio code ç­‰)
    SPEAK,          // <|speak|> - å¼€å§‹è¯´è¯
    LISTEN,         // <|listen|> - å¼€å§‹å¬ (åŒå·¥)
    CHUNK_EOS,      // <|chunk_eos|> - è¯­ä¹‰ chunk ç»“æŸ
    CHUNK_TTS_EOS,  // <|chunk_tts_eos|> - TTS chunk ç»“æŸ
    TURN_EOS,       // <|turn_eos|> - è½®æ¬¡ç»“æŸ
    TTS_EOS,        // <|tts_eos|> - æ—§ç‰ˆ TTS ç»“æŸ (å•å·¥)
    EOS             // </s> - åºåˆ—ç»“æŸ
};

// è·å– token ç±»å‹
static OmniTokenType get_token_type(struct omni_context * ctx, llama_token token) {
    if (token == ctx->special_token_speak) {
        return OmniTokenType::SPEAK;
    } else if (token == ctx->special_token_listen) {
        return OmniTokenType::LISTEN;
    } else if (token == ctx->special_token_chunk_eos) {
        return OmniTokenType::CHUNK_EOS;
    } else if (token == ctx->special_token_chunk_tts_eos) {
        return OmniTokenType::CHUNK_TTS_EOS;
    } else if (token == ctx->special_token_turn_eos) {
        return OmniTokenType::TURN_EOS;
    } else if (token == ctx->special_token_tts_eos) {
        return OmniTokenType::TTS_EOS;
    } else if (token == ctx->special_token_eos) {
        return OmniTokenType::EOS;
    }
    return OmniTokenType::NORMAL;
}

// æ£€æŸ¥æ˜¯å¦æ˜¯ä¼šè¯/è½®æ¬¡ç»“æŸ token
static bool is_end_token(struct omni_context * ctx, llama_token token) {
    OmniTokenType type = get_token_type(ctx, token);

    if (ctx->duplex_mode) {
        // åŒå·¥æ¨¡å¼:
        // [ä¿®å¤çŸ­å›å¤] ä¸å†åœ¨ chunk_eos/chunk_tts_eos å¤„ break
        // è®© LLM åœ¨ä¸€æ¬¡ stream_decode ä¸­æŒç»­ç”Ÿæˆï¼Œç›´åˆ°çœŸæ­£çš„è½®æ¬¡ç»“æŸ tokenã€‚
        // chunk_eos ä»…ç”¨äº TTS åˆ†æ®µæµå¼æ’­æ”¾ï¼Œä¸åº”ä¸­æ–­ LLM ç”Ÿæˆã€‚
        return type == OmniTokenType::LISTEN || type == OmniTokenType::TURN_EOS || type == OmniTokenType::TTS_EOS ||
               type == OmniTokenType::EOS;
    } else {
        // å•å·¥æµå¼ TTS æ¨¡å¼
        return type == OmniTokenType::TTS_EOS || type == OmniTokenType::EOS;
    }
}

// æ£€æŸ¥æ˜¯å¦æ˜¯ chunk ç»“æŸ token (ä½†ä¸æ˜¯ä¼šè¯ç»“æŸ)
static bool is_chunk_end_token(struct omni_context * ctx, llama_token token) {
    OmniTokenType type = get_token_type(ctx, token);
    return type == OmniTokenType::CHUNK_EOS || type == OmniTokenType::CHUNK_TTS_EOS;
}

// è·å– token ç±»å‹åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
static const char * get_token_type_name(OmniTokenType type) {
    switch (type) {
        case OmniTokenType::NORMAL:
            return "NORMAL";
        case OmniTokenType::SPEAK:
            return "SPEAK";
        case OmniTokenType::LISTEN:
            return "LISTEN";
        case OmniTokenType::CHUNK_EOS:
            return "CHUNK_EOS";
        case OmniTokenType::CHUNK_TTS_EOS:
            return "CHUNK_TTS_EOS";
        case OmniTokenType::TURN_EOS:
            return "TURN_EOS";
        case OmniTokenType::TTS_EOS:
            return "TTS_EOS";
        case OmniTokenType::EOS:
            return "EOS";
        default:
            return "UNKNOWN";
    }
}

//
// omni structure
//
struct unit_buffer {
    std::vector<float> buffer;
    std::string        text;
    bool               completed   = false;
    int                unit_n_past = 0;
    float              duration;
};

struct omni_output {
    std::vector<unit_buffer *> output;
    int                        idx;
};

struct LLMOut {
    std::string              text;
    int                      n_past;
    bool                     llm_finish = false;
    std::string              debug_dir;
    // æ·»åŠ token IDså’Œhidden statesç”¨äºTTSæ¡ä»¶ç”Ÿæˆ
    std::vector<llama_token> token_ids;      // LLMç”Ÿæˆçš„token IDs
    std::vector<float>       hidden_states;  // LLMçš„hidden states (n_tokens * n_embd)
    int                      n_embd = 0;     // hidden statesçš„ç»´åº¦

    // ğŸ”§ [ä¿®å¤åŒå·¥ç¼ºå­—é—®é¢˜] è¯¥ chunk æ˜¯å¦æ˜¯ turn çš„æœ€åä¸€ä¸ª chunk
    // æ­¤çŠ¶æ€éšæ•°æ®ä¸€èµ·ä¼ é€’ï¼Œé¿å…å…¨å±€çŠ¶æ€ current_turn_ended çš„æ—¶åºé—®é¢˜
    // åªæœ‰å½“ LLM æ£€æµ‹åˆ° TURN_EOS/TTS_EOS/EOS æ—¶æ‰è®¾ç½®ä¸º true
    bool is_end_of_turn = false;
};

struct TTSThreadInfo {
    const int                             MAX_QUEUE_SIZE;
    std::queue<LLMOut *>                  queue;
    std::mutex                            mtx;
    std::condition_variable               cv;
    std::chrono::steady_clock::time_point start;
    std::chrono::steady_clock::time_point end;
    int                                   n_past = 0;

    TTSThreadInfo(int maxQueueSize) : MAX_QUEUE_SIZE(maxQueueSize) {}
};

// å‰å‘å£°æ˜
static void kv_cache_slide_window(struct omni_context * ctx_omni, common_params * params, int chunk_size);

//
// omni mtmd embed
//
bool omni_eval_embed(llama_context * ctx_llama, const struct omni_embed * omni_embed, int n_batch, int * n_past) {
    int n_embd = llama_n_embd(llama_get_model(ctx_llama));

    for (int i = 0; i < omni_embed->n_pos; i += n_batch) {
        int n_eval = omni_embed->n_pos - i;
        if (n_eval > n_batch) {
            n_eval = n_batch;
        }
        llama_batch batch = {};
        batch.n_tokens    = int32_t(n_eval);
        batch.embd        = (omni_embed->embed + i * n_embd);
        std::vector<llama_pos> pos_vec(n_eval);
        for (int j = 0; j < n_eval; j++) {
            pos_vec[j] = *n_past + j;
        }
        batch.pos = pos_vec.data();

        if (llama_decode(ctx_llama, batch)) {
            LOG_ERR("%s : failed to eval\n", __func__);
            return false;
        }
        *n_past += n_eval;
    }
    return true;
}

bool prefill_with_emb(struct omni_context * ctx_omni,
                      common_params *       params,
                      float *               embed,
                      int                   n_pos,
                      int                   n_batch,
                      int *                 n_past) {
    kv_cache_slide_window(ctx_omni, params, n_pos);

    int n_embd = llama_n_embd(llama_get_model(ctx_omni->ctx_llama));
    for (int i = 0; i < n_pos; i += n_batch) {
        int n_eval = n_pos - i;
        if (n_eval > n_batch) {
            n_eval = n_batch;
        }
        llama_batch batch = {};
        batch.n_tokens    = int32_t(n_eval);
        batch.embd        = (embed + i * n_embd);
        std::vector<llama_pos> pos_vec(n_eval);
        for (int j = 0; j < n_eval; j++) {
            pos_vec[j] = *n_past + j;
        }
        batch.pos = pos_vec.data();

        if (llama_decode(ctx_omni->ctx_llama, batch)) {
            LOG_ERR("%s : failed to eval\n", __func__);
            return false;
        }
        *n_past += n_eval;
    }
    return true;
}

// ä¸ prefill_with_emb ç±»ä¼¼ï¼Œä½†ä¼šå°†æ¯æ¬¡ decode çš„ hidden_state ä¿å­˜å¹¶æ‹¼æ¥åˆ° hidden_states ä¸­
// hidden_states ç”±å‡½æ•°å†…éƒ¨åˆ†é…ç©ºé—´ï¼Œå¤§å°ä¸º n_pos * n_embd * sizeof(float)ï¼Œè°ƒç”¨è€…è´Ÿè´£é‡Šæ”¾
bool prefill_emb_with_hidden(struct omni_context * ctx_omni,
                             common_params *       params,
                             float *               embed,
                             int                   n_pos,
                             int                   n_batch,
                             int *                 n_past,
                             float *&              hidden_states) {
    if (n_pos == 0) {
        hidden_states = nullptr;
        return true;
    }

    kv_cache_slide_window(ctx_omni, params, n_pos);

    int n_embd = llama_n_embd(llama_get_model(ctx_omni->ctx_llama));

    // åœ¨å‡½æ•°å†…éƒ¨åˆ†é…ç©ºé—´
    hidden_states = (float *) malloc(n_pos * n_embd * sizeof(float));
    if (hidden_states == nullptr) {
        LOG_ERR("%s : failed to allocate memory for hidden_states\n", __func__);
        return false;
    }

    int tokens_processed = 0;

    for (int i = 0; i < n_pos; i += n_batch) {
        int n_eval = n_pos - i;
        if (n_eval > n_batch) {
            n_eval = n_batch;
        }

        llama_batch batch = {};
        batch.n_tokens    = int32_t(n_eval);
        batch.embd        = (embed + i * n_embd);
        std::vector<llama_pos> pos_vec(n_eval);
        for (int j = 0; j < n_eval; j++) {
            pos_vec[j] = *n_past + j;
        }
        batch.pos = pos_vec.data();

        // å¯ç”¨ embeddings è¾“å‡º
        llama_set_embeddings(ctx_omni->ctx_llama, true);

        if (llama_decode(ctx_omni->ctx_llama, batch)) {
            LOG_ERR("%s : failed to eval\n", __func__);
            llama_set_embeddings(ctx_omni->ctx_llama, false);
            free(hidden_states);
            hidden_states = nullptr;
            return false;
        }

        // è·å–å½“å‰ batch çš„ embeddings å¹¶å¤åˆ¶åˆ° hidden_states
        float * emb = llama_get_embeddings(ctx_omni->ctx_llama);
        if (emb != nullptr) {
            memcpy(hidden_states + tokens_processed * n_embd, emb, n_eval * n_embd * sizeof(float));
        }

        llama_set_embeddings(ctx_omni->ctx_llama, false);

        *n_past += n_eval;
        tokens_processed += n_eval;
    }
    return true;
}

static bool load_file_to_bytes(const char * path, unsigned char ** bytesOut, long * sizeOut) {
    auto file = fopen(path, "rb");
    if (file == NULL) {
        LOG_ERR("%s: can't read file %s\n", __func__, path);
        return false;
    }

    fseek(file, 0, SEEK_END);
    auto fileSize = ftell(file);
    fseek(file, 0, SEEK_SET);

    auto buffer = (unsigned char *) malloc(fileSize);  // Allocate memory to hold the file data
    if (buffer == NULL) {
        LOG_ERR("%s: failed to alloc %ld bytes for file %s\n", __func__, fileSize, path);
        perror("Memory allocation error");
        fclose(file);
        return false;
    }
    errno      = 0;
    size_t ret = fread(buffer, 1, fileSize, file);  // Read the file into the buffer
    if (ferror(file)) {
        die_fmt("read error: %s", strerror(errno));
    }
    if (ret != (size_t) fileSize) {
        die("unexpectedly reached end of file");
    }
    fclose(file);  // Close the file

    *bytesOut = buffer;
    *sizeOut  = fileSize;
    return true;
}

void omni_embed_free(struct omni_embed * embed) {
    free(embed->embed);
    free(embed);
}

// ğŸ”§ [é«˜æ¸…æ¨¡å¼] è¿”å›åˆ†ç¦»çš„ chunk embedsï¼ˆäºŒç»´ vectorï¼‰
// è¿”å›å€¼: vision_chunks[0] = overview, vision_chunks[1..n] = slices
static bool encode_image_with_vision_chunks(vision_ctx *                      ctx_vision,
                                            int                               n_threads,
                                            const vision_image_u8 *           img,
                                            std::vector<std::vector<float>> & vision_chunks) {
    const int64_t          t_img_enc_start_us = ggml_time_us();
    vision_image_f32_batch img_res_v;
    img_res_v.entries.resize(0);
    img_res_v.entries.clear();
    if (!vision_image_preprocess(ctx_vision, img, &img_res_v)) {
        LOG_ERR("%s: unable to preprocess image\n", __func__);
        img_res_v.entries.clear();
        return false;
    }

    int n_embd   = vision_n_mmproj_embd(ctx_vision);
    int n_tokens = vision_n_output_tokens(ctx_vision);

    vision_chunks.clear();
    vision_chunks.resize(img_res_v.entries.size());

    for (size_t i = 0; i < img_res_v.entries.size(); i++) {
        const int64_t t_img_enc_step_start_us = ggml_time_us();

        // ä¸ºæ¯ä¸ª chunk åˆ†é…ç©ºé—´
        vision_chunks[i].resize(n_embd * n_tokens);

        bool encoded = vision_image_encode(ctx_vision, n_threads, img_res_v.entries[i].get(), vision_chunks[i].data());
        if (!encoded) {
            LOG_ERR("Unable to encode image - spatial_unpad - subimage %d of %d\n", (int) i + 1,
                    (int) img_res_v.entries.size());
            return false;
        }
        const int64_t t_img_enc_steop_batch_us = ggml_time_us();
        LOG_INF("%s: step %d of %d encoded in %8.2f ms\n", __func__, (int) i + 1, (int) img_res_v.entries.size(),
                (t_img_enc_steop_batch_us - t_img_enc_step_start_us) / 1000.0);
    }
    const int64_t t_img_enc_batch_us = ggml_time_us();
    LOG_INF("%s: all %d chunks encoded in %8.2f ms (grid: %dx%d)\n", __func__, (int) img_res_v.entries.size(),
            (t_img_enc_batch_us - t_img_enc_start_us) / 1000.0, img_res_v.grid_x, img_res_v.grid_y);

    const int64_t t_img_enc_end_us = ggml_time_us();
    float         t_img_enc_ms     = (t_img_enc_end_us - t_img_enc_start_us) / 1000.0;
    int           total_tokens     = (int) vision_chunks.size() * n_tokens;
    LOG_INF("\n%s: image encoded in %8.2f ms by vision (%8.2f ms per chunk, %d total tokens)\n", __func__, t_img_enc_ms,
            t_img_enc_ms / vision_chunks.size(), total_tokens);

    return true;
}

// ä¿ç•™åŸæœ‰å‡½æ•°ç”¨äºå…¼å®¹ï¼ˆå°†æ‰€æœ‰ chunk æ‹¼æˆä¸€ä¸ª flat bufferï¼‰
static bool encode_image_with_vision(vision_ctx *            ctx_vision,
                                     int                     n_threads,
                                     const vision_image_u8 * img,
                                     float *                 image_embd,
                                     int *                   n_img_pos) {
    std::vector<std::vector<float>> vision_chunks;
    if (!encode_image_with_vision_chunks(ctx_vision, n_threads, img, vision_chunks)) {
        return false;
    }

    int n_embd        = vision_n_mmproj_embd(ctx_vision);
    int n_tokens      = vision_n_output_tokens(ctx_vision);
    int n_img_pos_out = 0;

    for (size_t i = 0; i < vision_chunks.size(); i++) {
        std::memcpy(image_embd + n_img_pos_out * n_embd, vision_chunks[i].data(), n_embd * n_tokens * sizeof(float));
        n_img_pos_out += n_tokens;
    }
    *n_img_pos = n_img_pos_out;
    LOG_INF("%s: image embedding created: %d tokens from %d chunks\n", __func__, *n_img_pos,
            (int) vision_chunks.size());

    return true;
}

static void build_vision_image_from_data(const stbi_uc * data, int nx, int ny, vision_image_u8 * img) {
    img->nx = nx;
    img->ny = ny;
    img->buf.resize(3 * nx * ny);
    std::memcpy(img->buf.data(), data, img->buf.size());
}

bool vision_image_load_from_bytes(const unsigned char * bytes, size_t bytes_length, struct vision_image_u8 * img) {
    int    nx, ny, nc;
    auto * data = stbi_load_from_memory(bytes, bytes_length, &nx, &ny, &nc, 3);
    if (!data) {
        LOG_ERR("%s: failed to decode image bytes\n", __func__);
        return false;
    }
    build_vision_image_from_data(data, nx, ny, img);
    stbi_image_free(data);
    return true;
}

struct omni_embed * omni_image_embed_make_with_bytes(struct vision_ctx *   ctx_vision,
                                                     int                   n_threads,
                                                     const unsigned char * image_bytes,
                                                     int                   image_bytes_length) {
    vision_image_u8 * img = vision_image_u8_init();
    if (!vision_image_load_from_bytes(image_bytes, image_bytes_length, img)) {
        vision_image_u8_free(img);
        LOG_ERR("%s: can't load image from bytes, is it a valid image?", __func__);
        return NULL;
    }
    int     num_max_patches = 10;
    float * image_embed     = (float *) malloc(vision_n_mmproj_embd(ctx_vision) * vision_n_output_tokens(ctx_vision) *
                                               num_max_patches * sizeof(float));
    if (!image_embed) {
        vision_image_u8_free(img);
        LOG_ERR("Unable to allocate memory for image embeddings\n");
        return NULL;
    }

    LOG_INF("%s: omni_image_embed_make_with_filename s1\n", __func__);
    int n_img_pos = 0;
    if (!encode_image_with_vision(ctx_vision, n_threads, img, image_embed, &n_img_pos)) {
        vision_image_u8_free(img);
        free(image_embed);
        LOG_ERR("%s: cannot encode image, aborting\n", __func__);
        return NULL;
    }
    LOG_INF("%s: omni_image_embed_make_with_filename s2\n", __func__);

    vision_image_u8_free(img);
    auto result   = (omni_embed *) malloc(sizeof(omni_embed));
    result->embed = image_embed;
    result->n_pos = n_img_pos;
    return result;
}

struct omni_embed * omni_image_embed_make_with_filename(struct vision_ctx * ctx_vision,
                                                        int                 n_threads,
                                                        std::string         image_path) {
    unsigned char * image_bytes;
    long            image_bytes_length;
    auto            loaded = load_file_to_bytes(image_path.c_str(), &image_bytes, &image_bytes_length);
    if (!loaded) {
        LOG_ERR("%s: failed to load %s\n", __func__, image_path.c_str());
        return NULL;
    }
    LOG_INF("%s: omni_image_embed_make_with_filename: %s\n", __func__, image_path.c_str());
    omni_embed * embed = omni_image_embed_make_with_bytes(ctx_vision, n_threads, image_bytes, image_bytes_length);
    free(image_bytes);

    return embed;
}

// ğŸ”§ [é«˜æ¸…æ¨¡å¼] åˆ›å»ºå¸¦ chunks çš„ vision embedï¼ˆç”¨äº V2.6 slice schemaï¼‰
// è¿”å›çš„ vector: [0] = overview, [1..n] = slices
bool omni_image_embed_make_chunks_with_filename(struct vision_ctx *               ctx_vision,
                                                int                               n_threads,
                                                std::string                       image_path,
                                                std::vector<std::vector<float>> & vision_chunks) {
    unsigned char * image_bytes;
    long            image_bytes_length;
    auto            loaded = load_file_to_bytes(image_path.c_str(), &image_bytes, &image_bytes_length);
    if (!loaded) {
        LOG_ERR("%s: failed to load %s\n", __func__, image_path.c_str());
        return false;
    }

    vision_image_u8 * img = vision_image_u8_init();
    if (!vision_image_load_from_bytes(image_bytes, image_bytes_length, img)) {
        vision_image_u8_free(img);
        free(image_bytes);
        LOG_ERR("%s: can't load image from bytes, is it a valid image?", __func__);
        return false;
    }
    free(image_bytes);

    bool success = encode_image_with_vision_chunks(ctx_vision, n_threads, img, vision_chunks);
    vision_image_u8_free(img);

    if (success) {
        LOG_INF("%s: created %d vision chunks from %s\n", __func__, (int) vision_chunks.size(), image_path.c_str());
    }
    return success;
}

bool audition_read_binary_file(const char * fname, std::vector<uint8_t> * buf_res) {
    FILE * f = fopen(fname, "rb");
    if (!f) {
        LOG_ERR("Unable to open file %s: %s\n", fname, strerror(errno));
        return false;
    }
    fseek(f, 0, SEEK_END);
    long file_size = ftell(f);
    fseek(f, 0, SEEK_SET);
    buf_res->resize(file_size);

    size_t n_read = fread(buf_res->data(), 1, file_size, f);
    fclose(f);
    if (n_read != (size_t) file_size) {
        LOG_ERR("Failed to read entire file %s\n", fname);
        return false;
    }

    return true;
}

struct omni_embed * omni_audio_embed_make_with_bytes(audition_ctx *      ctx_audio,
                                                     int                 n_threads,
                                                     audition_audio_u8 * audio) {
    audition_audio_f32 * res_auds = audition_audio_f32_init();
    // printf("omni_audio_embed_make_with_bytes 1 :\n");
    if (!audition_audio_preprocess(ctx_audio, audio, &res_auds)) {
        LOG_ERR("%s: failed to preprocess audio file\n", __func__);
        audition_audio_f32_free(res_auds);
        return NULL;
    }
    // printf("omni_audio_embed_make_with_bytes 2 :\n");
    // åˆ†é…ç©ºé—´
    int                n_embd   = audition_n_mmproj_embd(ctx_audio);
    int                n_tokens = audition_n_output_tokens(ctx_audio, res_auds);
    std::vector<float> output_buffer(n_embd * n_tokens);

    if (!audition_audio_encode(ctx_audio, n_threads, res_auds, output_buffer.data())) {
        LOG_ERR("%s: cannot encode audio, aborting\n", __func__);
        audition_audio_f32_free(res_auds);
        return NULL;
    }
    // printf("omni_audio_embed_make_with_bytes 4 :\n");
    auto result   = (omni_embed *) malloc(sizeof(omni_embed));
    result->embed = (float *) malloc(output_buffer.size() * sizeof(float));
    if (!result->embed) {
        free(result);
        audition_audio_f32_free(res_auds);
        LOG_ERR("%s: failed to allocate memory for audio embeddings\n", __func__);
        return NULL;
    }
    std::memcpy(result->embed, output_buffer.data(), output_buffer.size() * sizeof(float));
    result->n_pos = n_tokens;

    audition_audio_f32_free(res_auds);
    // printf("===audio embed tokens: %d %d\n", result->n_pos, ret.buf.size() / ret.n_len);
    return result;
}

struct omni_embed * omni_audio_embed_make_with_filename(struct audition_ctx * ctx_audio,
                                                        int                   n_threads,
                                                        std::string           audio_path) {
    audition_audio_u8 * audio = audition_audio_u8_init();
    // printf("omni_audio_embed_make_with_filename 1 :%s\n", audio_path.c_str());
    if (!audition_read_binary_file(audio_path.c_str(), &audio->buf)) {
        LOG_ERR("%s: failed to read audio file %s\n", __func__, audio_path.c_str());
        return NULL;
    }
    // printf("omni_audio_embed_make_with_filename 2 :%s\n", audio_path.c_str());
    omni_embed * embed = omni_audio_embed_make_with_bytes(ctx_audio, n_threads, audio);
    if (embed == NULL) {
        LOG_ERR("%s: failed to preprocess audio file, %s\n", __func__, audio_path.c_str());
    }

    audition_audio_u8_free(audio);
    // printf("omni_audio_embed_make_with_filename 3 :%s\n", audio_path.c_str());
    return embed;
}

//
// omni llm eval
//
static void kv_cache_slide_window(struct omni_context * ctx_omni, common_params * params, int chunk_size) {
    const int n_ctx = params->n_ctx;

    // æ£€æŸ¥æ˜¯å¦éœ€è¦æ»‘åŠ¨çª—å£
    if (ctx_omni->n_past + chunk_size < n_ctx) {
        return;  // è¿˜æœ‰è¶³å¤Ÿç©ºé—´ï¼Œæ— éœ€æ»‘åŠ¨
    }

    // ğŸ”§ [è¯Šæ–­] æ‰“å°æ»‘åŠ¨çª—å£è§¦å‘ä¿¡æ¯
    print_with_timestamp("âš ï¸ KV Cache æ»‘åŠ¨çª—å£è§¦å‘: n_past=%d, chunk_size=%d, n_ctx=%d, n_keep=%d, è½®æ¬¡æ•°=%zu\n",
                         ctx_omni->n_past, chunk_size, n_ctx, ctx_omni->n_keep, ctx_omni->round_start_positions.size());

    int n_discard      = 0;
    int delete_end_pos = ctx_omni->n_keep;  // åˆ é™¤èŒƒå›´çš„ç»“æŸä½ç½®

    // ==================== æŒ‰è½®æ¬¡è¾¹ç•Œåˆ é™¤ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰ ====================
    // ğŸ”§ [é‡è¦] round_start_positions è®°å½•çš„æ˜¯è½®æ¬¡**ç»“æŸ**ä½ç½®ï¼ˆä¹Ÿæ˜¯ä¸‹ä¸€è½®å¼€å§‹ä½ç½®ï¼‰
    // è½®æ¬¡å¸ƒå±€ï¼š
    //   è½®æ¬¡ 0: [n_keep, round_start_positions[0])
    //   è½®æ¬¡ 1: [round_start_positions[0], round_start_positions[1])
    //   è½®æ¬¡ i: [round_start_positions[i-1], round_start_positions[i])
    //   å½“å‰è½®ï¼ˆæœªç»“æŸï¼‰: [round_start_positions[size-1], n_past)
    if (ctx_omni->max_preserved_context > 0 && ctx_omni->round_start_positions.size() >= 1) {
        // ç­–ç•¥ï¼šä¿ç•™å°½å¯èƒ½å¤šçš„æœ€è¿‘è½®æ¬¡ï¼Œä½†æ€»é•¿åº¦ä¸è¶…è¿‡ max_preserved_context
        // ä»æœ€æ–°è½®æ¬¡å¾€å‰æ•°ï¼Œç´¯è®¡é•¿åº¦ç›´åˆ°è¶…è¿‡ max_preserved_context

        const auto & rounds            = ctx_omni->round_start_positions;
        int          cumulative_length = 0;
        int          keep_from_round   = rounds.size();  // ä»å“ªä¸ªè½®æ¬¡å¼€å§‹ä¿ç•™ï¼ˆ0-indexedï¼‰
        int          total_rounds      = rounds.size();  // æ€»è½®æ¬¡æ•°ï¼ˆå·²å®Œæˆçš„è½®æ¬¡ï¼‰

        // ä»æœ€åä¸€ä¸ªå·²å®Œæˆè½®æ¬¡å¾€å‰éå†
        for (int i = total_rounds - 1; i >= 0; --i) {
            // è®¡ç®—ç¬¬ i è½®çš„é•¿åº¦
            // è½®æ¬¡ i çš„èŒƒå›´æ˜¯ [round_start(i), round_end(i))
            int round_start  = (i == 0) ? ctx_omni->n_keep : rounds[i - 1];
            int round_end    = rounds[i];
            int round_length = round_end - round_start;

            if (cumulative_length + round_length > ctx_omni->max_preserved_context) {
                // åŠ ä¸Šè¿™ä¸€è½®ä¼šè¶…è¿‡é™åˆ¶ï¼Œåœæ­¢
                break;
            }

            cumulative_length += round_length;
            keep_from_round = i;
        }

        // è‡³å°‘ä¿ç•™æœ€è¿‘ä¸€è½®
        if (keep_from_round >= total_rounds) {
            keep_from_round = total_rounds - 1;
        }

        // è®¡ç®—è¦åˆ é™¤çš„èŒƒå›´
        // ä¿ç•™è½®æ¬¡ [keep_from_round, total_rounds)
        // åˆ é™¤è½®æ¬¡ [0, keep_from_round)
        // åˆ é™¤èŒƒå›´ï¼š[n_keep, è½®æ¬¡ keep_from_round çš„å¼€å§‹ä½ç½®)
        int delete_start = ctx_omni->n_keep;
        delete_end_pos   = (keep_from_round == 0) ? ctx_omni->n_keep : rounds[keep_from_round - 1];

        if (delete_end_pos > delete_start) {
            n_discard = delete_end_pos - delete_start;

            print_with_timestamp("âš ï¸ æŒ‰è½®æ¬¡åˆ é™¤: åˆ é™¤è½®æ¬¡ 0-%dï¼Œä¿ç•™è½®æ¬¡ %d-%dï¼Œä¿ç•™é•¿åº¦=%d\n", keep_from_round - 1,
                                 keep_from_round, total_rounds - 1, cumulative_length);

            // æ›´æ–° round_start_positionsï¼šåˆ é™¤æ—©æœŸè½®æ¬¡ï¼Œè°ƒæ•´å‰©ä½™è½®æ¬¡çš„ä½ç½®
            std::vector<int> new_rounds;
            for (int i = keep_from_round; i < total_rounds; ++i) {
                new_rounds.push_back(rounds[i] - n_discard);
            }
            ctx_omni->round_start_positions = new_rounds;

            print_with_timestamp("âš ï¸ æ›´æ–°è½®æ¬¡è¾¹ç•Œ: æ–°è¾¹ç•Œæ•°=%zuï¼Œé¦–è½®ç»“æŸä½ç½®=%d\n", new_rounds.size(),
                                 new_rounds.empty() ? -1 : new_rounds[0]);
        } else {
            // æ²¡æœ‰å¯åˆ é™¤çš„å®Œæ•´è½®æ¬¡ï¼Œå›é€€åˆ°æŒ‰æ¯”ä¾‹åˆ é™¤
            print_with_timestamp("âš ï¸ æ²¡æœ‰å¯åˆ é™¤çš„å®Œæ•´è½®æ¬¡ï¼ˆkeep_from_round=%dï¼‰ï¼Œå›é€€åˆ°æŒ‰æ¯”ä¾‹åˆ é™¤\n", keep_from_round);
            n_discard = 0;
        }
    }

    // ==================== å›é€€ç­–ç•¥ï¼šæŒ‰æ¯”ä¾‹åˆ é™¤ï¼ˆæ—§é€»è¾‘ï¼‰ ====================
    if (n_discard == 0) {
        const int n_left = ctx_omni->n_past - ctx_omni->n_keep;
        n_discard        = n_left / 2;
        delete_end_pos   = ctx_omni->n_keep + n_discard;

        // è¾¹ç•Œæ£€æŸ¥
        if (n_left <= 0 || n_discard <= 0) {
            print_with_timestamp("âš ï¸ KV Cache æ»‘åŠ¨çª—å£: è¾¹ç•Œæ£€æŸ¥å¤±è´¥ n_left=%d, n_discard=%dï¼Œè·³è¿‡æ»‘åŠ¨\n", n_left,
                                 n_discard);
            return;
        }

        // æŒ‰æ¯”ä¾‹åˆ é™¤æ—¶ï¼Œæ›´æ–° round_start_positions
        // round_start_positions[i] è¡¨ç¤ºç¬¬ i è½®çš„ç»“æŸä½ç½®
        // åˆ é™¤èŒƒå›´ [n_keep, delete_end_pos) ä¼šå½±å“è½®æ¬¡è¾¹ç•Œ
        std::vector<int> new_rounds;
        for (int pos : ctx_omni->round_start_positions) {
            if (pos > delete_end_pos) {
                // è¿™ä¸ªè½®æ¬¡ç»“æŸä½ç½®åœ¨åˆ é™¤èŒƒå›´ä¹‹åï¼Œéœ€è¦å‰ç§»
                new_rounds.push_back(pos - n_discard);
            }
            // å¦‚æœ pos <= delete_end_posï¼Œè¯´æ˜è¿™ä¸ªè½®æ¬¡è¢«åˆ é™¤æˆ–éƒ¨åˆ†åˆ é™¤ï¼Œä¸¢å¼ƒ
        }
        ctx_omni->round_start_positions = new_rounds;

        print_with_timestamp("âš ï¸ æŒ‰æ¯”ä¾‹åˆ é™¤åè½®æ¬¡è¾¹ç•Œ: å‰©ä½™ %zu ä¸ªè½®æ¬¡\n", new_rounds.size());

        print_with_timestamp("âš ï¸ æŒ‰æ¯”ä¾‹åˆ é™¤: n_left=%d, n_discard=%d, åˆ é™¤èŒƒå›´=[%d, %d)\n", n_left, n_discard,
                             ctx_omni->n_keep, delete_end_pos);
    }

    // ==================== æ‰§è¡Œ KV Cache æ“ä½œ ====================
    print_with_timestamp("âš ï¸ KV Cache æ»‘åŠ¨çª—å£æ‰§è¡Œ: åˆ é™¤èŒƒå›´=[%d, %d), n_discard=%d\n", ctx_omni->n_keep, delete_end_pos,
                         n_discard);

    llama_memory_t mem = llama_get_memory(ctx_omni->ctx_llama);
    if (mem) {
        // 1. åˆ é™¤ [n_keep, delete_end_pos) èŒƒå›´çš„ token
        bool rm_ok = llama_memory_seq_rm(mem, 0, ctx_omni->n_keep, delete_end_pos);
        (void) rm_ok;

        // 2. å°† [delete_end_pos, n_past) èŒƒå›´çš„ token ä½ç½®å‰ç§» n_discard
        llama_memory_seq_add(mem, 0, delete_end_pos, ctx_omni->n_past, -n_discard);
    }

    // 3. æ›´æ–° n_past
    int old_n_past = ctx_omni->n_past;
    ctx_omni->n_past -= n_discard;
    print_with_timestamp("âš ï¸ KV Cache æ»‘åŠ¨çª—å£å®Œæˆ: n_past ä» %d å‡å°‘åˆ° %d\n", old_n_past, ctx_omni->n_past);
}

static bool eval_tokens(struct omni_context *    ctx_omni,
                        common_params *          params,
                        std::vector<llama_token> tokens,
                        int                      n_batch,
                        int *                    n_past,
                        bool                     get_emb = false) {
    int N = (int) tokens.size();
    kv_cache_slide_window(ctx_omni, params, N);

    for (int i = 0; i < N; i += n_batch) {
        int n_eval = (int) tokens.size() - i;
        if (n_eval > n_batch) {
            n_eval = n_batch;
        }
        if (n_eval == 0) {
            break;
        }
        if (get_emb) {
            llama_set_embeddings(ctx_omni->ctx_llama, true);
        }
        // llama_batch_get_one è¿”å›çš„ batch.pos å¯èƒ½æ˜¯ nullptrï¼Œéœ€è¦æ‰‹åŠ¨è®¾ç½®
        llama_batch            batch = llama_batch_get_one(&tokens[i], n_eval);
        std::vector<llama_pos> pos_vec;
        if (batch.pos == nullptr) {
            pos_vec.resize(n_eval);
            batch.pos = pos_vec.data();
        }
        for (int j = 0; j < n_eval; j++) {
            batch.pos[j] = *n_past + j;  // ä»å½“å‰ n_past ä½ç½®å¼€å§‹
        }

        if (llama_decode(ctx_omni->ctx_llama, batch)) {
            LOG_ERR("%s : failed to eval. token %d/%d (batch size %d, n_past %d)\n", __func__, i, N, n_batch, *n_past);
            return false;
        }
        if (get_emb) {
            llama_set_embeddings(ctx_omni->ctx_llama, false);
        }
        *n_past += n_eval;
    }
    return true;
}

// ä¸ eval_tokens ç±»ä¼¼ï¼Œä½†ä¼šå°†æ¯æ¬¡ decode çš„ hidden_state ä¿å­˜å¹¶æ‹¼æ¥åˆ° hidden_states ä¸­
// hidden_states ç”±å‡½æ•°å†…éƒ¨åˆ†é…ç©ºé—´ï¼Œå¤§å°ä¸º N * n_embd * sizeof(float)ï¼Œè°ƒç”¨è€…è´Ÿè´£é‡Šæ”¾
static bool eval_tokens_with_hidden(struct omni_context *    ctx_omni,
                                    common_params *          params,
                                    std::vector<llama_token> tokens,
                                    int                      n_batch,
                                    int *                    n_past,
                                    float *&                 hidden_states) {
    int N = (int) tokens.size();
    if (N == 0) {
        hidden_states = nullptr;
        return true;
    }

    kv_cache_slide_window(ctx_omni, params, N);

    const int n_embd = llama_n_embd(llama_get_model(ctx_omni->ctx_llama));

    // åœ¨å‡½æ•°å†…éƒ¨åˆ†é…ç©ºé—´
    hidden_states = (float *) malloc(N * n_embd * sizeof(float));
    if (hidden_states == nullptr) {
        LOG_ERR("%s : failed to allocate memory for hidden_states\n", __func__);
        return false;
    }

    int tokens_processed = 0;

    for (int i = 0; i < N; i += n_batch) {
        int n_eval = (int) tokens.size() - i;
        if (n_eval > n_batch) {
            n_eval = n_batch;
        }
        if (n_eval == 0) {
            break;
        }

        // å¯ç”¨ embeddings è¾“å‡º
        llama_set_embeddings(ctx_omni->ctx_llama, true);
        // llama_batch_get_one è¿”å›çš„ batch.pos å¯èƒ½æ˜¯ nullptrï¼Œéœ€è¦æ‰‹åŠ¨è®¾ç½®
        llama_batch            batch = llama_batch_get_one(&tokens[i], n_eval);
        std::vector<llama_pos> pos_vec;
        if (batch.pos == nullptr) {
            pos_vec.resize(n_eval);
            batch.pos = pos_vec.data();
        }
        for (int j = 0; j < n_eval; j++) {
            batch.pos[j] = *n_past + j;  // ä»å½“å‰ n_past ä½ç½®å¼€å§‹
        }

        if (llama_decode(ctx_omni->ctx_llama, batch)) {
            LOG_ERR("%s : failed to eval. token %d/%d (batch size %d, n_past %d)\n", __func__, i, N, n_batch, *n_past);
            llama_set_embeddings(ctx_omni->ctx_llama, false);
            free(hidden_states);
            hidden_states = nullptr;
            return false;
        }

        // è·å–å½“å‰ batch çš„ embeddings å¹¶å¤åˆ¶åˆ° hidden_states
        float * emb = llama_get_embeddings(ctx_omni->ctx_llama);
        if (emb != nullptr) {
            // å°†å½“å‰ batch çš„ embeddings å¤åˆ¶åˆ° hidden_states çš„å¯¹åº”ä½ç½®
            memcpy(hidden_states + tokens_processed * n_embd, emb, n_eval * n_embd * sizeof(float));
        }

        llama_set_embeddings(ctx_omni->ctx_llama, false);

        *n_past += n_eval;
        tokens_processed += n_eval;
    }
    return true;
}

static bool eval_id(struct omni_context * ctx_omni, common_params * params, int id, int * n_past) {
    std::vector<llama_token> tokens;
    tokens.push_back(id);
    return eval_tokens(ctx_omni, params, tokens, 1, n_past);
}

static bool eval_id_with_hidden(struct omni_context * ctx_omni,
                                common_params *       params,
                                int                   id,
                                int *                 n_past,
                                float *&              hidden_states) {
    std::vector<llama_token> tokens;
    tokens.push_back(id);
    return eval_tokens_with_hidden(ctx_omni, params, tokens, 1, n_past, hidden_states);
}

static bool eval_string(struct omni_context * ctx_omni,
                        common_params *       params,
                        const char *          str,
                        int                   n_batch,
                        int *                 n_past,
                        bool                  add_bos,
                        bool                  get_emb = false) {
    std::string              str2     = str;
    std::vector<llama_token> embd_inp = common_tokenize(ctx_omni->ctx_llama, str2, add_bos, true);
    return eval_tokens(ctx_omni, params, embd_inp, n_batch, n_past, get_emb);
}

static bool eval_string_with_hidden(struct omni_context * ctx_omni,
                                    common_params *       params,
                                    const char *          str,
                                    int                   n_batch,
                                    int *                 n_past,
                                    bool                  add_bos,
                                    float *&              hidden_states) {
    std::string              str2     = str;
    std::vector<llama_token> embd_inp = common_tokenize(ctx_omni->ctx_llama, str2, add_bos, true);
    return eval_tokens_with_hidden(ctx_omni, params, embd_inp, n_batch, n_past, hidden_states);
}

static const char * sample(struct common_sampler * smpl,
                           struct omni_context *   ctx_omni,
                           common_params *         params,
                           int *                   n_past) {
    const llama_token id = common_sampler_sample(smpl, ctx_omni->ctx_llama, -1);
    common_sampler_accept(smpl, id, true);
    static std::string ret;
    if (llama_vocab_is_eog(llama_model_get_vocab(llama_get_model(ctx_omni->ctx_llama)), id)) {
        ret = "</s>";
    } else {
        ret = common_token_to_piece(ctx_omni->ctx_llama, id);
    }
    eval_id(ctx_omni, params, id, n_past);
    return ret.c_str();
}

static const char * sample_with_hidden(struct common_sampler * smpl,
                                       struct omni_context *   ctx_omni,
                                       common_params *         params,
                                       int *                   n_past,
                                       float *&                hidden_states) {
    const llama_token id = common_sampler_sample(smpl, ctx_omni->ctx_llama, -1);
    common_sampler_accept(smpl, id, true);
    static std::string ret;
    if (llama_vocab_is_eog(llama_model_get_vocab(llama_get_model(ctx_omni->ctx_llama)), id)) {
        ret = "</s>";
    } else {
        ret = common_token_to_piece(ctx_omni->ctx_llama, id);
    }
    eval_id_with_hidden(ctx_omni, params, id, n_past, hidden_states);
    return ret.c_str();
}

static const char * llama_loop(struct omni_context *   ctx_omni,
                               common_params *         params,
                               struct common_sampler * smpl,
                               int &                   n_past) {
    const char * tmp = sample(smpl, ctx_omni, params, &n_past);
    return tmp;
}

// ä¿®æ”¹sample_with_hiddenæ¥è¿”å›token IDï¼ˆé€šè¿‡å¼•ç”¨å‚æ•°ï¼‰
// ğŸ”§ [åŒå·¥æ¨¡å¼] æ”¯æŒ listen_prob_scale å‚æ•°ï¼Œå¢åŠ  <|listen|> çš„é‡‡æ ·æ¦‚ç‡
// ğŸ”§ [åŒå·¥æ¨¡å¼] æ”¯æŒ forbidden_token_idsï¼Œç¦æ­¢é‡‡æ · <|tts_pad|> ç­‰ token
static const char * sample_with_hidden_and_token(struct common_sampler * smpl,
                                                 struct omni_context *   ctx_omni,
                                                 common_params *         params,
                                                 int *                   n_past,
                                                 float *&                hidden_states,
                                                 llama_token &           token_id) {
    float * logits = llama_get_logits_ith(ctx_omni->ctx_llama, -1);

    // ğŸ”§ [åŒå·¥æ¨¡å¼] åœ¨é‡‡æ ·å‰è°ƒæ•´ logits
    if (ctx_omni->duplex_mode) {
        if (logits != nullptr) {
            // 1. ğŸ”§ [ä¿®å¤çŸ­å›å¤] åœ¨å‰ min_speak_tokens ä¸ª token å†…ï¼Œç¦æ­¢æ‰€æœ‰ç»“æŸ token
            // åŒ…æ‹¬: <|listen|>, <|turn_eos|>, <|tts_eos|>, </s> (EOS)
            // è¿™æ ·æ¨¡å‹å¿…é¡»è‡³å°‘ç”Ÿæˆè¶³å¤Ÿå¤šçš„æœ‰æ•ˆ token æ‰èƒ½ç»“æŸè¯´è¯
            bool in_min_speak_window =
                (ctx_omni->min_speak_tokens > 0 && ctx_omni->current_speak_token_count < ctx_omni->min_speak_tokens);

            if (in_min_speak_window) {
                // ç¦æ­¢æ‰€æœ‰ç»“æŸ token
                if (ctx_omni->special_token_listen >= 0) {
                    logits[ctx_omni->special_token_listen] = -INFINITY;
                }
                if (ctx_omni->special_token_turn_eos >= 0) {
                    logits[ctx_omni->special_token_turn_eos] = -INFINITY;
                }
                if (ctx_omni->special_token_tts_eos >= 0) {
                    logits[ctx_omni->special_token_tts_eos] = -INFINITY;
                }
                // ä¹Ÿç¦æ­¢ EOS token
                const llama_model * model  = llama_get_model(ctx_omni->ctx_llama);
                const llama_vocab * vocab  = llama_model_get_vocab(model);
                llama_token         eos_id = llama_vocab_eos(vocab);
                if (eos_id >= 0) {
                    logits[eos_id] = -INFINITY;
                }
                // æ¯ 10 ä¸ª token æ‰“å°ä¸€æ¬¡ï¼Œå‡å°‘æ—¥å¿—é‡
                if (ctx_omni->current_speak_token_count % 10 == 0) {
                    print_with_timestamp("[min_speak] suppressing ALL end tokens: count=%d/%d\n",
                                         ctx_omni->current_speak_token_count, ctx_omni->min_speak_tokens);
                }
            } else {
                // è¶…è¿‡æœ€å°é˜ˆå€¼åï¼Œæ­£å¸¸åº”ç”¨ listen_prob_scale
                if (ctx_omni->special_token_listen >= 0) {
                    float listen_bias = (ctx_omni->listen_prob_scale - 1.0f) * 2.0f;
                    logits[ctx_omni->special_token_listen] += listen_bias;
                }
                if (ctx_omni->current_speak_token_count == ctx_omni->min_speak_tokens) {
                    print_with_timestamp("[min_speak] ALL suppression lifted: count=%d/%d\n",
                                         ctx_omni->current_speak_token_count, ctx_omni->min_speak_tokens);
                }
            }

            // 2. ğŸ”§ [ä¸ Python å¯¹é½] ç¦æ­¢é‡‡æ · <|tts_pad|> token
            // Python: self.forbidden_token_ids = [self.tts_pad_id] + list(bad_token_ids)
            // <|tts_pad|> æ˜¯å¡«å…… tokenï¼Œæ¨¡å‹ä¸åº”è¯¥ä¸»åŠ¨ç”Ÿæˆå®ƒ
            // å¦‚æœä¸ç¦æ­¢ï¼Œæ¨¡å‹å¯èƒ½ç”Ÿæˆ <|speak|> â†’ <|tts_pad|> â†’ <|chunk_eos|>ï¼Œå¯¼è‡´æ— æœ‰æ•ˆè¾“å‡º
            if (ctx_omni->special_token_tts_pad >= 0) {
                logits[ctx_omni->special_token_tts_pad] = -INFINITY;
            }
        }
    }

    // ğŸ”§ [Length Penalty] è°ƒæ•´ EOS token çš„ logit å€¼ï¼ˆå•å·¥æ¨¡å¼ï¼‰
    // length_penalty > 1.0 ä¼šé™ä½ EOS æ¦‚ç‡ï¼Œè®©æ¨¡å‹ç”Ÿæˆæ›´é•¿çš„è¾“å‡º
    if (!ctx_omni->duplex_mode && ctx_omni->length_penalty != 1.0f && ctx_omni->special_token_tts_eos >= 0) {
        if (logits != nullptr) {
            float eos_logit = logits[ctx_omni->special_token_tts_eos];
            if (eos_logit > 0) {
                // logit > 0 æ—¶ï¼Œé™¤ä»¥ length_penalty æ¥é™ä½æ¦‚ç‡
                logits[ctx_omni->special_token_tts_eos] = eos_logit / ctx_omni->length_penalty;
            } else {
                // logit <= 0 æ—¶ï¼Œä¹˜ä»¥ length_penalty æ¥é™ä½æ¦‚ç‡
                logits[ctx_omni->special_token_tts_eos] = eos_logit * ctx_omni->length_penalty;
            }
        }
    }

    const llama_token id = common_sampler_sample(smpl, ctx_omni->ctx_llama, -1);
    token_id             = id;  // ä¿å­˜token ID
    common_sampler_accept(smpl, id, true);
    static std::string ret;
    if (llama_vocab_is_eog(llama_model_get_vocab(llama_get_model(ctx_omni->ctx_llama)), id)) {
        ret = "</s>";
    } else {
        ret = common_token_to_piece(ctx_omni->ctx_llama, id);
    }
    eval_id_with_hidden(ctx_omni, params, id, n_past, hidden_states);
    return ret.c_str();
}

static const char * llama_loop_with_hidden(struct omni_context *   ctx_omni,
                                           common_params *         params,
                                           struct common_sampler * smpl,
                                           int &                   n_past,
                                           float *&                hidden_states) {
    llama_token  dummy_token;
    const char * tmp = sample_with_hidden_and_token(smpl, ctx_omni, params, &n_past, hidden_states, dummy_token);
    return tmp;
}

// æ–°å¢ï¼šè¿”å›token IDçš„ç‰ˆæœ¬
static const char * llama_loop_with_hidden_and_token(struct omni_context *   ctx_omni,
                                                     common_params *         params,
                                                     struct common_sampler * smpl,
                                                     int &                   n_past,
                                                     float *&                hidden_states,
                                                     llama_token &           token_id) {
    const char * tmp = sample_with_hidden_and_token(smpl, ctx_omni, params, &n_past, hidden_states, token_id);
    return tmp;
}

//
// TTS specific helper functions
//

// Helper function to get RNG from sampler chain for multinomial sampling
// Uses common_sampler_get_rng() from common/sampling.cpp
// This ensures audio_bos sampling uses the same RNG as non-audio_bos sampling
static std::mt19937 * get_sampler_rng(struct common_sampler * smpl) {
    void * rng_ptr = common_sampler_get_rng(smpl);
    return static_cast<std::mt19937 *>(rng_ptr);
}

// ==============================================================================
// Projector Semantic å®ç° (ç²¾åº¦éªŒè¯ç‰ˆæœ¬)
// ä½¿ç”¨ ggml åç«¯è¿›è¡Œè®¡ç®—ï¼Œæ”¯æŒ CUDA åŠ é€Ÿ
// forward(x): relu(linear1(x)) -> linear2
// ==============================================================================
bool projector_init(projector_model & model, const std::string & fname, bool use_cuda) {
    struct gguf_init_params params = {
        /*.no_alloc = */ true,
        /*.ctx      = */ nullptr,
    };

    struct gguf_context * ctx_gguf = gguf_init_from_file(fname.c_str(), params);
    if (!ctx_gguf) {
        LOG_ERR("Projector: failed to open '%s'\n", fname.c_str());
        return false;
    }

#ifdef GGML_USE_CUDA
    if (use_cuda) {
        model.backend = ggml_backend_init_by_type(GGML_BACKEND_DEVICE_TYPE_GPU, NULL);
        if (!model.backend) {
            model.backend = ggml_backend_init_by_type(GGML_BACKEND_DEVICE_TYPE_CPU, NULL);
        }
    } else {
        model.backend = ggml_backend_init_by_type(GGML_BACKEND_DEVICE_TYPE_CPU, NULL);
    }
#else
    (void) use_cuda;
    model.backend = ggml_backend_init_by_type(GGML_BACKEND_DEVICE_TYPE_CPU, NULL);
#endif

    if (!model.backend) {
        LOG_ERR("Projector: failed to init backend\n");
        gguf_free(ctx_gguf);
        return false;
    }

    model.buf_type = ggml_backend_get_default_buffer_type(model.backend);

    const int64_t n_tensors = gguf_get_n_tensors(ctx_gguf);

    size_t                  ctx_size   = ggml_tensor_overhead() * n_tensors;
    struct ggml_init_params ctx_params = {
        /*.mem_size   = */ ctx_size,
        /*.mem_buffer = */ nullptr,
        /*.no_alloc   = */ true,
    };
    model.ctx_w = ggml_init(ctx_params);

    for (int64_t i = 0; i < n_tensors; i++) {
        const char *         name   = gguf_get_tensor_name(ctx_gguf, i);
        enum ggml_type       type   = gguf_get_tensor_type(ctx_gguf, i);
        struct ggml_tensor * tensor = nullptr;

        if (strcmp(name, "linear1.weight") == 0) {
            tensor                     = ggml_new_tensor_2d(model.ctx_w, type, 4096, 768);
            model.layer.linear1_weight = tensor;
            model.hparams.in_dim       = 4096;
            model.hparams.out_dim      = 768;
        } else if (strcmp(name, "linear1.bias") == 0) {
            tensor                   = ggml_new_tensor_1d(model.ctx_w, type, 768);
            model.layer.linear1_bias = tensor;
        } else if (strcmp(name, "linear2.weight") == 0) {
            tensor                     = ggml_new_tensor_2d(model.ctx_w, type, 768, 768);
            model.layer.linear2_weight = tensor;
        } else if (strcmp(name, "linear2.bias") == 0) {
            tensor                   = ggml_new_tensor_1d(model.ctx_w, type, 768);
            model.layer.linear2_bias = tensor;
        } else {
            continue;
        }

        if (tensor) {
            ggml_set_name(tensor, name);
        }
    }

    model.buf_w = ggml_backend_alloc_ctx_tensors(model.ctx_w, model.backend);

    FILE * f = fopen(fname.c_str(), "rb");
    if (!f) {
        LOG_ERR("Projector: failed to open file for reading\n");
        return false;
    }

    for (int64_t i = 0; i < n_tensors; i++) {
        const char *         name   = gguf_get_tensor_name(ctx_gguf, i);
        struct ggml_tensor * tensor = ggml_get_tensor(model.ctx_w, name);
        if (!tensor) {
            continue;
        }

        size_t offset = gguf_get_data_offset(ctx_gguf) + gguf_get_tensor_offset(ctx_gguf, i);
        fseek(f, offset, SEEK_SET);

        size_t tensor_size = ggml_nbytes(tensor);
        void * data        = malloc(tensor_size);
        if (fread(data, 1, tensor_size, f) != tensor_size) {
            LOG_ERR("Projector: failed to read tensor %s\n", name);
            free(data);
            fclose(f);
            return false;
        }

        ggml_backend_tensor_set(tensor, data, 0, tensor_size);
        free(data);
    }

    fclose(f);
    gguf_free(ctx_gguf);

    model.initialized = true;
    return true;
}

void projector_free(projector_model & model) {
    if (model.ctx_w) {
        ggml_free(model.ctx_w);
    }
    if (model.buf_w) {
        ggml_backend_buffer_free(model.buf_w);
    }
    if (model.backend) {
        ggml_backend_free(model.backend);
    }
    model.ctx_w       = nullptr;
    model.buf_w       = nullptr;
    model.backend     = nullptr;
    model.initialized = false;
}

static struct ggml_cgraph * projector_build_graph(projector_model &     model,
                                                  struct ggml_context * ctx,
                                                  struct ggml_tensor *  input) {
    struct ggml_cgraph * gf = ggml_new_graph(ctx);

    // linear1 + relu
    struct ggml_tensor * hidden = ggml_mul_mat(ctx, model.layer.linear1_weight, input);
    hidden                      = ggml_add(ctx, hidden, model.layer.linear1_bias);
    hidden                      = ggml_relu(ctx, hidden);

    // linear2
    struct ggml_tensor * output = ggml_mul_mat(ctx, model.layer.linear2_weight, hidden);
    output                      = ggml_add(ctx, output, model.layer.linear2_bias);

    ggml_build_forward_expand(gf, output);
    return gf;
}

std::vector<float> projector_forward(projector_model & model, const float * input_data, int n_tokens) {
    const int in_dim  = model.hparams.in_dim;
    const int out_dim = model.hparams.out_dim;

    // ğŸ”§ [å®‰å…¨æ£€æŸ¥] éªŒè¯å‚æ•°
    if (n_tokens <= 0 || n_tokens > 10000) {
        LOG_ERR("projector_forward: invalid n_tokens=%d\n", n_tokens);
        return {};
    }
    if (in_dim <= 0 || in_dim > 10000 || out_dim <= 0 || out_dim > 10000) {
        LOG_ERR("projector_forward: invalid dimensions in_dim=%d, out_dim=%d\n", in_dim, out_dim);
        return {};
    }

    size_t                  ctx_size = ggml_tensor_overhead() * 10 + ggml_graph_overhead();
    struct ggml_init_params params   = {
        /*.mem_size   = */ ctx_size,
        /*.mem_buffer = */ nullptr,
        /*.no_alloc   = */ true,
    };
    struct ggml_context * ctx = ggml_init(params);

    struct ggml_tensor * input = ggml_new_tensor_2d(ctx, GGML_TYPE_F32, in_dim, n_tokens);
    ggml_set_name(input, "input");
    ggml_set_input(input);

    struct ggml_cgraph * gf = projector_build_graph(model, ctx, input);

    ggml_backend_buffer_t buf_compute = ggml_backend_alloc_ctx_tensors(ctx, model.backend);
    if (!buf_compute) {
        LOG_ERR("Projector: failed to allocate compute buffer\n");
        ggml_free(ctx);
        return {};
    }

    ggml_backend_tensor_set(input, input_data, 0, n_tokens * in_dim * sizeof(float));

    enum ggml_status status = ggml_backend_graph_compute(model.backend, gf);
    if (status != GGML_STATUS_SUCCESS) {
        LOG_ERR("Projector: graph compute failed with status %d\n", (int) status);
        ggml_backend_buffer_free(buf_compute);
        ggml_free(ctx);
        return {};
    }

    struct ggml_tensor * output = ggml_graph_node(gf, ggml_graph_n_nodes(gf) - 1);
    std::vector<float>   result(n_tokens * out_dim);
    ggml_backend_tensor_get(output, result.data(), 0, n_tokens * out_dim * sizeof(float));

    ggml_backend_buffer_free(buf_compute);
    ggml_free(ctx);

    return result;
}

// ==============================================================================

// Load TTS weights from GGUF file
bool load_tts_weights_from_gguf(struct omni_context * ctx_omni, const char * tts_model_path) {
    // Initialize GGUF context
    struct ggml_context *   ctx_meta = NULL;
    struct gguf_init_params params   = {
        /*.no_alloc = */ false,
        /*.ctx      = */ &ctx_meta,
    };

    struct gguf_context * ctx_gguf = gguf_init_from_file(tts_model_path, params);
    if (!ctx_gguf) {
        LOG_ERR("TTS: Failed to load GGUF file: %s\n", tts_model_path);
        return false;
    }

    // Load emb_code.0.weight: (num_audio_tokens=6562, hidden_size=768)
    // This is used to convert audio token IDs to embeddings during decode phase
    const char * emb_code_name = "emb_code.0.weight";
    int64_t      emb_code_idx  = gguf_find_tensor(ctx_gguf, emb_code_name);
    if (emb_code_idx >= 0) {
        struct ggml_tensor * emb_code_tensor = ggml_get_tensor(ctx_meta, emb_code_name);
        if (emb_code_tensor) {
            // emb_code is Embedding(num_audio_tokens, hidden_size)
            // In PyTorch: weight shape is (num_audio_tokens, hidden_size) = [6562, 768]
            // In GGUF: stored as (hidden_size, num_audio_tokens) = [768, 6562] (transposed)
            int64_t dim0 = emb_code_tensor->ne[0];
            int64_t dim1 = emb_code_tensor->ne[1];

            // Determine which dimension is which based on expected values
            int64_t num_audio_tokens = 6562;
            int64_t hidden_size      = 768;

            // GGUF stores as (hidden_size, num_audio_tokens) = [768, 6562]
            if (dim0 == hidden_size && dim1 == num_audio_tokens) {
                // Correct: stored as (hidden_size, num_audio_tokens)
            } else if (dim0 == num_audio_tokens && dim1 == hidden_size) {
                // Stored as (num_audio_tokens, hidden_size) - need to transpose
                num_audio_tokens = dim0;
                hidden_size      = dim1;
            } else {
                LOG_ERR("TTS: emb_code.0.weight has unexpected shape [%ld, %ld], expected [768, 6562] or [6562, 768]\n",
                        dim0, dim1);
                ggml_free(ctx_meta);
                gguf_free(ctx_gguf);
                return false;
            }

            // Allocate memory and copy data
            size_t emb_code_size      = dim0 * dim1 * sizeof(float);
            ctx_omni->emb_code_weight = (float *) malloc(emb_code_size);
            if (!ctx_omni->emb_code_weight) {
                LOG_ERR("TTS: Failed to allocate memory for emb_code.0.weight\n");
                ggml_free(ctx_meta);
                gguf_free(ctx_gguf);
                return false;
            }

            // Copy/convert tensor data based on type
            enum ggml_type emb_code_type     = emb_code_tensor->type;
            int64_t        emb_code_elements = dim0 * dim1;

            if (emb_code_type == GGML_TYPE_F32) {
                // F32: direct copy
                memcpy(ctx_omni->emb_code_weight, emb_code_tensor->data, emb_code_size);
            } else if (emb_code_type == GGML_TYPE_F16) {
                // F16: convert to F32
                const ggml_fp16_t * src_f16 = (const ggml_fp16_t *) emb_code_tensor->data;
                for (int64_t i = 0; i < emb_code_elements; ++i) {
                    ctx_omni->emb_code_weight[i] = ggml_fp16_to_fp32(src_f16[i]);
                }
            } else {
                LOG_ERR("TTS: emb_code.0.weight has unsupported type: %d\n", emb_code_type);
                free(ctx_omni->emb_code_weight);
                ctx_omni->emb_code_weight = nullptr;
                ggml_free(ctx_meta);
                gguf_free(ctx_gguf);
                return false;
            }

            ctx_omni->emb_code_vocab_size           = num_audio_tokens;  // 6562
            ctx_omni->emb_code_hidden_size          = hidden_size;       // 768
            // NOTE: GGUF data is stored in row-major order, matching NumPy/PyTorch
            // Even when metadata shape is [768, 6562], the actual data layout is (6562, 768) row-major
            // So we should access as: weight[token_idx * hidden_size + j]
            // This means: emb_code_stored_as_transposed should be FALSE
            ctx_omni->emb_code_stored_as_transposed = false;  // Data is always (vocab_size, hidden_size) in memory
        } else {
            LOG_ERR("TTS: Failed to get tensor %s from GGUF context\n", emb_code_name);
            ggml_free(ctx_meta);
            gguf_free(ctx_gguf);
            return false;
        }
    } else {
        LOG_ERR("TTS: Tensor %s not found in GGUF file (this is OK if using token IDs)\n", emb_code_name);
        // Note: emb_code is optional if we use token IDs, but we prefer embeddings
    }

    // Load emb_text.weight: (vocab_size=152064, hidden_size=768)
    // PyTorch: nn.Embedding(vocab_size, hidden_size) -> weight shape is [vocab_size, hidden_size] = [152064, 768]
    // GGUF: may be stored as [hidden_size, vocab_size] = [768, 152064] (transposed)
    const char * emb_text_name = "emb_text.weight";
    int64_t      emb_text_idx  = gguf_find_tensor(ctx_gguf, emb_text_name);
    if (emb_text_idx >= 0) {
        struct ggml_tensor * emb_text_tensor = ggml_get_tensor(ctx_meta, emb_text_name);
        if (emb_text_tensor) {
            int64_t dim0 = emb_text_tensor->ne[0];
            int64_t dim1 = emb_text_tensor->ne[1];

            // Expected values
            int64_t expected_vocab_size  = 152064;
            int64_t expected_hidden_size = 768;

            // GGML tensor ç»´åº¦ç†è§£ï¼š
            // ne[0] = æœ€å†…å±‚ç»´åº¦ (stride=1) = hidden_size = 768
            // ne[1] = å¤–å±‚ç»´åº¦ = vocab_size = 152064
            // å†…å­˜å¸ƒå±€æ˜¯ row-majorï¼Œå³ [vocab_size][hidden_size]
            // æ‰€ä»¥ ne[0]=768, ne[1]=152064 æ„å‘³ç€æ•°æ®å·²ç»æ˜¯ [vocab_size, hidden_size] æ ¼å¼
            // ä¸éœ€è¦è½¬ç½®ï¼

            int64_t vocab_size, hidden_size;

            if (dim0 == expected_hidden_size && dim1 == expected_vocab_size) {
                // GGML shape: ne[0]=768, ne[1]=152064
                // è¿™æ„å‘³ç€å†…å­˜å¸ƒå±€æ˜¯ [vocab_size=152064][hidden_size=768]
                // ä¸éœ€è¦è½¬ç½®
                vocab_size  = dim1;  // 152064
                hidden_size = dim0;  // 768
            } else if (dim0 == expected_vocab_size && dim1 == expected_hidden_size) {
                // GGML shape: ne[0]=152064, ne[1]=768 (unusual)
                // è¿™æ„å‘³ç€å†…å­˜å¸ƒå±€æ˜¯ [hidden_size=768][vocab_size=152064]
                // è¿™ç§æƒ…å†µéœ€è¦è½¬ç½®
                vocab_size  = dim0;  // 152064
                hidden_size = dim1;  // 768
                LOG_ERR("TTS: emb_text.weight has unusual GGML shape, not handled\n");
                ggml_free(ctx_meta);
                gguf_free(ctx_gguf);
                return false;
            } else {
                LOG_ERR("TTS: emb_text.weight has unexpected shape [%ld, %ld], expected ne=[%ld, %ld]\n", dim0, dim1,
                        expected_hidden_size, expected_vocab_size);
                ggml_free(ctx_meta);
                gguf_free(ctx_gguf);
                return false;
            }

            // Allocate memory for the weight
            size_t emb_text_size      = vocab_size * hidden_size * sizeof(float);
            ctx_omni->emb_text_weight = (float *) malloc(emb_text_size);
            if (!ctx_omni->emb_text_weight) {
                LOG_ERR("TTS: Failed to allocate memory for emb_text.weight\n");
                ggml_free(ctx_meta);
                gguf_free(ctx_gguf);
                return false;
            }

            // Copy/convert tensor data based on type
            enum ggml_type emb_text_type     = emb_text_tensor->type;
            int64_t        emb_text_elements = vocab_size * hidden_size;

            if (emb_text_type == GGML_TYPE_F32) {
                // F32: direct copy
                memcpy(ctx_omni->emb_text_weight, emb_text_tensor->data, emb_text_size);
            } else if (emb_text_type == GGML_TYPE_F16) {
                // F16: convert to F32
                const ggml_fp16_t * src_f16 = (const ggml_fp16_t *) emb_text_tensor->data;
                for (int64_t i = 0; i < emb_text_elements; ++i) {
                    ctx_omni->emb_text_weight[i] = ggml_fp16_to_fp32(src_f16[i]);
                }
            } else {
                LOG_ERR("TTS: emb_text.weight has unsupported type: %d\n", emb_text_type);
                free(ctx_omni->emb_text_weight);
                ctx_omni->emb_text_weight = nullptr;
                ggml_free(ctx_meta);
                gguf_free(ctx_gguf);
                return false;
            }

            ctx_omni->emb_text_vocab_size  = vocab_size;   // 152064
            ctx_omni->emb_text_hidden_size = hidden_size;  // 768
        } else {
            LOG_ERR("TTS: Failed to get tensor %s from GGUF context\n", emb_text_name);
            ggml_free(ctx_meta);
            gguf_free(ctx_gguf);
            return false;
        }
    } else {
        LOG_ERR("TTS: Tensor %s not found in GGUF file\n", emb_text_name);
        ggml_free(ctx_meta);
        gguf_free(ctx_gguf);
        return false;
    }

    // Load projector_semantic weights
    const char * projector_names[] = { "projector_semantic.linear1.weight", "projector_semantic.linear1.bias",
                                       "projector_semantic.linear2.weight", "projector_semantic.linear2.bias" };

    float ** projector_ptrs[] = { &ctx_omni->projector_semantic_linear1_weight,
                                  &ctx_omni->projector_semantic_linear1_bias,
                                  &ctx_omni->projector_semantic_linear2_weight,
                                  &ctx_omni->projector_semantic_linear2_bias };

    // PyTorch nn.Linear(in_features, out_features) weight shape is (out_features, in_features)
    // GGUF may store as (out_features, in_features) or (in_features, out_features)
    // We need to detect and handle both cases
    int64_t expected_shapes_pytorch[][2] = {
        { 768, 4096 }, // linear1.weight: PyTorch shape (out_features, in_features)
        { 768, 0    }, // linear1.bias (1D)
        { 768, 768  }, // linear2.weight: PyTorch shape (out_features, in_features)
        { 768, 0    }  // linear2.bias (1D)
    };

    int64_t expected_shapes_transposed[][2] = {
        { 4096, 768 }, // linear1.weight: transposed shape (in_features, out_features)
        { 768,  0   }, // linear1.bias (1D)
        { 768,  768 }, // linear2.weight: same for square matrix
        { 768,  0   }  // linear2.bias (1D)
    };

    // Track whether weights need transposition
    bool need_transpose[2] = { false, false };  // [linear1, linear2]

    for (int i = 0; i < 4; i++) {
        int64_t tensor_idx = gguf_find_tensor(ctx_gguf, projector_names[i]);
        if (tensor_idx >= 0) {
            struct ggml_tensor * tensor = ggml_get_tensor(ctx_meta, projector_names[i]);
            if (tensor) {
                int64_t dim0 = tensor->ne[0];
                int64_t dim1 = (ggml_n_dims(tensor) > 1) ? tensor->ne[1] : 0;

                if (i % 2 == 0) {  // weight (2D)
                    // Check if stored as PyTorch shape (out_features, in_features) or transposed
                    bool is_pytorch_shape =
                        (dim0 == expected_shapes_pytorch[i][0] && dim1 == expected_shapes_pytorch[i][1]);
                    bool is_transposed_shape =
                        (dim0 == expected_shapes_transposed[i][0] && dim1 == expected_shapes_transposed[i][1]);

                    if (is_pytorch_shape) {
                        // Stored as PyTorch shape (out_features, in_features), need to transpose
                        need_transpose[i / 2] = true;
                    } else if (is_transposed_shape) {
                        // Already transposed, use directly
                        need_transpose[i / 2] = false;
                    } else {
                        LOG_ERR("TTS: %s has unexpected shape: [%ld, %ld], expected [%ld, %ld] or [%ld, %ld]\n",
                                projector_names[i], dim0, dim1, expected_shapes_pytorch[i][0],
                                expected_shapes_pytorch[i][1], expected_shapes_transposed[i][0],
                                expected_shapes_transposed[i][1]);
                        // Try to continue, assume PyTorch shape
                        need_transpose[i / 2] = true;
                    }
                } else {  // bias (1D)
                    if (dim0 != expected_shapes_pytorch[i][0] || dim1 != 0) {
                        LOG_ERR("TTS: %s has wrong shape: [%ld, %ld], expected [%ld, 0]\n", projector_names[i], dim0,
                                dim1, expected_shapes_pytorch[i][0]);
                    }
                }

                // Check tensor type for F16 conversion
                enum ggml_type proj_tensor_type = tensor->type;

                if (i % 2 == 0 && need_transpose[i / 2]) {
                    // Weight needs transposition: allocate transposed size (always F32 output)
                    int64_t in_dim          = expected_shapes_pytorch[i][1];  // PyTorch in_features
                    int64_t out_dim         = expected_shapes_pytorch[i][0];  // PyTorch out_features
                    size_t  transposed_size = in_dim * out_dim * sizeof(float);
                    *projector_ptrs[i]      = (float *) malloc(transposed_size);
                    if (!*projector_ptrs[i]) {
                        LOG_ERR("TTS: Failed to allocate memory for transposed %s\n", projector_names[i]);
                        // Clean up
                        for (int j = 0; j < i; j++) {
                            if (*projector_ptrs[j]) {
                                free(*projector_ptrs[j]);
                                *projector_ptrs[j] = nullptr;
                            }
                        }
                        ggml_free(ctx_meta);
                        gguf_free(ctx_gguf);
                        return false;
                    }

                    // Transpose: src[out_dim][in_dim] -> dst[in_dim][out_dim], handling F16 if needed
                    float * dst_data = *projector_ptrs[i];
                    if (proj_tensor_type == GGML_TYPE_F32) {
                        const float * src_data = (const float *) tensor->data;
                        for (int64_t out = 0; out < out_dim; out++) {
                            for (int64_t in = 0; in < in_dim; in++) {
                                dst_data[in * out_dim + out] = src_data[out * in_dim + in];
                            }
                        }
                    } else if (proj_tensor_type == GGML_TYPE_F16) {
                        const ggml_fp16_t * src_data = (const ggml_fp16_t *) tensor->data;
                        for (int64_t out = 0; out < out_dim; out++) {
                            for (int64_t in = 0; in < in_dim; in++) {
                                dst_data[in * out_dim + out] = ggml_fp16_to_fp32(src_data[out * in_dim + in]);
                            }
                        }
                    } else {
                        LOG_ERR("TTS: %s has unsupported type: %d\n", projector_names[i], proj_tensor_type);
                        free(*projector_ptrs[i]);
                        *projector_ptrs[i] = nullptr;
                        ggml_free(ctx_meta);
                        gguf_free(ctx_gguf);
                        return false;
                    }
                } else {
                    // Direct copy (bias or already transposed weight), handle F16
                    int64_t num_elements = (dim1 > 0) ? dim0 * dim1 : dim0;
                    size_t  output_size  = num_elements * sizeof(float);
                    *projector_ptrs[i]   = (float *) malloc(output_size);
                    if (!*projector_ptrs[i]) {
                        LOG_ERR("TTS: Failed to allocate memory for %s\n", projector_names[i]);
                        // Clean up
                        for (int j = 0; j < i; j++) {
                            if (*projector_ptrs[j]) {
                                free(*projector_ptrs[j]);
                                *projector_ptrs[j] = nullptr;
                            }
                        }
                        ggml_free(ctx_meta);
                        gguf_free(ctx_gguf);
                        return false;
                    }

                    if (proj_tensor_type == GGML_TYPE_F32) {
                        memcpy(*projector_ptrs[i], tensor->data, output_size);
                    } else if (proj_tensor_type == GGML_TYPE_F16) {
                        const ggml_fp16_t * src_f16 = (const ggml_fp16_t *) tensor->data;
                        for (int64_t k = 0; k < num_elements; ++k) {
                            (*projector_ptrs[i])[k] = ggml_fp16_to_fp32(src_f16[k]);
                        }
                    } else {
                        LOG_ERR("TTS: %s has unsupported type: %d\n", projector_names[i], proj_tensor_type);
                        free(*projector_ptrs[i]);
                        *projector_ptrs[i] = nullptr;
                        ggml_free(ctx_meta);
                        gguf_free(ctx_gguf);
                        return false;
                    }
                    if (dim1 > 0) {
                    }
                }
            } else {
                LOG_ERR("TTS: Failed to get tensor %s from GGUF context\n", projector_names[i]);
                // Clean up
                for (int j = 0; j < i; j++) {
                    if (*projector_ptrs[j]) {
                        free(*projector_ptrs[j]);
                        *projector_ptrs[j] = nullptr;
                    }
                }
                ggml_free(ctx_meta);
                gguf_free(ctx_gguf);
                return false;
            }
        } else {
            LOG_ERR("TTS: Tensor %s not found in GGUF file\n", projector_names[i]);
            // Clean up
            for (int j = 0; j < i; j++) {
                if (*projector_ptrs[j]) {
                    free(*projector_ptrs[j]);
                    *projector_ptrs[j] = nullptr;
                }
            }
            ggml_free(ctx_meta);
            gguf_free(ctx_gguf);
            return false;
        }
    }

    // Set projector dimensions
    ctx_omni->projector_semantic_input_dim  = 4096;
    ctx_omni->projector_semantic_output_dim = 768;

    // Load head_code.weight: (hidden_size=768, num_audio_tokens=6562)
    // Note: num_vq=1, so we only load head_code.0.weight
    const char * head_code_name = "head_code.0.weight";
    int64_t      head_code_idx  = gguf_find_tensor(ctx_gguf, head_code_name);
    if (head_code_idx >= 0) {
        struct ggml_tensor * head_code_tensor = ggml_get_tensor(ctx_meta, head_code_name);
        if (head_code_tensor) {
            // head_code is Linear(hidden_size, num_audio_tokens, bias=False)
            // In PyTorch: weight shape is (num_audio_tokens, hidden_size) = [6562, 768]
            // In GGUF: stored as (hidden_size, num_audio_tokens) = [768, 6562] (already transposed)
            int64_t dim0 = head_code_tensor->ne[0];
            int64_t dim1 = (ggml_n_dims(head_code_tensor) > 1) ? head_code_tensor->ne[1] : 0;

            // Expected shape in GGUF: (hidden_size=768, num_audio_tokens=6562)
            int64_t expected_hidden_size      = 768;
            int64_t expected_num_audio_tokens = 6562;

            // Allocate memory for weight: (hidden_size, num_audio_tokens) = [768, 6562]
            size_t head_code_size      = expected_hidden_size * expected_num_audio_tokens * sizeof(float);
            ctx_omni->head_code_weight = (float *) malloc(head_code_size);
            if (!ctx_omni->head_code_weight) {
                LOG_ERR("TTS: Failed to allocate memory for head_code.0.weight\n");
                // Clean up already loaded weights
                if (ctx_omni->emb_text_weight) {
                    free(ctx_omni->emb_text_weight);
                    ctx_omni->emb_text_weight = nullptr;
                }
                for (int j = 0; j < 4; j++) {
                    if (*projector_ptrs[j]) {
                        free(*projector_ptrs[j]);
                        *projector_ptrs[j] = nullptr;
                    }
                }
                ggml_free(ctx_meta);
                gguf_free(ctx_gguf);
                return false;
            }

            // CRITICAL FIX: The conversion script transposes head_code weight to [768, 6562] before saving,
            // but the GGUF metadata shape may still be [6562, 768] due to how add_tensor works.
            // We need to detect the actual data format by testing both layouts.
            //
            // Strategy: Try both formats and see which one produces correct logits.
            // But a simpler approach: Since the conversion script always transposes to [768, 6562],
            // and the actual data is stored in that format, we should always use the data as-is
            // (treating it as [768, 6562]) regardless of metadata shape.
            //
            // However, if metadata says [6562, 768], it might be an old conversion that didn't transpose.
            // We'll use a heuristic: check if the first few values match what we expect.

            const float * src_data       = (const float *) head_code_tensor->data;
            bool          need_transpose = false;

            // CRITICAL FIX: Based on conversion script analysis, the script always transposes
            // head_code to [768, 6562] before saving. So the actual data is always [768, 6562],
            // regardless of metadata shape. We should NOT transpose based on metadata.
            //
            // However, if metadata says [6562, 768], it might be an old conversion that didn't transpose.
            // We'll use a simple heuristic: if metadata says [6562, 768], assume data needs transpose.
            // If metadata says [768, 6562], assume data is already correct.

            if (dim0 == expected_hidden_size && dim1 == expected_num_audio_tokens) {
                // Metadata says (768, 6562) - data should already be in correct format
                need_transpose = false;
            } else if (dim0 == expected_num_audio_tokens && dim1 == expected_hidden_size) {
                // Metadata says (6562, 768) - but conversion script may have already transposed the data
                // We need to check: if conversion script transposed, data is actually [768, 6562] and we should NOT transpose
                // If conversion script didn't transpose, data is [6562, 768] and we SHOULD transpose
                //
                // Since the conversion script ALWAYS transposes (line 351: W_transposed = W.T),
                // the data is always [768, 6562] regardless of metadata.
                // So we should NOT transpose.
                need_transpose = false;  // CRITICAL FIX: Don't transpose, data is already [768, 6562]
            } else {
                LOG_ERR("TTS: head_code.0.weight has unexpected shape [%ld, %ld], expected [%d, %d] or [%d, %d]\n",
                        dim0, dim1, expected_hidden_size, expected_num_audio_tokens, expected_num_audio_tokens,
                        expected_hidden_size);
                // Clean up
                free(ctx_omni->head_code_weight);
                ctx_omni->head_code_weight = nullptr;
                if (ctx_omni->emb_text_weight) {
                    free(ctx_omni->emb_text_weight);
                    ctx_omni->emb_text_weight = nullptr;
                }
                for (int j = 0; j < 4; j++) {
                    if (*projector_ptrs[j]) {
                        free(*projector_ptrs[j]);
                        *projector_ptrs[j] = nullptr;
                    }
                }
                ggml_free(ctx_meta);
                gguf_free(ctx_gguf);
                return false;
            }

            // Check tensor type and copy/convert accordingly
            // âš¡ ä¼˜åŒ–ï¼šè½¬ç½®å­˜å‚¨ä¸º [6562, 768]ï¼Œä½¿æ¯ä¸ªoutput tokençš„æƒé‡è¿ç»­å­˜å‚¨
            // è¿™æ ·åœ¨è®¡ç®—logitsæ—¶å¯ä»¥ç”¨é«˜æ•ˆçš„å‘é‡ç‚¹ç§¯
            // åŸå§‹: weight[j * 6562 + i] = W[j, i]  (j=hidden, i=output)
            // è½¬ç½®å: weight[i * 768 + j] = W[i, j] (i=output, j=hidden)
            enum ggml_type tensor_type    = head_code_tensor->type;
            int64_t        total_elements = expected_hidden_size * expected_num_audio_tokens;

            print_with_timestamp("TTS: head_code shape: dim0=%ld, dim1=%ld, will transpose to [%ld, %ld]\n", dim0, dim1,
                                 expected_num_audio_tokens, expected_hidden_size);

            if (tensor_type == GGML_TYPE_F32) {
                // F32: copy with transpose from [768, 6562] to [6562, 768]
                for (int64_t i = 0; i < expected_num_audio_tokens; ++i) {
                    for (int64_t j = 0; j < expected_hidden_size; ++j) {
                        // src: [j * 6562 + i], dst: [i * 768 + j]
                        ctx_omni->head_code_weight[i * expected_hidden_size + j] =
                            src_data[j * expected_num_audio_tokens + i];
                    }
                }
            } else if (tensor_type == GGML_TYPE_F16) {
                // F16: convert to F32 with transpose
                const ggml_fp16_t * src_f16 = (const ggml_fp16_t *) src_data;
                for (int64_t i = 0; i < expected_num_audio_tokens; ++i) {
                    for (int64_t j = 0; j < expected_hidden_size; ++j) {
                        ctx_omni->head_code_weight[i * expected_hidden_size + j] =
                            ggml_fp16_to_fp32(src_f16[j * expected_num_audio_tokens + i]);
                    }
                }
            } else {
                LOG_ERR("TTS: head_code.0.weight has unsupported type: %d\n", tensor_type);
                free(ctx_omni->head_code_weight);
                ctx_omni->head_code_weight = nullptr;
                ggml_free(ctx_meta);
                gguf_free(ctx_gguf);
                return false;
            }

            ctx_omni->head_code_hidden_size      = expected_hidden_size;
            ctx_omni->head_code_num_audio_tokens = expected_num_audio_tokens;

            // ğŸ” è°ƒè¯•ï¼šéªŒè¯åŠ è½½çš„æ•°æ®
            // Python weight[0, 0:5] = [0.01385498, -0.01647949, 0.0111084, -0.01367188, -0.01141357]
            // C++ head_code_weight[0..4] åº”è¯¥å’Œ Python ä¸€è‡´
            print_with_timestamp("TTS: head_code loaded, verifying first few values:\n");
            print_with_timestamp("  head_code_weight[0] = %.8f (expect ~0.01385498)\n", ctx_omni->head_code_weight[0]);
            print_with_timestamp("  head_code_weight[1] = %.8f (expect ~-0.01647949)\n", ctx_omni->head_code_weight[1]);
            print_with_timestamp("  head_code_weight[768] = %.8f (this is weight[1, 0], expect ~0.04150391)\n",
                                 ctx_omni->head_code_weight[768]);
        } else {
            LOG_ERR("TTS: Failed to get tensor %s from GGUF context\n", head_code_name);
            // Clean up
            if (ctx_omni->emb_text_weight) {
                free(ctx_omni->emb_text_weight);
                ctx_omni->emb_text_weight = nullptr;
            }
            for (int j = 0; j < 4; j++) {
                if (*projector_ptrs[j]) {
                    free(*projector_ptrs[j]);
                    *projector_ptrs[j] = nullptr;
                }
            }
            ggml_free(ctx_meta);
            gguf_free(ctx_gguf);
            return false;
        }
    } else {
        LOG_ERR("TTS: Tensor %s not found in GGUF file\n", head_code_name);
        // Clean up
        if (ctx_omni->emb_text_weight) {
            free(ctx_omni->emb_text_weight);
            ctx_omni->emb_text_weight = nullptr;
        }
        for (int j = 0; j < 4; j++) {
            if (*projector_ptrs[j]) {
                free(*projector_ptrs[j]);
                *projector_ptrs[j] = nullptr;
            }
        }
        ggml_free(ctx_meta);
        gguf_free(ctx_gguf);
        return false;
    }

    ggml_free(ctx_meta);
    gguf_free(ctx_gguf);
    return true;
}

// TODO: å®ç°TTSçš„emb_textå±‚è°ƒç”¨
// åŠŸèƒ½ï¼šå°†token IDè½¬æ¢ä¸ºembedding
// è¾“å…¥ï¼štoken_id (llama_token), TTSæ¨¡å‹ä¸Šä¸‹æ–‡
// è¾“å‡ºï¼šembeddingå‘é‡ (float*, å¤§å°ä¸ºtts_n_embd)
// å®ç°æ–¹å¼ï¼š
//   1. ä»TTSæ¨¡å‹æ–‡ä»¶ä¸­åŠ è½½emb_textæƒé‡ï¼ˆ152064 x 768ï¼‰
//      - åœ¨omni_initä¸­åŠ è½½emb_textæƒé‡åˆ°ctx_omniä¸­
//      - æƒé‡åç§°ï¼šæ ¹æ®GGUFæ ¼å¼ï¼Œå¯èƒ½æ˜¯"tts.emb_text.weight"æˆ–ç±»ä¼¼
//   2. æŸ¥æ‰¾ï¼šembedding = emb_text_weight[token_id]
//   3. è¿”å›embeddingå‘é‡
// æ³¨æ„ï¼šéœ€è¦ç¡®ä¿token_idåœ¨[0, 152064)èŒƒå›´å†…
//
// å®ç°æ­¥éª¤ï¼š
// 1. åœ¨omni_contextä¸­æ·»åŠ emb_text_weightå­—æ®µï¼ˆfloat*, 152064 * 768ï¼‰
// 2. åœ¨omni_initä¸­ä»TTSæ¨¡å‹æ–‡ä»¶åŠ è½½emb_textæƒé‡
// 3. åœ¨è¿™é‡Œå®ç°æŸ¥æ‰¾é€»è¾‘
static bool tts_emb_text(struct omni_context * ctx_omni, llama_token token_id, float * embedding_out, int tts_n_embd) {
    // Check if weights are loaded
    if (!ctx_omni->emb_text_weight) {
        LOG_ERR("TTS: emb_text_weight not loaded\n");
        return false;
    }

    // Check token_id range
    if (token_id < 0 || token_id >= ctx_omni->emb_text_vocab_size) {
        LOG_ERR("TTS: token_id %d out of range [0, %d)\n", token_id, ctx_omni->emb_text_vocab_size);
        return false;
    }

    // Check embedding dimension
    if (tts_n_embd != ctx_omni->emb_text_hidden_size) {
        LOG_ERR("TTS: tts_n_embd (%d) != emb_text_hidden_size (%d)\n", tts_n_embd, ctx_omni->emb_text_hidden_size);
        return false;
    }

    // Copy embedding: embedding_out = emb_text_weight[token_id]
    const float * src = ctx_omni->emb_text_weight + token_id * tts_n_embd;
    memcpy(embedding_out, src, tts_n_embd * sizeof(float));

    return true;
}

// TTSçš„projector_semanticå±‚å®ç°
// åŠŸèƒ½ï¼šå°†LLM hidden statesï¼ˆ4096ç»´ï¼‰æŠ•å½±åˆ°TTS hidden_dimï¼ˆ768ç»´ï¼‰
// è¾“å…¥ï¼šllm_hidden_states (float*, n_tokens * 4096), n_tokens, llm_n_embd (4096)
// è¾“å‡ºï¼šprojected_hidden_states (float*, n_tokens * 768), tts_n_embd (768)
//
// æƒé‡å­˜å‚¨æ ¼å¼ï¼š
//   - PyTorch nn.Linear(in_features, out_features)çš„æƒé‡å½¢çŠ¶æ˜¯(out_features, in_features)
//   - GGUFå¯èƒ½å­˜å‚¨ä¸º(out_features, in_features)æˆ–(in_features, out_features)
//   - åŠ è½½æ—¶ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶è½¬ç½®ä¸º(in_features, out_features)æ ¼å¼ä»¥ä¾¿çŸ©é˜µä¹˜æ³•
//   - linear1_weight: è½¬ç½®åå­˜å‚¨ä¸º(4096, 768) - å­˜å‚¨åœ¨ctx_omni->projector_semantic_linear1_weight
//   - linear1_bias: (768,) - å­˜å‚¨åœ¨ctx_omni->projector_semantic_linear1_bias
//   - linear2_weight: (768, 768) - å­˜å‚¨åœ¨ctx_omni->projector_semantic_linear2_weight
//   - linear2_bias: (768,) - å­˜å‚¨åœ¨ctx_omni->projector_semantic_linear2_bias
//
// çŸ©é˜µä¹˜æ³•å®ç°ï¼š
//   å¯¹æ¯ä¸ªtokençš„hidden stateï¼š
//     hidden_proj = ReLU(linear1(hidden) + bias1)  // (1, 4096) @ (4096, 768) = (1, 768)
//     hidden_proj = linear2(hidden_proj) + bias2    // (1, 768) @ (768, 768) = (1, 768)
//   å½’ä¸€åŒ–åœ¨è°ƒç”¨è€…ä¸­å®Œæˆï¼ˆä½¿ç”¨normalize_l2_per_tokenï¼‰
static bool tts_projector_semantic(struct omni_context * ctx_omni,
                                   const float *         llm_hidden_states,
                                   int                   n_tokens,
                                   int                   llm_n_embd,
                                   float *               projected_hidden_states,
                                   int                   tts_n_embd) {
    // ä¼˜å…ˆä½¿ç”¨æ–°çš„ ggml å®ç° (ç²¾åº¦éªŒè¯ç‰ˆæœ¬)
    if (ctx_omni->projector.initialized) {
        // æ£€æŸ¥ç»´åº¦
        if (llm_n_embd != ctx_omni->projector.hparams.in_dim) {
            LOG_ERR("TTS: llm_n_embd (%d) != projector in_dim (%d)\n", llm_n_embd, ctx_omni->projector.hparams.in_dim);
            return false;
        }
        if (tts_n_embd != ctx_omni->projector.hparams.out_dim) {
            LOG_ERR("TTS: tts_n_embd (%d) != projector out_dim (%d)\n", tts_n_embd,
                    ctx_omni->projector.hparams.out_dim);
            return false;
        }

        // ä½¿ç”¨ ggml åç«¯è®¡ç®—
        std::vector<float> result = projector_forward(ctx_omni->projector, llm_hidden_states, n_tokens);
        if (result.empty()) {
            LOG_ERR("TTS: projector_forward failed\n");
            return false;
        }

        // å¤åˆ¶ç»“æœ
        memcpy(projected_hidden_states, result.data(), n_tokens * tts_n_embd * sizeof(float));
        return true;
    }

    // Fallback: ä½¿ç”¨æ—§çš„ float* æƒé‡å®ç°
    // Check if weights are loaded
    if (!ctx_omni->projector_semantic_linear1_weight || !ctx_omni->projector_semantic_linear1_bias ||
        !ctx_omni->projector_semantic_linear2_weight || !ctx_omni->projector_semantic_linear2_bias) {
        LOG_ERR("TTS: projector_semantic weights not loaded (both ggml and legacy)\n");
        return false;
    }

    // Check dimensions
    if (llm_n_embd != ctx_omni->projector_semantic_input_dim) {
        LOG_ERR("TTS: llm_n_embd (%d) != projector_semantic_input_dim (%d)\n", llm_n_embd,
                ctx_omni->projector_semantic_input_dim);
        return false;
    }

    if (tts_n_embd != ctx_omni->projector_semantic_output_dim) {
        LOG_ERR("TTS: tts_n_embd (%d) != projector_semantic_output_dim (%d)\n", tts_n_embd,
                ctx_omni->projector_semantic_output_dim);
        return false;
    }

    const int input_dim  = ctx_omni->projector_semantic_input_dim;   // 4096
    const int output_dim = ctx_omni->projector_semantic_output_dim;  // 768

    // Process each token (legacy CPU implementation)
    for (int t = 0; t < n_tokens; t++) {
        const float * hidden = llm_hidden_states + t * input_dim;
        float *       output = projected_hidden_states + t * output_dim;

        // Temporary buffer for intermediate results
        std::vector<float> temp(output_dim);

        // Step 1: linear1: temp = hidden @ linear1_weight + linear1_bias
        for (int j = 0; j < output_dim; j++) {
            float sum = ctx_omni->projector_semantic_linear1_bias[j];
            for (int i = 0; i < input_dim; i++) {
                sum += hidden[i] * ctx_omni->projector_semantic_linear1_weight[i * output_dim + j];
            }
            temp[j] = sum;
        }

        // Step 2: ReLU activation
        for (int j = 0; j < output_dim; j++) {
            temp[j] = (temp[j] > 0.0f) ? temp[j] : 0.0f;
        }

        // Step 3: linear2: output = temp @ linear2_weight + linear2_bias
        for (int j = 0; j < output_dim; j++) {
            float sum = ctx_omni->projector_semantic_linear2_bias[j];
            for (int i = 0; i < output_dim; i++) {
                sum += temp[i] * ctx_omni->projector_semantic_linear2_weight[i * output_dim + j];
            }
            output[j] = sum;
        }
    }

    return true;
}

// è¾…åŠ©å‡½æ•°ï¼šL2å½’ä¸€åŒ–ï¼ˆå¯¹æ¯ä¸ªtokençš„embeddingåˆ†åˆ«å½’ä¸€åŒ–ï¼‰
// åŒ¹é…Pythonçš„ F.normalize(hidden_embeds, p=2, dim=-1)
// æ³¨æ„ï¼šPyTorchçš„F.normalizeä½¿ç”¨sqrt(sum(x^2) + eps)ï¼Œç„¶åé™¤ä»¥norm
static void normalize_l2_per_token(float * embeddings, int n_tokens, int n_embd, float eps = 1e-8f) {
    for (int t = 0; t < n_tokens; t++) {
        float * vec = embeddings + t * n_embd;

        // Calculate L2 norm (matching PyTorch: sqrt(sum(x^2) + eps))
        float norm_sq = 0.0f;
        for (int i = 0; i < n_embd; i++) {
            float val = vec[i];
            norm_sq += val * val;
        }
        // PyTorch F.normalize: norm = sqrt(sum(x^2) + eps), then x = x / norm
        float norm = std::sqrt(norm_sq + eps);

        // Normalize: divide by norm (matching PyTorch F.normalize with p=2, dim=-1)
        // CRITICAL: Always normalize, even if norm is very small (eps ensures norm > 0)
        if (norm > 0.0f) {
            float inv_norm = 1.0f / norm;
            for (int i = 0; i < n_embd; i++) {
                vec[i] *= inv_norm;
            }
        } else {
            // If norm is zero (shouldn't happen), set to unit vector
            LOG_WRN("TTS: WARNING - zero norm detected for token %d, setting to unit vector\n", t);
            float inv_sqrt_n = 1.0f / std::sqrt((float) n_embd);
            for (int i = 0; i < n_embd; i++) {
                vec[i] = inv_sqrt_n;
            }
        }

        // Verify normalization (always check to catch bugs)
        float verify_norm_sq = 0.0f;
        for (int i = 0; i < n_embd; i++) {
            float val = vec[i];
            verify_norm_sq += val * val;
        }
        float verify_norm = std::sqrt(verify_norm_sq);
        if (std::abs(verify_norm - 1.0f) > 0.01f) {
            LOG_ERR(
                "TTS: ERROR - normalization verification failed for token %d: norm=%.6f (expected ~1.0), "
                "norm_sq=%.6f\n",
                t, verify_norm, verify_norm_sq);
        }
    }
}

static bool eval_tokens_tts(struct omni_context *    ctx_omni,
                            common_params *          params,
                            std::vector<llama_token> tokens,
                            int                      n_batch,
                            int *                    n_past_tts) {
    fflush(stdout);
    int N = (int) tokens.size();
    fflush(stdout);
    // Note: TTS model might need different KV cache management
    // For now, we'll use a simple approach similar to LLM
    fflush(stdout);
    fflush(stdout);
    for (int i = 0; i < N; i += n_batch) {
        fflush(stdout);
        int n_eval = (int) tokens.size() - i;
        fflush(stdout);
        if (n_eval > n_batch) {
            n_eval = n_batch;
            fflush(stdout);
        }
        if (n_eval == 0) {
            fflush(stdout);
            break;
        }
        fflush(stdout);

        // Use llama_batch_get_one and manually set pos
        // Note: llama_batch_get_one may return batch with nullptr pos, so we need to handle it
        llama_batch batch = llama_batch_get_one(&tokens[i], n_eval);
        fflush(stdout);

        // If batch.pos is nullptr, we need to allocate it
        std::vector<llama_pos> pos_vec;
        if (batch.pos == nullptr) {
            fflush(stdout);
            pos_vec.resize(n_eval);
            batch.pos = pos_vec.data();
        }

        // Set pos values to ensure correct KV cache position
        for (int j = 0; j < n_eval; j++) {
            batch.pos[j] = *n_past_tts + j;
        }
        fflush(stdout);

        // Enable embeddings output for TTS model (needed for head_code logits calculation)
        llama_set_embeddings(ctx_omni->ctx_tts_llama, true);
        fflush(stdout);
        int decode_ret = llama_decode(ctx_omni->ctx_tts_llama, batch);

        // Keep embeddings enabled for sample_tts_token to use

        if (decode_ret != 0) {
            LOG_ERR("%s : failed to eval TTS tokens. token %d/%d (batch size %d, n_past %d), decode_ret=%d\n", __func__,
                    i, N, n_batch, *n_past_tts, decode_ret);
            return false;
        }
        *n_past_tts += n_eval;
    }
    return true;
}

static bool eval_string_tts(struct omni_context * ctx_omni,
                            common_params *       params,
                            const char *          str,
                            int                   n_batch,
                            int *                 n_past_tts,
                            bool                  add_bos) {
    std::string              str2     = str;
    std::vector<llama_token> embd_inp = common_tokenize(ctx_omni->ctx_tts_llama, str2, add_bos, true);
    return eval_tokens_tts(ctx_omni, params, embd_inp, n_batch, n_past_tts);
}

// ä½¿ç”¨embeddingä½œä¸ºTTSè¾“å…¥çš„prefillå‡½æ•°ï¼ˆç±»ä¼¼prefill_with_embï¼Œä½†é’ˆå¯¹TTSæ¨¡å‹ï¼‰
bool prefill_with_emb_tts(struct omni_context * ctx_omni,
                          common_params *       params,
                          float *               embed,
                          int                   n_pos,
                          int                   n_batch,
                          int *                 n_past_tts) {
    // ğŸ”§ [å®‰å…¨æ£€æŸ¥] éªŒè¯è¾“å…¥å‚æ•°
    if (n_pos <= 0) {
        LOG_ERR("%s: invalid n_pos=%d, skipping\n", __func__, n_pos);
        return false;
    }
    if (n_pos > 10000) {
        LOG_ERR("%s: n_pos=%d seems too large, likely data corruption\n", __func__, n_pos);
        return false;
    }
    if (!ctx_omni->ctx_tts_llama || !ctx_omni->model_tts) {
        LOG_ERR("%s: TTS model not loaded\n", __func__);
        return false;
    }

    int n_embd = llama_n_embd(llama_get_model(ctx_omni->ctx_tts_llama));

    // ğŸ”§ [å®‰å…¨æ£€æŸ¥] éªŒè¯ n_embd æ˜¯åˆç†å€¼
    if (n_embd <= 0 || n_embd > 10000) {
        LOG_ERR("%s: invalid n_embd=%d from TTS model, likely model corruption\n", __func__, n_embd);
        return false;
    }

    // ğŸ”§ [å®‰å…¨æ£€æŸ¥] æ£€æŸ¥ä¹˜æ³•æº¢å‡º
    if (n_pos > (INT_MAX / n_embd)) {
        LOG_ERR("%s: n_pos=%d * n_embd=%d would overflow\n", __func__, n_pos, n_embd);
        return false;
    }

    // Save condition embeddings for first audio token re-forward (if not already saved)
    // This is needed to match Python's behavior: first audio token re-forwards the condition
    if (!ctx_omni->tts_condition_saved && n_pos > 0) {
        ctx_omni->tts_condition_embeddings.resize(n_pos * n_embd);
        std::memcpy(ctx_omni->tts_condition_embeddings.data(), embed, n_pos * n_embd * sizeof(float));
        ctx_omni->tts_condition_length = n_pos;
        ctx_omni->tts_condition_n_embd = n_embd;
        ctx_omni->tts_condition_saved  = true;
    }

    // Save the starting position before the loop
    int text_start_pos = *n_past_tts;

    // Check if we need to save all hidden states (for alignment testing)
    const char * save_hidden_states_dir = getenv("TTS_SAVE_HIDDEN_STATES_DIR");
    bool         save_all_hidden_states = (save_hidden_states_dir != nullptr);

    for (int i = 0; i < n_pos; i += n_batch) {
        int n_eval = n_pos - i;
        if (n_eval > n_batch) {
            n_eval = n_batch;
        }

        llama_batch batch = {};
        batch.n_tokens    = int32_t(n_eval);
        batch.embd        = (embed + i * n_embd);  // ä½¿ç”¨embeddingä½œä¸ºè¾“å…¥

        // è®¾ç½®poså€¼ä»¥ç¡®ä¿æ­£ç¡®çš„KV cacheä½ç½®
        // Python: pos_ids = torch.arange(text_start_pos, text_start_pos + condition_length)
        // C++: batch.pos[j] = text_start_pos + i + j (where i is the offset within the current batch)
        std::vector<llama_pos> pos_vec(n_eval);
        batch.pos = pos_vec.data();
        for (int j = 0; j < n_eval; j++) {
            batch.pos[j] = text_start_pos + i + j;  // Fix: use text_start_pos + i + j instead of *n_past_tts + j
        }

        // Enable embeddings output for TTS model (needed for head_code logits calculation)
        llama_set_embeddings(ctx_omni->ctx_tts_llama, true);

        if (llama_decode(ctx_omni->ctx_tts_llama, batch)) {
            LOG_ERR("%s : failed to eval TTS embeddings. pos %d/%d (batch size %d, n_past %d)\n", __func__, i, n_pos,
                    n_batch, *n_past_tts);
            llama_set_embeddings(ctx_omni->ctx_tts_llama, false);
            return false;
        }

        // Save hidden states for each token in the batch (for alignment testing)
        // Note: llama_get_embeddings_ith uses negative indices relative to the end of the batch
        // For a batch of n_eval tokens: -1 is last, -2 is second-to-last, ..., -n_eval is first
        if (save_all_hidden_states) {
            for (int j = 0; j < n_eval; j++) {
                int           token_idx    = text_start_pos + i + j;
                // Get j-th token in current batch: j=0 -> -n_eval (first), j=n_eval-1 -> -1 (last)
                int           llama_idx    = j - n_eval;
                const float * hidden_state = llama_get_embeddings_ith(ctx_omni->ctx_tts_llama, llama_idx);
                if (hidden_state) {
                    char filepath[512];
                    snprintf(filepath, sizeof(filepath), "%s/hidden_states_%03d.bin", save_hidden_states_dir,
                             token_idx);
                    FILE * f = fopen(filepath, "wb");
                    if (f) {
                        fwrite(&token_idx, sizeof(int32_t), 1, f);
                        fwrite(&n_embd, sizeof(int32_t), 1, f);
                        fwrite(hidden_state, sizeof(float), n_embd, f);
                        fclose(f);
                    }
                } else {
                    LOG_WRN("TTS: Failed to get hidden state for token %d (llama_idx=%d)\n", token_idx, llama_idx);
                }
            }
        }

        // Keep embeddings enabled for sample_tts_token to use
    }

    // Update n_past_tts after all tokens are processed
    *n_past_tts = text_start_pos + n_pos;

    return true;
}

// Save logits to file for Python comparison
static void save_logits_to_file(const char * filepath, const float * logits, int num_tokens, int token_index) {
    char full_path[512];
    snprintf(full_path, sizeof(full_path), "%s/logits_%03d.bin", filepath, token_index);

    FILE * f = fopen(full_path, "wb");
    if (!f) {
        LOG_ERR("Failed to open logits file for writing: %s\n", full_path);
        return;
    }

    // Write: token_index (int32), num_tokens (int32), logits (float32 array)
    fwrite(&token_index, sizeof(int32_t), 1, f);
    fwrite(&num_tokens, sizeof(int32_t), 1, f);
    fwrite(logits, sizeof(float), num_tokens, f);
    fclose(f);
}

// Save hidden states to file for Python comparison
static void save_hidden_states_to_file(const char *  filepath,
                                       const float * hidden_states,
                                       int           hidden_size,
                                       int           token_index) {
    char full_path[512];
    snprintf(full_path, sizeof(full_path), "%s/hidden_states_%03d.bin", filepath, token_index);

    FILE * f = fopen(full_path, "wb");
    if (!f) {
        LOG_ERR("Failed to open hidden states file for writing: %s\n", full_path);
        return;
    }

    // Write: token_index (int32), hidden_size (int32), hidden_states (float32 array)
    fwrite(&token_index, sizeof(int32_t), 1, f);
    fwrite(&hidden_size, sizeof(int32_t), 1, f);
    fwrite(hidden_states, sizeof(float), hidden_size, f);
    fclose(f);
}

// ========== RAS (Repetition Aware Sampling) Implementation ==========
// Ported from Python: tts_streaming_generate.py
// Key idea: Use nucleus sampling (top_p + top_k), but if too many recent tokens repeat,
// fall back to random sampling to break the pattern.

// Nucleus sampling (top-p + top-k)
// Returns a sampled token index from the logits
static int nucleus_sampling_tts(const float * logits, int num_tokens, float top_p, int top_k, std::mt19937 & rng) {
    // 1. Compute softmax probabilities
    float max_logit = logits[0];
    for (int i = 1; i < num_tokens; ++i) {
        if (logits[i] > max_logit) {
            max_logit = logits[i];
        }
    }

    std::vector<float> probs(num_tokens);
    float              sum = 0.0f;
    for (int i = 0; i < num_tokens; ++i) {
        probs[i] = expf(logits[i] - max_logit);
        sum += probs[i];
    }
    for (int i = 0; i < num_tokens; ++i) {
        probs[i] /= sum;
    }

    // 2. Sort by probability descending
    std::vector<std::pair<float, int>> sorted_probs;
    sorted_probs.reserve(num_tokens);
    for (int i = 0; i < num_tokens; ++i) {
        sorted_probs.push_back({ probs[i], i });
    }
    std::sort(sorted_probs.begin(), sorted_probs.end(),
              [](const auto & a, const auto & b) { return a.first > b.first; });

    // 3. Collect tokens within top_p and top_k
    std::vector<float> filtered_probs;
    std::vector<int>   filtered_indices;
    float              cum_prob = 0.0f;

    for (const auto & p : sorted_probs) {
        if (cum_prob < top_p && (int) filtered_probs.size() < top_k) {
            cum_prob += p.first;
            filtered_probs.push_back(p.first);
            filtered_indices.push_back(p.second);
        } else {
            break;
        }
    }

    // 4. Renormalize filtered probs
    float filtered_sum = 0.0f;
    for (float p : filtered_probs) {
        filtered_sum += p;
    }
    for (float & p : filtered_probs) {
        p /= filtered_sum;
    }

    // 5. Multinomial sampling
    std::uniform_real_distribution<float> dist(0.0f, 1.0f);
    float                                 r   = dist(rng);
    float                                 cum = 0.0f;
    for (size_t i = 0; i < filtered_probs.size(); ++i) {
        cum += filtered_probs[i];
        if (r <= cum) {
            return filtered_indices[i];
        }
    }
    return filtered_indices.back();  // Fallback
}

// Random sampling (uniform multinomial from all tokens)
static int random_sampling_tts(const float * logits, int num_tokens, std::mt19937 & rng) {
    // 1. Compute softmax probabilities
    float max_logit = logits[0];
    for (int i = 1; i < num_tokens; ++i) {
        if (logits[i] > max_logit) {
            max_logit = logits[i];
        }
    }

    std::vector<float> probs(num_tokens);
    float              sum = 0.0f;
    for (int i = 0; i < num_tokens; ++i) {
        probs[i] = expf(logits[i] - max_logit);
        sum += probs[i];
    }
    for (int i = 0; i < num_tokens; ++i) {
        probs[i] /= sum;
    }

    // 2. Multinomial sampling
    std::uniform_real_distribution<float> dist(0.0f, 1.0f);
    float                                 r   = dist(rng);
    float                                 cum = 0.0f;
    for (int i = 0; i < num_tokens; ++i) {
        cum += probs[i];
        if (r <= cum) {
            return i;
        }
    }
    return num_tokens - 1;  // Fallback
}

// RAS: Repetition Aware Sampling
// If the sampled token repeats too often in recent history, use random sampling instead
// ğŸ”§ [ä¸ Python TTSSamplingParams å¯¹é½] (modeling_minicpmo.py line 69-76)
static int ras_sampling_tts(const float *            logits,
                            int                      num_tokens,
                            const std::vector<int> & decoded_tokens,    // Recent tokens (relative indices)
                            std::mt19937 &           rng,
                            float                    top_p    = 0.85f,  // TTSSamplingParams.top_p = 0.85
                            int                      top_k    = 25,     // TTSSamplingParams.top_k = 25
                            int                      win_size = 16,     // TTSSamplingParams.win_size = 16
                            float                    tau_r    = 0.1f    // TTSSamplingParams.tau_r = 0.1
) {
    // 1. First, do nucleus sampling to get a candidate
    int top_id = nucleus_sampling_tts(logits, num_tokens, top_p, top_k, rng);

    // 2. Count how many times this token appears in the recent window
    int start_idx = std::max(0, (int) decoded_tokens.size() - win_size);
    int rep_num   = 0;
    for (int i = start_idx; i < (int) decoded_tokens.size(); ++i) {
        if (decoded_tokens[i] == top_id) {
            rep_num++;
        }
    }

    // 3. If repetition exceeds threshold, switch to random sampling
    // Python: if rep_num >= win_size * tau_r
    if (rep_num >= (int) (win_size * tau_r)) {
        return random_sampling_tts(logits, num_tokens, rng);
    }

    return top_id;
}

// Apply repetition penalty to logits - matching Python's CustomRepetitionPenaltyLogitsProcessorRepeat
// Python implementation:
//   freq = F.one_hot(input_ids, num_tokens).sum(1)  # count frequency
//   alpha = torch.pow(penalty, freq)
//   inp = scores.multiply(alpha)  # for negative scores
//   oth = scores.divide(alpha)    # for positive scores
//   out = torch.where(scores < 0, inp, oth)
static void apply_repetition_penalty_tts(float *                  logits,
                                         int                      num_tokens,
                                         const std::vector<int> & decoded_tokens,  // Recent tokens (relative indices)
                                         float                    penalty,
                                         int                      past_window = 16) {
    if (decoded_tokens.empty() || penalty == 1.0f) {
        return;
    }

    // Get the window of recent tokens
    int start_idx = std::max(0, (int) decoded_tokens.size() - past_window);

    // Count frequency of each token in the window
    std::vector<int> freq(num_tokens, 0);
    for (int i = start_idx; i < (int) decoded_tokens.size(); ++i) {
        int tok = decoded_tokens[i];
        if (tok >= 0 && tok < num_tokens) {
            freq[tok]++;
        }
    }

    // Apply penalty: alpha = penalty ^ freq
    // For positive logits: divide by alpha (makes them smaller, lower probability)
    // For negative logits: multiply by alpha (makes them more negative, lower probability)
    for (int i = 0; i < num_tokens; ++i) {
        if (freq[i] > 0) {
            float alpha = powf(penalty, (float) freq[i]);
            if (logits[i] < 0) {
                logits[i] *= alpha;  // More negative
            } else {
                logits[i] /= alpha;  // Smaller positive
            }
        }
    }
}

// Nucleus sampling with min_tokens_to_keep (matching Python's TopPLogitsWarper and TopKLogitsWarper)
static int nucleus_sampling_with_min_keep_tts(const float *  logits,
                                              int            num_tokens,
                                              float          top_p,
                                              int            top_k,
                                              int            min_tokens_to_keep,  // Python default: 3
                                              std::mt19937 & rng) {
    // 1. Compute softmax probabilities
    float max_logit = logits[0];
    for (int i = 1; i < num_tokens; ++i) {
        if (logits[i] > max_logit) {
            max_logit = logits[i];
        }
    }

    std::vector<float> probs(num_tokens);
    float              sum = 0.0f;
    for (int i = 0; i < num_tokens; ++i) {
        probs[i] = expf(logits[i] - max_logit);
        sum += probs[i];
    }
    for (int i = 0; i < num_tokens; ++i) {
        probs[i] /= sum;
    }

    // 2. Sort by probability descending
    std::vector<std::pair<float, int>> sorted_probs;
    sorted_probs.reserve(num_tokens);
    for (int i = 0; i < num_tokens; ++i) {
        sorted_probs.push_back({ probs[i], i });
    }
    std::sort(sorted_probs.begin(), sorted_probs.end(),
              [](const auto & a, const auto & b) { return a.first > b.first; });

    // 3. Collect tokens within top_p and top_k, but keep at least min_tokens_to_keep
    std::vector<float> filtered_probs;
    std::vector<int>   filtered_indices;
    float              cum_prob = 0.0f;

    for (const auto & p : sorted_probs) {
        // Always keep min_tokens_to_keep tokens
        if ((int) filtered_probs.size() < min_tokens_to_keep) {
            cum_prob += p.first;
            filtered_probs.push_back(p.first);
            filtered_indices.push_back(p.second);
        }
        // After min_tokens_to_keep, apply top_p and top_k
        else if (cum_prob < top_p && (int) filtered_probs.size() < top_k) {
            cum_prob += p.first;
            filtered_probs.push_back(p.first);
            filtered_indices.push_back(p.second);
        } else {
            break;
        }
    }

    // 4. Renormalize filtered probs
    float filtered_sum = 0.0f;
    for (float p : filtered_probs) {
        filtered_sum += p;
    }
    for (float & p : filtered_probs) {
        p /= filtered_sum;
    }

    // 5. Multinomial sampling
    std::uniform_real_distribution<float> dist(0.0f, 1.0f);
    float                                 r   = dist(rng);
    float                                 cum = 0.0f;
    for (size_t i = 0; i < filtered_probs.size(); ++i) {
        cum += filtered_probs[i];
        if (r <= cum) {
            return filtered_indices[i];
        }
    }
    return filtered_indices.back();  // Fallback
}

// ==================== å•å·¥ç‰ˆæœ¬çš„ sample_tts_token ====================
// ç›´æ¥ä» omni_sinplex.cpp å¤åˆ¶ï¼Œä¿è¯å•å·¥æ¨¡å¼è¡Œä¸ºå®Œå…¨ä¸€è‡´
// ğŸ”§ [ä¸ Python å¯¹é½] æ·»åŠ  is_final_text_chunk å‚æ•°ï¼š
//    - é final chunkï¼šé‡‡æ ·åˆ° EOS æ—¶ä¸ prefillï¼Œé¿å…æ±¡æŸ“ KV cache
//    - final chunkï¼šé‡‡æ ·åˆ° EOS æ—¶æ­£å¸¸ prefill
static llama_token sample_tts_token_simplex(struct common_sampler *          smpl,
                                            struct omni_context *            ctx_omni,
                                            common_params *                  params,
                                            int *                            n_past_tts,
                                            const std::vector<llama_token> * all_generated_tokens,
                                            int                              token_index_in_chunk,
                                            bool                             force_no_eos        = false,
                                            bool                             is_final_text_chunk = false) {
    const char * logits_debug_dir = getenv("TTS_LOGITS_DEBUG_DIR");

    const int audio_bos_token_id = 151687;
    const int num_audio_tokens   = 6562;
    const int eos_relative_idx   = num_audio_tokens - 1;  // EOS token relative index: 6561

    // å•å·¥ç‰ˆæœ¬ï¼šis_audio_bos åªæœ‰åœ¨æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹çš„ç¬¬ä¸€ä¸ª token æ—¶æ‰ä¸º true
    bool is_audio_bos =
        (all_generated_tokens == nullptr || all_generated_tokens->empty()) && (token_index_in_chunk == 0);
    if (is_audio_bos) {
        print_with_timestamp("TTS simplex: is_audio_bos=true (first audio token)\n");
    }

    // Re-forward condition for first audio token
    if (is_audio_bos && ctx_omni->tts_condition_saved && ctx_omni->tts_condition_length > 0) {
        llama_memory_t mem = llama_get_memory(ctx_omni->ctx_tts_llama);
        if (mem) {
            llama_memory_seq_rm(mem, 0, 0, -1);
        }
        int condition_n_past = 0;
        if (!prefill_with_emb_tts(ctx_omni, params, ctx_omni->tts_condition_embeddings.data(),
                                  ctx_omni->tts_condition_length, params->n_batch, &condition_n_past)) {
            LOG_ERR("TTS simplex: Failed to re-forward condition\n");
            return 0;
        }
        *n_past_tts = condition_n_past;
    }

    // ä½¿ç”¨ head_code å±‚è®¡ç®— audio logits
    const float * hidden_state = llama_get_embeddings_ith(ctx_omni->ctx_tts_llama, -1);
    if (hidden_state == nullptr) {
        LOG_ERR("TTS simplex: failed to get hidden state\n");
        return 0;
    }

    if (ctx_omni->head_code_weight == nullptr) {
        LOG_ERR("TTS simplex: head_code weight not loaded\n");
        return 0;
    }

    if (ctx_omni->head_code_hidden_size != 768 || ctx_omni->head_code_num_audio_tokens != num_audio_tokens) {
        LOG_ERR("TTS simplex: head_code dimensions mismatch\n");
        return 0;
    }

    std::vector<float> audio_logits(num_audio_tokens, 0.0f);
    const float *      head_code_w = ctx_omni->head_code_weight;
    const int          hidden_size = ctx_omni->head_code_hidden_size;

    for (int i = 0; i < num_audio_tokens; ++i) {
        const float * row = head_code_w + i * hidden_size;
        float         sum = 0.0f;
        for (int j = 0; j < hidden_size; ++j) {
            sum += hidden_state[j] * row[j];
        }
        audio_logits[i] = sum;
    }

    std::mt19937 * rng = get_sampler_rng(smpl);
    std::mt19937   local_rng;
    if (rng == nullptr) {
        local_rng = std::mt19937(std::random_device{}());
        rng       = &local_rng;
    }

    // å•å·¥ç‰ˆæœ¬ï¼šä½¿ç”¨ all_generated_tokens åš repetition penalty
    std::vector<int> decoded_tokens_relative;
    if (all_generated_tokens != nullptr) {
        for (llama_token tid : *all_generated_tokens) {
            int relative_idx = tid - audio_bos_token_id;
            if (relative_idx >= 0 && relative_idx < num_audio_tokens) {
                decoded_tokens_relative.push_back(relative_idx);
            }
        }
    }

    // ğŸ”§ [ä¸ Python streaming å¯¹é½] TTS é‡‡æ ·å‚æ•°
    // Python tts_streaming_generate.py ä½¿ç”¨ï¼š
    // - temperature (ä» TTSSamplingParams ä¼ å…¥ï¼Œé»˜è®¤ 0.8)
    // - repetition_penalty = 1.05
    // - window = 8 (recent_ids = logits_token[:, -8:])
    // - multinomial é‡‡æ · (æ—  top-p/top-k)
    float temperature        = 0.8f;
    float repetition_penalty = 1.05f;
    int   win_size           = 8;  // ğŸ”§ [ä¸ Python å¯¹é½] Python: recent_ids = logits_token[:, -8:]

    bool use_argmax = (params->sampling.temp <= 0.0f);

    int selected_relative_idx;
    if (use_argmax) {
        float max_logit       = audio_logits[0];
        selected_relative_idx = 0;
        for (int i = 1; i < num_audio_tokens; ++i) {
            if (audio_logits[i] > max_logit) {
                max_logit             = audio_logits[i];
                selected_relative_idx = i;
            }
        }
    } else {
        // Step 1: åº”ç”¨ temperature
        // Python: logits /= self.temperature
        for (int i = 0; i < num_audio_tokens; ++i) {
            audio_logits[i] /= temperature;
        }

        // Step 2: åªæœ‰ t > 0 æ—¶æ‰åº”ç”¨ repetition penalty
        // Python: if t > 0: ... recent_ids = logits_token[:, -8:]
        if (!is_audio_bos && !decoded_tokens_relative.empty()) {
            // ğŸ”§ [ä¸ Python å¯¹é½] è·å–æœ€è¿‘ win_size ä¸ª tokens
            int start_idx = std::max(0, (int) decoded_tokens_relative.size() - win_size);

            // ğŸ”§ [ä¸ Python å¯¹é½] ä½¿ç”¨ bool mask è€Œä¸æ˜¯é¢‘ç‡è®¡æ•°
            // Python: occurred = F.one_hot(recent_ids, ...).sum(dim=1).bool()
            std::vector<bool> occurred(num_audio_tokens, false);
            for (int i = start_idx; i < (int) decoded_tokens_relative.size(); ++i) {
                int tok = decoded_tokens_relative[i];
                if (tok >= 0 && tok < num_audio_tokens) {
                    occurred[tok] = true;
                }
            }

            // ğŸ”§ [ä¸ Python å¯¹é½] åº”ç”¨ repetition penalty
            // Python: logits = torch.where(occurred & (logits >= 0), logits / penalty, logits)
            //         logits = torch.where(occurred & (logits < 0), logits * penalty, logits)
            for (int i = 0; i < num_audio_tokens; ++i) {
                if (occurred[i]) {
                    if (audio_logits[i] >= 0) {
                        audio_logits[i] /= repetition_penalty;
                    } else {
                        audio_logits[i] *= repetition_penalty;
                    }
                }
            }
        }

        // Step 3: å¦‚æœ force_no_eos=trueï¼Œå°† EOS logit è®¾ä¸º -inf
        if (force_no_eos) {
            audio_logits[eos_relative_idx] = -std::numeric_limits<float>::infinity();
        }

        // Step 4: ğŸ”§ [ä¸ Python å¯¹é½] ä½¿ç”¨ multinomial é‡‡æ · (æ—  top-p/top-k)
        // Python: scores = F.softmax(logits, dim=-1)
        //         next_token = torch.multinomial(scores, num_samples=1)
        selected_relative_idx = random_sampling_tts(audio_logits.data(), num_audio_tokens, *rng);
    }

    if (selected_relative_idx < 0 || selected_relative_idx >= num_audio_tokens) {
        selected_relative_idx = 0;
    }

    const llama_token id           = audio_bos_token_id + selected_relative_idx;
    int               relative_idx = selected_relative_idx;

    common_sampler_accept(smpl, id, true);

    // ğŸ”§ [ä¸ Python å¯¹é½] æ£€æµ‹æ˜¯å¦é‡‡æ ·åˆ° EOS
    bool is_eos = (relative_idx == eos_relative_idx);

    // ğŸ”§ [ä¸ Python å¯¹é½] EOS prefill é€»è¾‘ï¼š
    // Python ä¸­ EOS token ä¸ä¼šè¢«åŠ å…¥ all_generated_tokensï¼Œæ‰€ä»¥ä¸‹ä¸€è½®ä¸ä¼š forward è¿› TTS
    // C++ ä¸­éœ€è¦æ˜¾å¼æ§åˆ¶ï¼š
    //   - é final chunkï¼šé‡‡æ ·åˆ° EOS æ—¶ä¸ prefillï¼Œç›´æ¥è¿”å›ï¼ˆè®©è°ƒç”¨æ–¹çŸ¥é“å·²ç»“æŸï¼‰
    //   - final chunkï¼šæ•´ä¸ªç”Ÿæˆç»“æŸï¼Œprefill EOSï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼Œä¿æŒçŠ¶æ€ä¸€è‡´æ€§ï¼‰
    if (is_eos && !is_final_text_chunk) {
        // é final chunk é‡‡æ ·åˆ° EOSï¼Œä¸ prefillï¼Œç›´æ¥è¿”å›
        // è¿™æ · TTS æ¨¡å‹çš„ KV cache ä¸ä¼šåŒ…å« EOSï¼Œä¸‹ä¸€ä¸ª chunk å¯ä»¥ç»§ç»­ä½¿ç”¨
        return id;
    }

    // ä½¿ç”¨ emb_code è·å– embeddingï¼Œç„¶åé€šè¿‡ prefill_with_emb_tts è¾“å…¥æ¨¡å‹
    if (ctx_omni->emb_code_weight != nullptr && relative_idx >= 0 && relative_idx < ctx_omni->emb_code_vocab_size) {
        const float * emb_code_w           = ctx_omni->emb_code_weight;
        const int     emb_code_hidden_size = ctx_omni->emb_code_hidden_size;
        const int     emb_code_vocab_size  = ctx_omni->emb_code_vocab_size;

        std::vector<float> audio_token_embedding(emb_code_hidden_size);

        if (ctx_omni->emb_code_stored_as_transposed) {
            for (int j = 0; j < emb_code_hidden_size; ++j) {
                audio_token_embedding[j] = emb_code_w[j * emb_code_vocab_size + relative_idx];
            }
        } else {
            for (int j = 0; j < emb_code_hidden_size; ++j) {
                audio_token_embedding[j] = emb_code_w[relative_idx * emb_code_hidden_size + j];
            }
        }

        if (!prefill_with_emb_tts(ctx_omni, params, audio_token_embedding.data(), 1, 1, n_past_tts)) {
            LOG_ERR("TTS simplex: failed to decode audio token embedding\n");
            return 0;
        }
    } else {
        LOG_ERR("TTS simplex: emb_code not available\n");
        return 0;
    }

    return id;
}

llama_token sample_tts_token(struct common_sampler *          smpl,
                             struct omni_context *            ctx_omni,
                             common_params *                  params,
                             int *                            n_past_tts,
                             const std::vector<llama_token> * all_generated_tokens,
                             const std::vector<llama_token> * chunk_generated_tokens,
                             int                              token_index_in_chunk,
                             bool                             force_no_eos,
                             bool                             is_final_text_chunk = false) {
    // Debug: Save logits directory (set via environment variable)
    const char * logits_debug_dir = getenv("TTS_LOGITS_DEBUG_DIR");

    // TTS model constants
    const int audio_bos_token_id = 151687;
    const int num_audio_tokens   = 6562;  // head_code output size

    // ğŸ”§ [å·®å¼‚2ä¿®å¤] åˆ†ç¦»ä¸¤ä¸ªæ¦‚å¿µï¼Œä¸ Python generate_chunk å¯¹é½ï¼š
    // 1. is_first_token_overall: æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹çš„ç¬¬ä¸€ä¸ª tokenï¼ˆç”¨äº re-forward conditionï¼‰
    //    Python TTSStreamingGenerator: audio_bos = len(self.all_generated_tokens) == 0 and t == 0
    // 2. is_chunk_first_token: å½“å‰ chunk çš„ç¬¬ä¸€ä¸ª tokenï¼ˆç”¨äºè·³è¿‡ sampling processorsï¼‰
    //    Python generate_chunk: if t == 0: audio_bos = True
    //    Python generate_chunk ä¸­ï¼Œæ¯ä¸ª chunk çš„ç¬¬ä¸€ä¸ª token ä¸åº”ç”¨ repetition penalty å’Œ warpers

    // is_first_token_overall: ç”¨äºæ§åˆ¶æ˜¯å¦ re-forward conditionï¼ˆæ¸…ç©º KV cacheï¼‰
    bool is_first_token_overall =
        (all_generated_tokens == nullptr || all_generated_tokens->empty()) && (token_index_in_chunk == 0);

    // ğŸ”§ [å•åŒå·¥é€‚é…] skip_processors: æ§åˆ¶æ˜¯å¦è·³è¿‡ sampling processors
    // - åŒå·¥æ¨¡å¼ï¼šæ¯ä¸ª chunk çš„ç¬¬ä¸€ä¸ª token éƒ½è·³è¿‡ï¼ˆä¸ Python generate_chunk å¯¹é½ï¼‰
    //   Python generate_chunk: if t == 0: audio_bos = True
    // - å•å·¥æ¨¡å¼ï¼šåªæœ‰æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹çš„ç¬¬ä¸€ä¸ª token è·³è¿‡ï¼ˆä¸ Python TTSStreamingGenerator å¯¹é½ï¼‰
    //   Python: audio_bos = len(self.all_generated_tokens) == 0 and t == 0
    bool skip_processors;
    if (ctx_omni->duplex_mode) {
        // åŒå·¥æ¨¡å¼ï¼šæ¯ä¸ª chunk çš„ç¬¬ä¸€ä¸ª token éƒ½è·³è¿‡
        skip_processors = (token_index_in_chunk == 0);
    } else {
        // å•å·¥æ¨¡å¼ï¼šåªæœ‰æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹çš„ç¬¬ä¸€ä¸ª token è·³è¿‡
        skip_processors = is_first_token_overall;
    }

    // åªåœ¨ç¬¬ä¸€ä¸ªtokenæ—¶æ‰“å°
    if (is_first_token_overall) {
        print_with_timestamp("TTS sample: is_first_token_overall=true, duplex_mode=%d\n", ctx_omni->duplex_mode);
    }

    // CRITICAL FIX: For the first audio token of the ENTIRE generation, we need to re-forward the entire condition
    // This matches Python's behavior where past_key_values=None on the first forward
    // Python: outputs = self.tts.model(position_ids=pos_ids, past_key_values=None, inputs_embeds=inputs_embeds, use_cache=True)
    // ğŸ”§ [å·®å¼‚2ä¿®å¤] åªåœ¨æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹çš„ç¬¬ä¸€ä¸ª token æ—¶ re-forwardï¼Œä¸æ˜¯æ¯ä¸ª chunk çš„ç¬¬ä¸€ä¸ª
    if (is_first_token_overall && ctx_omni->tts_condition_saved && ctx_omni->tts_condition_length > 0) {
        // ğŸ”§ [å®‰å…¨æ£€æŸ¥] éªŒè¯ tts_condition_* å€¼æ˜¯å¦åˆç†
        int    cond_len      = ctx_omni->tts_condition_length;
        int    cond_n_embd   = ctx_omni->tts_condition_n_embd;
        size_t cond_emb_size = ctx_omni->tts_condition_embeddings.size();
        size_t expected_size = (size_t) cond_len * cond_n_embd;

        if (cond_len <= 0 || cond_len > 10000) {
            LOG_ERR("TTS sample: invalid tts_condition_length=%d\n", cond_len);
            return 0;
        }
        if (cond_n_embd <= 0 || cond_n_embd > 10000) {
            LOG_ERR("TTS sample: invalid tts_condition_n_embd=%d\n", cond_n_embd);
            return 0;
        }
        if (cond_emb_size != expected_size) {
            LOG_ERR("TTS sample: tts_condition_embeddings size mismatch: %zu != %zu (len=%d * n_embd=%d)\n",
                    cond_emb_size, expected_size, cond_len, cond_n_embd);
            return 0;
        }
        // Clear KV cache to match Python's past_key_values=None behavior
        // Use llama_memory_seq_rm to remove all tokens from sequence 0
        // seq_id=0, p0=0 (from beginning), p1=-1 (to end) removes all tokens
        llama_memory_t mem = llama_get_memory(ctx_omni->ctx_tts_llama);
        if (mem) {
            llama_memory_seq_rm(mem, 0, 0, -1);
        } else {
            LOG_ERR("TTS: Failed to get memory for KV cache clear\n");
        }

        // Reset n_past_tts to 0 (like Python's text_start_pos=0)
        int condition_n_past = 0;

        // Re-forward the entire condition
        if (!prefill_with_emb_tts(ctx_omni, params, ctx_omni->tts_condition_embeddings.data(),
                                  ctx_omni->tts_condition_length, params->n_batch, &condition_n_past)) {
            LOG_ERR("TTS: Failed to re-forward condition for first audio token\n");
            return 0;
        }

        // Update n_past_tts to match the condition length
        *n_past_tts = condition_n_past;
    }

    // 1. è·å–TTSæ¨¡å‹çš„æœ€åä¸€ä¸ªä½ç½®çš„hidden state
    // hidden_state shape: (hidden_size=768,)
    const float * hidden_state = llama_get_embeddings_ith(ctx_omni->ctx_tts_llama, -1);
    if (hidden_state == nullptr) {
        LOG_ERR("TTS: failed to get hidden state from TTS model\n");
        return 0;
    }

    // Debug: Save hidden states to file for Python comparison
    if (logits_debug_dir != nullptr) {
        int hidden_size = llama_n_embd(llama_get_model(ctx_omni->ctx_tts_llama));
        save_hidden_states_to_file(logits_debug_dir, hidden_state, hidden_size, token_index_in_chunk);
    }

    // 2. æ£€æŸ¥head_codeæƒé‡æ˜¯å¦å·²åŠ è½½
    if (ctx_omni->head_code_weight == nullptr) {
        LOG_ERR("TTS: head_code weight not loaded\n");
        return 0;
    }

    if (ctx_omni->head_code_hidden_size != 768 || ctx_omni->head_code_num_audio_tokens != num_audio_tokens) {
        LOG_ERR("TTS: head_code dimensions mismatch: expected (768, 6562), got (%d, %d)\n",
                ctx_omni->head_code_hidden_size, ctx_omni->head_code_num_audio_tokens);
        return 0;
    }

    // 3. ä½¿ç”¨head_codeå±‚è®¡ç®—audio tokençš„logits
    // logits = hidden_state @ head_code_weight
    // hidden_state: (768,), head_code_weight: [6562, 768] (è½¬ç½®åå­˜å‚¨) -> logits: (6562,)
    std::vector<float> audio_logits(num_audio_tokens, 0.0f);
    const float *      head_code_w = ctx_omni->head_code_weight;
    const int          hidden_size = ctx_omni->head_code_hidden_size;

    // âš¡ ä¼˜åŒ–ï¼šhead_code_weightå·²è½¬ç½®ä¸º[6562, 768]ï¼Œæ¯è¡Œè¿ç»­å­˜å‚¨
    // è¿ç»­å†…å­˜è®¿é—®ï¼Œcacheå‹å¥½
    for (int i = 0; i < num_audio_tokens; ++i) {
        const float * row = head_code_w + i * hidden_size;
        float         sum = 0.0f;
        for (int j = 0; j < hidden_size; ++j) {
            sum += hidden_state[j] * row[j];
        }
        audio_logits[i] = sum;
    }

    int eos_relative_idx = num_audio_tokens - 1;  // EOS token relative index: 6561

    // Debug: Save raw logits to file for Python comparison
    if (logits_debug_dir != nullptr) {
        save_logits_to_file(logits_debug_dir, audio_logits.data(), num_audio_tokens, token_index_in_chunk);
    }

    // Save hidden state and logits for comparison (before evaluation)
    const char * output_dir = getenv("TTS_OUTPUT_DIR");
    if (output_dir != nullptr) {
        // Save hidden state (for first token only)
        if (token_index_in_chunk == 0) {
            char hidden_state_path[512];
            snprintf(hidden_state_path, sizeof(hidden_state_path), "%s/cpp_first_hidden_state.bin", output_dir);
            FILE * f_hidden = fopen(hidden_state_path, "wb");
            if (f_hidden) {
                fwrite(hidden_state, sizeof(float), hidden_size, f_hidden);
                fclose(f_hidden);
            }
        }

        // Save logits for all tokens (for debugging)
        char logits_path[512];
        snprintf(logits_path, sizeof(logits_path), "%s/cpp_logits_token_%d.bin", output_dir, token_index_in_chunk);
        FILE * f_logits = fopen(logits_path, "wb");
        if (f_logits) {
            fwrite(audio_logits.data(), sizeof(float), num_audio_tokens, f_logits);
            fclose(f_logits);
        }
    }

    // 4. é‡‡æ ·æµç¨‹ - ä¸ Python MiniCPMTTS.generate() å®Œå…¨å¯¹é½
    // Python é‡‡æ ·æµç¨‹:
    //   1. logits /= temperature (é»˜è®¤ 0.8)
    //   2. if not audio_bos: apply repetition_penalty (penalty=1.05, past_window=16)
    //   3. if not audio_bos: apply TopP (0.85) + TopK (25) warper (min_tokens_to_keep=3)
    //   4. softmax + multinomial

    // Get RNG from sampler
    std::mt19937 * rng = get_sampler_rng(smpl);
    std::mt19937   local_rng;
    if (rng == nullptr) {
        // Fallback to local RNG
        LOG_WRN("TTS: sampler RNG not available, using local RNG\n");
        local_rng = std::mt19937(std::random_device{}());
        rng       = &local_rng;
    }

    // ğŸ”§ [å•åŒå·¥é€‚é…] Collect decoded tokens (relative indices) for repetition penalty
    // - åŒå·¥æ¨¡å¼ï¼šä½¿ç”¨ chunk_generated_tokensï¼ˆå½“å‰ chunk å†…çš„ tokensï¼‰
    //   Python generate_chunk: input_ids_sliced = new_tokens[:, 0:t]
    // - å•å·¥æ¨¡å¼ï¼šä½¿ç”¨ all_generated_tokensï¼ˆæ‰€æœ‰ç”Ÿæˆçš„ tokensï¼‰
    //   Python TTSStreamingGenerator: self.all_generated_tokens
    std::vector<int>                 decoded_tokens_relative;
    const std::vector<llama_token> * tokens_for_penalty;
    if (ctx_omni->duplex_mode) {
        // åŒå·¥æ¨¡å¼ï¼šä¼˜å…ˆä½¿ç”¨å½“å‰ chunk çš„ tokens
        tokens_for_penalty = chunk_generated_tokens ? chunk_generated_tokens : all_generated_tokens;
    } else {
        // å•å·¥æ¨¡å¼ï¼šä½¿ç”¨æ‰€æœ‰ç”Ÿæˆçš„ tokens
        tokens_for_penalty = all_generated_tokens;
    }
    if (tokens_for_penalty != nullptr) {
        for (llama_token tid : *tokens_for_penalty) {
            // Convert absolute token ID to relative index
            int relative_idx = tid - audio_bos_token_id;
            if (relative_idx >= 0 && relative_idx < num_audio_tokens) {
                decoded_tokens_relative.push_back(relative_idx);
            }
        }
    }

    // ğŸ”§ [ä¸ Python TTSSamplingParams å¯¹é½] (modeling_minicpmo.py line 69-76)
    float temperature        = 0.8f;   // TTSSamplingParams.temperature = 0.8
    float top_p              = 0.85f;  // TTSSamplingParams.top_p = 0.85
    int   top_k              = 25;     // TTSSamplingParams.top_k = 25
    float repetition_penalty = 1.05f;  // TTSSamplingParams.repetition_penalty = 1.05
    int   win_size           = 16;     // TTSSamplingParams.win_size = 16
    float tau_r              = 0.1f;   // TTSSamplingParams.tau_r = 0.1
    int   min_tokens_to_keep = 3;      // Python: TopPLogitsWarper/TopKLogitsWarper default

    // Get temperature from params if specified (for argmax mode)
    bool use_argmax = (params->sampling.temp <= 0.0f);

    int selected_relative_idx;
    if (use_argmax) {
        // Deterministic sampling: select argmax (highest logit)
        float max_logit       = audio_logits[0];
        selected_relative_idx = 0;
        for (int i = 1; i < num_audio_tokens; ++i) {
            if (audio_logits[i] > max_logit) {
                max_logit             = audio_logits[i];
                selected_relative_idx = i;
            }
        }
    } else {
        // Step 1: Apply temperature
        for (int i = 0; i < num_audio_tokens; ++i) {
            audio_logits[i] /= temperature;
        }

        // ğŸ”§ [å•åŒå·¥é€‚é…] Step 2 & 3: Apply repetition penalty and TopP/TopK
        // - åŒå·¥æ¨¡å¼ï¼šæ¯ä¸ª chunk çš„ç¬¬ä¸€ä¸ª token è·³è¿‡
        // - å•å·¥æ¨¡å¼ï¼šåªæœ‰æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹çš„ç¬¬ä¸€ä¸ª token è·³è¿‡
        if (!skip_processors && !decoded_tokens_relative.empty()) {
            // Apply repetition penalty (matching Python's CustomRepetitionPenaltyLogitsProcessorRepeat)
            apply_repetition_penalty_tts(audio_logits.data(), num_audio_tokens, decoded_tokens_relative,
                                         repetition_penalty, win_size);
        }

        // ğŸ”§ [å·®å¼‚1ä¿®å¤] åœ¨é‡‡æ ·å‰é˜»æ­¢ EOS token è¢«é‡‡æ ·
        // Python generate_chunk: if force_no_stop or t < min_new_tokens: logits[:, eos_token] = -torch.inf
        // è¿™æ ·å¯ä»¥ç¡®ä¿åœ¨è¾¾åˆ° min_new_tokens ä¹‹å‰ä¸ä¼šç”Ÿæˆ EOS
        if (ctx_omni->duplex_mode && force_no_eos) {
            int eos_relative_idx           = num_audio_tokens - 1;  // EOS token relative index: 6561
            audio_logits[eos_relative_idx] = -std::numeric_limits<float>::infinity();
        }

        // Step 4: Nucleus sampling with min_tokens_to_keep (matching Python's warpers)
        selected_relative_idx = nucleus_sampling_with_min_keep_tts(audio_logits.data(), num_audio_tokens, top_p, top_k,
                                                                   min_tokens_to_keep, *rng);
    }

    // 5. éªŒè¯é‡‡æ ·ç»“æœåœ¨æœ‰æ•ˆèŒƒå›´å†…
    if (selected_relative_idx < 0 || selected_relative_idx >= num_audio_tokens) {
        LOG_ERR("TTS: invalid selected index %d, should be in [0, %d)\n", selected_relative_idx, num_audio_tokens);
        // Fallback: use first token
        selected_relative_idx = 0;
    }

    // Convert relative index to absolute token ID
    const llama_token id           = audio_bos_token_id + selected_relative_idx;
    int               relative_idx = selected_relative_idx;

    common_sampler_accept(smpl, id, true);

    // ğŸ”§ [ä¸ Python å¯¹é½] æ£€æµ‹æ˜¯å¦é‡‡æ ·åˆ° EOS
    int  eos_relative_idx_check = num_audio_tokens - 1;  // EOS token relative index: 6561
    bool is_eos                 = (relative_idx == eos_relative_idx_check);

    // ğŸ”§ [ä¸ Python å¯¹é½] EOS prefill é€»è¾‘ï¼š
    // Python ä¸­ EOS token ä¸ä¼šè¢«åŠ å…¥ all_generated_tokensï¼Œæ‰€ä»¥ä¸‹ä¸€è½®ä¸ä¼š forward è¿› TTS
    // C++ ä¸­éœ€è¦æ˜¾å¼æ§åˆ¶ï¼š
    //   - é final chunkï¼šé‡‡æ ·åˆ° EOS æ—¶ä¸ prefillï¼Œç›´æ¥è¿”å›ï¼ˆè®©è°ƒç”¨æ–¹çŸ¥é“å·²ç»“æŸï¼‰
    //   - final chunkï¼šæ•´ä¸ªç”Ÿæˆç»“æŸï¼Œprefill EOSï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼Œä¿æŒçŠ¶æ€ä¸€è‡´æ€§ï¼‰
    if (ctx_omni->duplex_mode && is_eos && !is_final_text_chunk) {
        // é final chunk é‡‡æ ·åˆ° EOSï¼Œä¸ prefillï¼Œç›´æ¥è¿”å›
        // è¿™æ · TTS æ¨¡å‹çš„ KV cache ä¸ä¼šåŒ…å« EOSï¼Œä¸‹ä¸€ä¸ª chunk å¯ä»¥ç»§ç»­ä½¿ç”¨
        return id;
    }

    // 9. ä½¿ç”¨emb_codeå°†audio token IDè½¬æ¢ä¸ºembeddingï¼Œç„¶åä½¿ç”¨prefill_with_emb_tts
    // è¿™æ ·å¯ä»¥é¿å…token IDè¶…å‡ºè¯æ±‡è¡¨èŒƒå›´çš„é—®é¢˜
    if (ctx_omni->emb_code_weight != nullptr && relative_idx >= 0 && relative_idx < ctx_omni->emb_code_vocab_size) {
        // Get embedding from emb_code
        const float * emb_code_w           = ctx_omni->emb_code_weight;
        const int     emb_code_hidden_size = ctx_omni->emb_code_hidden_size;
        const int     emb_code_vocab_size  = ctx_omni->emb_code_vocab_size;

        // Allocate embedding buffer
        std::vector<float> audio_token_embedding(emb_code_hidden_size);

        if (ctx_omni->emb_code_stored_as_transposed) {
            // Stored as (hidden_size, num_audio_tokens) = [768, 6562]
            // Access: embedding[j] = emb_code_weight[j * num_audio_tokens + relative_idx]
            for (int j = 0; j < emb_code_hidden_size; ++j) {
                audio_token_embedding[j] = emb_code_w[j * emb_code_vocab_size + relative_idx];
            }
        } else {
            // Stored as (num_audio_tokens, hidden_size) = [6562, 768]
            // Access: embedding[j] = emb_code_weight[relative_idx * hidden_size + j]
            for (int j = 0; j < emb_code_hidden_size; ++j) {
                audio_token_embedding[j] = emb_code_w[relative_idx * emb_code_hidden_size + j];
            }
        }

        // Use prefill_with_emb_tts to decode with embedding instead of token ID
        if (!prefill_with_emb_tts(ctx_omni, params, audio_token_embedding.data(), 1, 1, n_past_tts)) {
            LOG_ERR("TTS: failed to decode audio token embedding\n");
            return 0;
        }
    } else {
        // Fallback: use token IDs (may fail if token ID exceeds vocab size)
        LOG_ERR("TTS: emb_code not available, falling back to token IDs (may fail if token exceeds vocab)\n");
        std::vector<llama_token> tokens;
        tokens.push_back(id);
        if (!eval_tokens_tts(ctx_omni, params, tokens, 1, n_past_tts)) {
            LOG_ERR("TTS: failed to decode audio token ID (token may exceed vocab size)\n");
            return 0;
        }
    }

    return id;
}

// Check if a token is an audio token (based on config: num_audio_tokens = 6562)
// Audio tokens are typically in a specific range
static bool is_audio_token(llama_token token, int audio_bos_token_id = 151687, int num_audio_tokens = 6562) {
    // Audio tokens are typically in range [audio_bos_token_id, audio_bos_token_id + num_audio_tokens)
    // Check if token is in the audio token range
    return (token >= audio_bos_token_id && token < audio_bos_token_id + num_audio_tokens);
}

// Simple UTF-8 incomplete byte checker
// Returns the number of incomplete bytes at the end of the string
// Returns 0 if the string ends with a complete UTF-8 sequence
static size_t findIncompleteUtf8(const std::string & str) {
    if (str.empty()) {
        return 0;
    }

    size_t len = str.length();

    // Check from the end backwards to find incomplete UTF-8 sequences
    size_t pos                         = len;
    int    expected_continuation_bytes = 0;

    while (pos > 0) {
        unsigned char c = (unsigned char) str[pos - 1];

        if ((c & 0x80) == 0) {
            // ASCII character (0xxxxxxx), complete sequence
            break;
        } else if ((c & 0xC0) == 0x80) {
            // Continuation byte (10xxxxxx), part of a multi-byte sequence
            expected_continuation_bytes++;
            pos--;
        } else if ((c & 0xE0) == 0xC0) {
            // 2-byte sequence start (110xxxxx)
            // Should have exactly 1 continuation byte after it
            if (expected_continuation_bytes == 1) {
                // Complete 2-byte sequence
                break;
            } else {
                // Incomplete: missing continuation byte(s)
                return len - pos + 1;  // Return incomplete bytes including the start byte
            }
        } else if ((c & 0xF0) == 0xE0) {
            // 3-byte sequence start (1110xxxx)
            // Should have exactly 2 continuation bytes after it
            if (expected_continuation_bytes == 2) {
                // Complete 3-byte sequence
                break;
            } else {
                // Incomplete: missing continuation byte(s)
                return len - pos + (3 - expected_continuation_bytes);
            }
        } else if ((c & 0xF8) == 0xF0) {
            // 4-byte sequence start (11110xxx)
            // Should have exactly 3 continuation bytes after it
            if (expected_continuation_bytes == 3) {
                // Complete 4-byte sequence
                break;
            } else {
                // Incomplete: missing continuation byte(s)
                return len - pos + (4 - expected_continuation_bytes);
            }
        } else {
            // Invalid UTF-8 byte pattern (should not happen in valid UTF-8)
            // Treat as complete to avoid breaking valid text
            break;
        }
    }

    // If we've checked all bytes and still have expected continuation bytes,
    // the sequence is incomplete
    if (pos == 0 && expected_continuation_bytes > 0) {
        return len;
    }

    return 0;  // String ends with complete UTF-8 sequence
}

// ==================== æ»‘åŠ¨çª—å£å®ç° (#39) ====================
// åŸºäº Python sliding_utils.py å’Œ stream_decoder.py

/**
 * é‡ç½®æ»‘åŠ¨çª—å£çŠ¶æ€
 */
void sliding_window_reset(struct omni_context * ctx_omni) {
    if (!ctx_omni) {
        return;
    }

    int old_unit_count = ctx_omni->unit_history.size();

    ctx_omni->unit_history.clear();
    ctx_omni->next_unit_id                 = 0;
    ctx_omni->pending_unit_id              = -1;
    ctx_omni->pending_unit_start_cache_len = 0;
    ctx_omni->system_preserve_length       = 0;
    ctx_omni->position_offset              = 0;

    // ç»Ÿè®¡ä¿¡æ¯
    ctx_omni->sliding_event_count  = 0;
    ctx_omni->total_dropped_tokens = 0;
    ctx_omni->total_dropped_units  = 0;

    if (old_unit_count > 0) {
        print_with_timestamp("[SW] reset: cleared %d units, all sliding window state reset\n", old_unit_count);
    }
}

/**
 * è·å–å½“å‰ KV cache é•¿åº¦
 */
static int get_cache_length(struct omni_context * ctx_omni) {
    if (!ctx_omni || !ctx_omni->ctx_llama) {
        return 0;
    }
    return ctx_omni->n_past;
}

/**
 * æ³¨å†Œ unit å¼€å§‹
 * åœ¨æ¯ä¸ª unitï¼ˆéŸ³é¢‘/è§†é¢‘/omni chunkï¼‰å¤„ç†å¼€å§‹æ—¶è°ƒç”¨
 * @return è¿”å›åˆ†é…çš„ unit_id
 */
int sliding_window_register_unit_start(struct omni_context * ctx_omni) {
    if (!ctx_omni) {
        return -1;
    }

    ctx_omni->pending_unit_id              = ctx_omni->next_unit_id;
    ctx_omni->pending_unit_start_cache_len = get_cache_length(ctx_omni);

    print_with_timestamp("[SW] unit_start: pending_unit_id=%d, cache_len=%d, preserve=%d, units=%zu\n",
                         ctx_omni->pending_unit_id, ctx_omni->pending_unit_start_cache_len,
                         ctx_omni->system_preserve_length, ctx_omni->unit_history.size());

    return ctx_omni->pending_unit_id;
}

/**
 * æ³¨å†Œ unit ç»“æŸ
 * åœ¨æ¯ä¸ª unit å¤„ç†å®Œæˆåè°ƒç”¨ï¼Œè®°å½•è¯¥ unit çš„ä¿¡æ¯
 */
void sliding_window_register_unit_end(struct omni_context *            ctx_omni,
                                      const std::string &              input_type,
                                      const std::vector<llama_token> & generated_tokens,
                                      bool                             is_listen) {
    if (!ctx_omni) {
        return;
    }

    if (ctx_omni->pending_unit_id < 0) {
        print_with_timestamp("[SW] WARNING: register_unit_end called without register_unit_start\n");
        return;
    }

    int current_cache_len = get_cache_length(ctx_omni);
    int unit_len          = current_cache_len - ctx_omni->pending_unit_start_cache_len;

    if (unit_len > 0) {
        UnitEntry entry;
        entry.unit_id          = ctx_omni->pending_unit_id;
        entry.length           = unit_len;
        entry.type             = input_type;
        entry.generated_tokens = generated_tokens;
        entry.is_listen        = is_listen;

        ctx_omni->unit_history.push_back(entry);

        print_with_timestamp(
            "[SW] unit_end: unit_id=%d type=%s len=%d gen_tokens=%zu is_listen=%d | cache=%d preserve=%d "
            "total_units=%zu\n",
            entry.unit_id, entry.type.c_str(), entry.length, entry.generated_tokens.size(), entry.is_listen,
            current_cache_len, ctx_omni->system_preserve_length, ctx_omni->unit_history.size());
    } else {
        print_with_timestamp(
            "[SW] WARNING: unit_end: unit_id=%d has zero length (start=%d, current=%d), not recorded\n",
            ctx_omni->pending_unit_id, ctx_omni->pending_unit_start_cache_len, current_cache_len);
    }

    ctx_omni->pending_unit_id              = -1;
    ctx_omni->pending_unit_start_cache_len = 0;
    ctx_omni->next_unit_id++;
}

/**
 * æ³¨å†Œ system prompt
 * åœ¨ system prompt prefill å®Œæˆåè°ƒç”¨ï¼Œè®°å½•ä¿æŠ¤é•¿åº¦
 */
void sliding_window_register_system_prompt(struct omni_context * ctx_omni) {
    if (!ctx_omni) {
        return;
    }

    ctx_omni->system_preserve_length = get_cache_length(ctx_omni);
    print_with_timestamp("[SW] system_prompt registered: preserve_length=%d (will be protected from sliding)\n",
                         ctx_omni->system_preserve_length);
}

/**
 * ä» KV cache ä¸­åˆ é™¤æŒ‡å®šæ•°é‡çš„ tokens
 * åˆ é™¤ä½äº [preserve, preserve + length) åŒºé—´çš„ tokens
 * 
 * æ³¨æ„ï¼šllama.cpp çš„ llama_memory_seq_rm å‡½æ•°å¯ä»¥ç›´æ¥åˆ é™¤æŒ‡å®šèŒƒå›´çš„ tokens
 * ä½†åˆ é™¤åéœ€è¦è¿›è¡Œ RoPE ä½ç½®é‡å¯¹é½ï¼ˆæš‚æ—¶ä¸æ”¯æŒï¼Œéœ€è¦æ›´æ·±å…¥çš„ä¿®æ”¹ï¼‰
 * 
 * å½“å‰å®ç°ï¼šä½¿ç”¨ç®€åŒ–çš„ç­–ç•¥ï¼Œåˆ é™¤ tokens åæ›´æ–° position_offset
 * åç»­ç”Ÿæˆæ—¶ä½¿ç”¨ position_offset æ¥è°ƒæ•´ position_ids
 */
bool sliding_window_drop_tokens_from_cache(struct omni_context * ctx_omni, int length) {
    if (!ctx_omni || !ctx_omni->ctx_llama || length <= 0) {
        print_with_timestamp("[SW] drop_tokens: invalid params (length=%d)\n", length);
        return false;
    }

    int cache_len_before = get_cache_length(ctx_omni);
    int preserve         = ctx_omni->system_preserve_length;

    if (cache_len_before <= preserve) {
        print_with_timestamp("[SW] drop_tokens: cache_len=%d <= preserve=%d, nothing to drop\n", cache_len_before,
                             preserve);
        return false;
    }

    int available = cache_len_before - preserve;
    if (available < length) {
        print_with_timestamp("[SW] drop_tokens: cannot drop %d tokens, only %d available (cache=%d, preserve=%d)\n",
                             length, available, cache_len_before, preserve);
        return false;
    }

    // ä½¿ç”¨ llama_memory_seq_rm åˆ é™¤ [preserve, preserve + length) åŒºé—´çš„ tokens
    llama_memory_t mem = llama_get_memory(ctx_omni->ctx_llama);
    if (!mem) {
        print_with_timestamp("[SW] drop_tokens: failed to get llama memory\n");
        return false;
    }

    // åˆ é™¤æŒ‡å®šèŒƒå›´çš„ tokens
    // llama_memory_seq_rm(mem, seq_id, p0, p1) åˆ é™¤ [p0, p1) èŒƒå›´çš„ tokens
    bool success = llama_memory_seq_rm(mem, 0, preserve, preserve + length);

    if (success) {
        // æ›´æ–° n_past
        ctx_omni->n_past = cache_len_before - length;

        // æ›´æ–° position_offsetï¼ˆç”¨äºåç»­ RoPE è®¡ç®—ï¼‰
        ctx_omni->position_offset += length;

        print_with_timestamp("[SW] drop_tokens: SUCCESS, dropped %d tokens from [%d, %d), cache %d -> %d, offset=%d\n",
                             length, preserve, preserve + length, cache_len_before, ctx_omni->n_past,
                             ctx_omni->position_offset);
    } else {
        print_with_timestamp("[SW] drop_tokens: FAILED to drop %d tokens\n", length);
    }

    return success;
}

/**
 * åˆ é™¤æŒ‡å®šçš„ unit
 */
static bool sliding_window_drop_unit(struct omni_context * ctx_omni, int unit_id) {
    if (!ctx_omni) {
        return false;
    }

    // æŸ¥æ‰¾ unit
    auto it = std::find_if(ctx_omni->unit_history.begin(), ctx_omni->unit_history.end(),
                           [unit_id](const UnitEntry & e) { return e.unit_id == unit_id; });

    if (it == ctx_omni->unit_history.end()) {
        print_with_timestamp("[SW] drop_unit: unit_id=%d not found\n", unit_id);
        return false;
    }

    int total_len = it->length;
    if (total_len <= 0) {
        print_with_timestamp("[SW] drop_unit: unit_id=%d has zero length, removing from history\n", unit_id);
        ctx_omni->unit_history.erase(it);
        return false;
    }

    int cache_before = get_cache_length(ctx_omni);
    if (!sliding_window_drop_tokens_from_cache(ctx_omni, total_len)) {
        print_with_timestamp("[SW] drop_unit: failed to drop %d tokens for unit_id=%d\n", total_len, unit_id);
        return false;
    }

    int cache_after = get_cache_length(ctx_omni);
    print_with_timestamp("[SW] ğŸ—‘ï¸ DROPPED unit_id=%d type=%s len=%d gen_tokens=%zu | cache %d -> %d, offset=%d\n",
                         it->unit_id, it->type.c_str(), it->length, it->generated_tokens.size(), cache_before,
                         cache_after, ctx_omni->position_offset);

    ctx_omni->unit_history.erase(it);
    return true;
}

/**
 * åˆ é™¤æœ€æ—©çš„ä¸€ä¸ªé system unit
 */
static bool sliding_window_drop_next_unit(struct omni_context * ctx_omni) {
    if (!ctx_omni) {
        return false;
    }

    for (const auto & entry : ctx_omni->unit_history) {
        // è·³è¿‡ system ç±»å‹
        if (entry.type == "system") {
            print_with_timestamp("[SW] drop_next_unit: skipping system unit_id=%d\n", entry.unit_id);
            continue;
        }

        print_with_timestamp("[SW] drop_next_unit: attempting to drop unit_id=%d\n", entry.unit_id);
        if (sliding_window_drop_unit(ctx_omni, entry.unit_id)) {
            return true;
        }
    }

    print_with_timestamp("[SW] drop_next_unit: no droppable unit found in %zu units\n", ctx_omni->unit_history.size());
    return false;
}

/**
 * æ‰§è¡Œæ»‘åŠ¨çª—å£ç­–ç•¥
 * å½“ cache é•¿åº¦è¶…è¿‡é«˜æ°´ä½çº¿æ—¶ï¼Œå¾ªç¯ç§»é™¤æœ€æ—©çš„ unitï¼Œç›´åˆ°é™åˆ°ä½æ°´ä½çº¿ä»¥ä¸‹
 * 
 * @return true å¦‚æœæ‰§è¡Œäº†æ»‘çª—æ“ä½œï¼Œfalse å¦‚æœæ²¡æœ‰éœ€è¦æ»‘çª—
 */
bool sliding_window_enforce(struct omni_context * ctx_omni) {
    if (!ctx_omni) {
        return false;
    }

    const auto & cfg = ctx_omni->sliding_window_config;

    // æ£€æŸ¥æ˜¯å¦å¯ç”¨æ»‘çª—
    if (cfg.mode == "off") {
        return false;
    }

    int cache_len_before = get_cache_length(ctx_omni);

    // æ£€æŸ¥æ˜¯å¦è¶…è¿‡é«˜æ°´ä½çº¿
    if (cache_len_before <= cfg.high_water_tokens) {
        return false;  // æœªè¶…è¿‡é«˜æ°´ä½çº¿ï¼Œä¸è§¦å‘
    }

    // è¶…è¿‡é«˜æ°´ä½çº¿ï¼Œå¼€å§‹æ»‘çª—
    print_with_timestamp("[SW] âš¡ SLIDING TRIGGERED: cache=%d > high_water=%d, target=low_water=%d\n", cache_len_before,
                         cfg.high_water_tokens, cfg.low_water_tokens);

    int dropped_count = 0;
    int cache_len     = cache_len_before;

    while (cache_len > cfg.low_water_tokens) {
        if (!sliding_window_drop_next_unit(ctx_omni)) {
            print_with_timestamp("[SW] enforce_window: no more units to drop, stopping\n");
            break;
        }
        dropped_count++;
        cache_len = get_cache_length(ctx_omni);
    }

    if (dropped_count > 0) {
        // æ›´æ–°ç»Ÿè®¡
        ctx_omni->sliding_event_count++;
        ctx_omni->total_dropped_tokens += cache_len_before - cache_len;
        ctx_omni->total_dropped_units += dropped_count;

        // ä¸€è‡´æ€§æ£€æŸ¥
        int expected = ctx_omni->system_preserve_length;
        for (const auto & u : ctx_omni->unit_history) {
            expected += u.length;
        }
        bool is_consistent = (expected == cache_len);

        print_with_timestamp(
            "[SW] âœ… SLIDING DONE: cache %d -> %d, dropped %d units, remaining %zu units | consistency: expected=%d "
            "actual=%d %s\n",
            cache_len_before, cache_len, dropped_count, ctx_omni->unit_history.size(), expected, cache_len,
            is_consistent ? "âœ“" : "âœ— MISMATCH!");

        if (!is_consistent) {
            print_with_timestamp("[SW] âŒ CONSISTENCY ERROR! preserve=%d + sum(units)=%d != cache=%d, offset=%d\n",
                                 ctx_omni->system_preserve_length, expected - ctx_omni->system_preserve_length,
                                 cache_len, ctx_omni->position_offset);
        }
    }

    return dropped_count > 0;
}

//
// omni main
//
std::condition_variable g_decode_cv;
bool                    prefill_done = true;
std::mutex              speek_mtx;
std::condition_variable speek_cv;
bool                    last_speek_done_flag = false;

// è®© thread å¯ä»¥ç»“æŸ
std::atomic<bool> llm_thread_running(true);
std::atomic<bool> tts_thread_running(true);
std::atomic<bool> t2w_thread_running(true);

// è¯»å– omni_output äº’æ–¥
std::mutex buffer_mutex;

void print_with_timestamp(const char * format, ...) {
    // è·å–å½“å‰æ—¶é—´
    auto now       = std::chrono::system_clock::now();
    auto in_time_t = std::chrono::system_clock::to_time_t(now);
    auto ms        = std::chrono::duration_cast<std::chrono::milliseconds>(now.time_since_epoch()) % 1000;

    // æ ¼å¼åŒ–æ—¶é—´æˆ³
    std::tm buf;
#ifdef _WIN32
    localtime_s(&buf, &in_time_t);
#else
    localtime_r(&in_time_t, &buf);
#endif
    std::cout << std::put_time(&buf, "%H:%M:%S") << '.' << std::setfill('0') << std::setw(3) << ms.count() << " ";

    // æ‰“å°æ ¼å¼åŒ–å­—ç¬¦ä¸²
    va_list args;
    va_start(args, format);
    vprintf(format, args);
    va_end(args);
}

static struct llama_model * llama_init(common_params * params, std::string model_path) {
    llama_backend_init();
    llama_numa_init(params->numa);

    llama_model_params model_params = common_model_params_to_llama(*params);
    llama_model *      model        = llama_load_model_from_file(model_path.c_str(), model_params);
    if (model == NULL) {
        LOG_ERR("%s: unable to load model\n", __func__);
        return NULL;
    }
    return model;
}

// TTSä¸“ç”¨æ¨¡å‹åŠ è½½ - æ”¯æŒç‹¬ç«‹çš„GPUå±‚æ•°è®¾ç½®
// é€šè¿‡ç¯å¢ƒå˜é‡ TTS_GPU_LAYERS æ§åˆ¶ï¼Œ-1 è¡¨ç¤ºä½¿ç”¨ä¸LLMç›¸åŒçš„è®¾ç½®
static struct llama_model * llama_init_tts(common_params * params,
                                           std::string     model_path,
                                           int             n_gpu_layers_override = -1) {
    llama_backend_init();
    llama_numa_init(params->numa);

    llama_model_params model_params = common_model_params_to_llama(*params);

    // å¦‚æœæŒ‡å®šäº†overrideå€¼(>=0)ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä¿æŒä¸LLMç›¸åŒçš„è®¾ç½®
    if (n_gpu_layers_override >= 0) {
        model_params.n_gpu_layers = n_gpu_layers_override;
    }

    llama_model * model = llama_load_model_from_file(model_path.c_str(), model_params);
    if (model == NULL) {
        LOG_ERR("%s: unable to load TTS model\n", __func__);
        return NULL;
    }
    return model;
}

struct omni_context * omni_init(struct common_params * params,
                                int                    media_type,
                                bool                   use_tts,
                                std::string            tts_bin_dir,
                                int                    tts_gpu_layers,
                                const std::string &    token2wav_device,
                                bool                   duplex_mode,
                                llama_model *          existing_model,
                                llama_context *        existing_ctx,
                                const std::string &    base_output_dir) {
    // process the prompt
    print_with_timestamp("=== omni_init start\n");
    // if (params->prompt.empty() && params->interactive == false) {
    //     LOG_INF("prompt should be given or interactive mode should be on");
    //     return NULL;
    // }
    // auto ctx_omni = (struct omni_context *)malloc(sizeof(omni_context));
    auto ctx_omni = new omni_context();

    ctx_omni->params          = params;
    ctx_omni->media_type      = media_type;
    ctx_omni->use_tts         = use_tts;
    ctx_omni->duplex_mode     = duplex_mode;
    ctx_omni->base_output_dir = base_output_dir;  // ğŸ”§ [å¤šå®ä¾‹æ”¯æŒ] è®¾ç½®å¯é…ç½®çš„è¾“å‡ºç›®å½•
    print_with_timestamp("media_type = %d, duplex_mode = %d, base_output_dir = %s\n", media_type, duplex_mode,
                         base_output_dir.c_str());
    // ğŸ”§ [å¯¹é½ Python MiniCPM-o-4_5-latest] prompt æ ¼å¼
    // Python default_tts_chat_template:
    //   {% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}
    //   {% if add_generation_prompt %}{{ '<|im_start|>assistant\n' + think_str + '<|tts_bos|>' }}{% endif %}
    //
    // Python audio_assistant æ¨¡å¼çš„ system prompt:
    //   vc_prompt_prefix = "æ¨¡ä»¿éŸ³é¢‘æ ·æœ¬çš„éŸ³è‰²å¹¶ç”Ÿæˆæ–°çš„å†…å®¹ã€‚"
    //   vc_prompt_suffix = "ä½ çš„ä»»åŠ¡æ˜¯ç”¨è¿™ç§å£°éŸ³æ¨¡å¼æ¥å½“ä¸€ä¸ªåŠ©æ‰‹ã€‚è¯·è®¤çœŸã€é«˜è´¨é‡åœ°å›å¤ç”¨æˆ·çš„é—®é¢˜ã€‚è¯·ç”¨é«˜è‡ªç„¶åº¦çš„æ–¹å¼å’Œç”¨æˆ·èŠå¤©ã€‚ä½ æ˜¯ç”±é¢å£æ™ºèƒ½å¼€å‘çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼šé¢å£å°é’¢ç‚®ã€‚"
    //   sys_msgs = {"role": "system", "content": [vc_prompt_prefix, ref_audio, vc_prompt_suffix]}
    //
    // å®Œæ•´æ ¼å¼ (audio_assistant æ¨¡å¼):
    //   <|im_start|>system
    //   æ¨¡ä»¿éŸ³é¢‘æ ·æœ¬çš„éŸ³è‰²å¹¶ç”Ÿæˆæ–°çš„å†…å®¹ã€‚
    //   <|audio_start|>[ref_audio_embed]<|audio_end|>ä½ çš„ä»»åŠ¡æ˜¯ç”¨è¿™ç§å£°éŸ³æ¨¡å¼æ¥å½“ä¸€ä¸ªåŠ©æ‰‹ã€‚...
    //   <|im_end|>
    //   <|im_start|>user
    //   <|audio_start|>[user_audio_embed]<|audio_end|>
    //   <|im_end|>
    //   <|im_start|>assistant
    //   <think>
    //
    //   </think>
    //
    //   <|tts_bos|>
    //
    // æ³¨æ„: voice_clone_prompt æ˜¯ system prompt çš„ prefixï¼Œassistant_prompt æ˜¯ system prompt çš„ suffix
    //       stream_decode ä¼šæ·»åŠ å®é™…çš„ assistant generation prompt
    if (duplex_mode) {
        // ğŸ”§ [ä¸ Python å¯¹é½] Audio åŒå·¥æ¨¡å¼ï¼šåµŒå…¥å‚è€ƒéŸ³é¢‘
        // åŒå·¥æ¨¡å¼ä¸éœ€è¦ <|im_start|>user\nï¼Œç”¨ <unit> æ ‡è®°ç”¨æˆ·è¾“å…¥
        ctx_omni->audio_voice_clone_prompt =
            "<|im_start|>system\nStreaming Duplex Conversation! You are a helpful assistant.\n<|audio_start|>";
        ctx_omni->audio_assistant_prompt = "<|audio_end|><|im_end|>\n";

        // ğŸ”§ [ä¿®å¤] Omni åŒå·¥æ¨¡å¼ï¼šä¹Ÿéœ€è¦åµŒå…¥å‚è€ƒéŸ³é¢‘ï¼Œæ ¼å¼ä¸ Audio åŒå·¥ç›¸åŒ
        ctx_omni->omni_voice_clone_prompt =
            "<|im_start|>system\nStreaming Duplex Conversation! You are a helpful assistant.\n<|audio_start|>";
        ctx_omni->omni_assistant_prompt = "<|audio_end|><|im_end|>\n";
    } else {
        // ğŸ”§ [ä¸ Python å¯¹é½] éåŒå·¥æ¨¡å¼ Audio æ ¼å¼ (audio_assistant æ¨¡å¼)
        // æ ¼å¼: <|im_start|>system\n...<|im_end|>\n<|im_start|>user\n
        // ğŸ”§ [æ•´åˆ] åœ¨ sys prompt æœ«å°¾ç›´æ¥æ·»åŠ  <|im_start|>user\nï¼Œä¸å†åœ¨ stream_prefill é‡ŒåŠ¨æ€æ·»åŠ 
        // è¿™æ ·æ›´ç¨³å¦¥ï¼Œä¸ä¾èµ– Python ç«¯çš„ counter é‡ç½®
        ctx_omni->audio_voice_clone_prompt = "<|im_start|>system\næ¨¡ä»¿éŸ³é¢‘æ ·æœ¬çš„éŸ³è‰²å¹¶ç”Ÿæˆæ–°çš„å†…å®¹ã€‚\n<|audio_start|>";
        ctx_omni->audio_assistant_prompt =
            "<|audio_end|>"
            "ä½ çš„ä»»åŠ¡æ˜¯ç”¨è¿™ç§å£°éŸ³æ¨¡å¼æ¥å½“ä¸€ä¸ªåŠ©æ‰‹ã€‚è¯·è®¤çœŸã€é«˜è´¨é‡åœ°å›å¤ç”¨æˆ·çš„é—®é¢˜ã€‚è¯·ç”¨é«˜è‡ªç„¶åº¦çš„æ–¹å¼å’Œç”¨æˆ·èŠå¤©ã€‚ä½ æ˜¯ç”±"
            "é¢å£æ™ºèƒ½å¼€å‘çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼šé¢å£å°é’¢ç‚®ã€‚<|im_end|>\n<|im_start|>user\n";

        // Omni æ¨¡å¼ï¼ˆéåŒå·¥ï¼‰ï¼šä¸ Audio æ¨¡å¼ç±»ä¼¼ï¼Œæœ«å°¾ä¹Ÿæ·»åŠ  <|im_start|>user\n
        ctx_omni->omni_voice_clone_prompt = "<|im_start|>system\næ¨¡ä»¿éŸ³é¢‘æ ·æœ¬çš„éŸ³è‰²å¹¶ç”Ÿæˆæ–°çš„å†…å®¹ã€‚\n<|audio_start|>";
        ctx_omni->omni_assistant_prompt =
            "<|audio_end|>"
            "ä½ çš„ä»»åŠ¡æ˜¯ç”¨è¿™ç§å£°éŸ³æ¨¡å¼æ¥å½“ä¸€ä¸ªåŠ©æ‰‹ã€‚è¯·è®¤çœŸã€é«˜è´¨é‡åœ°å›å¤ç”¨æˆ·çš„é—®é¢˜ã€‚è¯·ç”¨é«˜è‡ªç„¶åº¦çš„æ–¹å¼å’Œç”¨æˆ·èŠå¤©ã€‚<|im_"
            "end|>\n<|im_start|>user\n";
    }

    llama_model *   model     = nullptr;
    llama_context * ctx_llama = nullptr;

    // æ”¯æŒæ¨¡å‹å¤ç”¨ï¼ˆå•å·¥æ¨¡å¼å¸¸ç”¨ï¼‰
    if (existing_model != nullptr && existing_ctx != nullptr) {
        print_with_timestamp("=== omni_init: reusing existing LLM model and context\n");
        model                = existing_model;
        ctx_llama            = existing_ctx;
        ctx_omni->owns_model = false;  // ä¸æ‹¥æœ‰æ¨¡å‹ï¼Œomni_free æ—¶ä¸é‡Šæ”¾

        // ğŸ”§ [æ¨¡å¼åˆ‡æ¢ä¿®å¤] æ¸…ç† LLM çš„ KV cacheï¼Œé¿å…ä½ç½®å†²çª
        // å½“ä»ä¸€ä¸ªæ¨¡å¼åˆ‡æ¢åˆ°å¦ä¸€ä¸ªæ¨¡å¼æ—¶ï¼Œéœ€è¦æ¸…ç†æ—§çš„ KV cache
        llama_memory_t mem = llama_get_memory(ctx_llama);
        if (mem) {
            llama_memory_seq_rm(mem, 0, 0, -1);  // æ¸…é™¤ sequence 0 çš„æ‰€æœ‰ KV cache
            print_with_timestamp("=== omni_init: cleared LLM KV cache for mode switch\n");
        }
    } else {
        // åŠ è½½æ–°æ¨¡å‹
        print_with_timestamp("=== omni_init: loading new LLM model\n");
        model = llama_init(params, params->model.path);
        if (model == NULL) {
            return NULL;
        }
        llama_context_params ctx_params = common_context_params_to_llama(*params);
        ctx_params.n_ctx                = params->n_ctx;

        ctx_llama = llama_new_context_with_model(model, ctx_params);
        if (ctx_llama == NULL) {
            LOG_ERR("%s: error: failed to create the llama_context\n", __func__);
            return NULL;
        }
        ctx_omni->owns_model = true;  // æ‹¥æœ‰æ¨¡å‹ï¼Œomni_free æ—¶éœ€è¦é‡Šæ”¾
    }

    struct common_sampler * sampler = common_sampler_init(model, params->sampling);
    ctx_omni->ctx_llama             = ctx_llama;
    ctx_omni->model                 = model;
    ctx_omni->ctx_sampler           = sampler;

    if (use_tts && !params->tts_model.empty()) {
        print_with_timestamp("=== omni_init: loading TTS model\n");
        // ä½¿ç”¨TTSä¸“ç”¨çš„æ¨¡å‹åŠ è½½å‡½æ•°ï¼Œæ”¯æŒç‹¬ç«‹çš„GPUå±‚æ•°è®¾ç½®
        // tts_gpu_layers ä» omni_init å‚æ•°ä¼ å…¥ï¼Œ-1 è¡¨ç¤ºä½¿ç”¨ä¸LLMç›¸åŒçš„è®¾ç½®
        print_with_timestamp("TTS model: loading with n_gpu_layers=%d\n", tts_gpu_layers);
        llama_model * tts_model = llama_init_tts(params, params->tts_model, tts_gpu_layers);
        if (tts_model == NULL) {
            LOG_ERR("%s: error: failed to init TTS model from %s\n", __func__, params->tts_model.c_str());
            llama_free(ctx_llama);
            llama_free_model(model);
            common_sampler_free(sampler);
            delete ctx_omni;
            return NULL;
        }

        // TTS æ¨¡å‹ä½¿ç”¨ç‹¬ç«‹çš„ä¸Šä¸‹æ–‡å‚æ•°
        // æ³¨æ„ï¼šTTS æ¨¡å‹å¯èƒ½éœ€è¦ä¸åŒçš„ä¸Šä¸‹æ–‡å¤§å°å’Œæ‰¹å¤„ç†å¤§å°
        llama_context_params tts_ctx_params = common_context_params_to_llama(*params);
        // å¦‚æœ TTS æ¨¡å‹éœ€è¦æ›´å°çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œå¯ä»¥åœ¨è¿™é‡Œè°ƒæ•´
        // ä¾‹å¦‚ï¼štts_ctx_params.n_ctx = std::min(params->n_ctx, 2048); // é™åˆ¶ TTS ä¸Šä¸‹æ–‡å¤§å°
        tts_ctx_params.n_ctx                = params->n_ctx;  // æš‚æ—¶ä½¿ç”¨ç›¸åŒçš„ n_ctxï¼Œåç»­å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´

        llama_context * ctx_tts_llama = llama_new_context_with_model(tts_model, tts_ctx_params);
        if (ctx_tts_llama == NULL) {
            LOG_ERR("%s: error: failed to create the TTS llama_context\n", __func__);
            llama_free_model(tts_model);
            // æ¸…ç†å·²åˆ†é…çš„èµ„æº
            llama_free(ctx_llama);
            llama_free_model(model);
            common_sampler_free(sampler);
            delete ctx_omni;
            return NULL;
        }

        // åˆ›å»º TTS çš„é‡‡æ ·å™¨
        // ğŸ”§ TTSæµå¼é‡‡æ ·å‚æ•° - ä¸ Python ras_sampling å¯¹é½ï¼š
        // Python TTSSamplingParams é»˜è®¤ temperature=0.8 (modeling_minicpmo.py line 75)
        common_params_sampling tts_sampling = params->sampling;
        tts_sampling.temp                   = 0.8f;  // ğŸ”§ [ä¸ Python å¯¹é½] TTSSamplingParams.temperature=0.8
        tts_sampling.top_p =
            0.85f;  // ğŸ”§ [ä¸ Python å¯¹é½] TTSSamplingParams.top_p=0.85             // ğŸ”§ [ä¸ Python streaming å¯¹é½] top_p=0.8
        tts_sampling.top_k                  = 25;     // top_k = 25 (ras_sampling å‚æ•°)
        tts_sampling.penalty_repeat         = 1.05f;  // repetition_penalty = 1.05
        tts_sampling.min_p                  = 0.01f;  // min_p = 0.01
        // Python: CustomRepetitionPenaltyLogitsProcessorRepeat(repetition_penalty, num_code, 16)
        tts_sampling.penalty_last_n         = 16;  // past_window = 16 (ä¸Pythonå¯¹é½)
        struct common_sampler * tts_sampler = common_sampler_init(tts_model, tts_sampling);
        print_with_timestamp("TTS sampler: temp=%.2f, top_p=%.2f, top_k=%d, rep_penalty=%.2f\n", tts_sampling.temp,
                             tts_sampling.top_p, tts_sampling.top_k, tts_sampling.penalty_repeat);

        ctx_omni->model_tts       = tts_model;
        ctx_omni->ctx_tts_llama   = ctx_tts_llama;
        ctx_omni->ctx_tts_sampler = tts_sampler;

        // Load TTS weights from GGUF file
        print_with_timestamp("TTS: loading weights from GGUF (emb_code, emb_text, projector_semantic, head_code)...\n");
        if (!load_tts_weights_from_gguf(ctx_omni, params->tts_model.c_str())) {
            LOG_ERR("%s: error: failed to load TTS weights from %s\n", __func__, params->tts_model.c_str());
            llama_free(ctx_tts_llama);
            llama_free_model(tts_model);
            common_sampler_free(tts_sampler);
            llama_free(ctx_llama);
            llama_free_model(model);
            common_sampler_free(sampler);
            delete ctx_omni;
            return NULL;
        }
        print_with_timestamp("TTS: weights loaded successfully\n");

        // Load Projector Semantic from GGUF file
        // è·¯å¾„: {tts_bin_dir}/MiniCPM-o-4_5-projector-F16.gguf
        std::string projector_path = tts_bin_dir + "/MiniCPM-o-4_5-projector-F16.gguf";
        print_with_timestamp("Projector: loading from %s\n", projector_path.c_str());
        if (projector_init(ctx_omni->projector, projector_path, true)) {
            print_with_timestamp("Projector: loaded successfully\n");
        } else {
            print_with_timestamp("Projector: failed to load, will use fallback implementation\n");
        }
    }

    ctx_omni->omni_emb.resize((64 + 10 + 1) * 4096);  // temp fix for omni embed
    ctx_omni->audio_emb.resize((10 + 1) * 4096);      // temp fix for audio embed
    print_with_timestamp("=== omni_init: loading APM model\n");
    if (params->apm_model.empty()) {
        LOG_ERR("%s: error: apm_model path is empty\n", __func__);
        if (ctx_omni->use_tts) {
            llama_free(ctx_omni->ctx_tts_llama);
            llama_free_model(ctx_omni->model_tts);
            common_sampler_free(ctx_omni->ctx_tts_sampler);
        }
        llama_free(ctx_llama);
        llama_free_model(model);
        common_sampler_free(sampler);
        delete ctx_omni;
        return NULL;
    }
    ctx_omni->ctx_audio =
        audition_init(params->apm_model.c_str(), audition_context_params{ true, GGML_LOG_LEVEL_INFO });
    print_with_timestamp("APM: init from %s\n", params->apm_model.c_str());
    if (ctx_omni->ctx_audio == nullptr) {
        LOG_ERR("%s: error: failed to init audition model from %s\n", __func__, params->apm_model.c_str());
        // æ¸…ç† TTS æ¨¡å‹èµ„æºï¼ˆå¦‚æœå·²åŠ è½½ï¼‰
        if (ctx_omni->use_tts) {
            llama_free(ctx_omni->ctx_tts_llama);
            llama_free_model(ctx_omni->model_tts);
            common_sampler_free(ctx_omni->ctx_tts_sampler);
        }
        llama_free(ctx_llama);
        llama_free_model(model);
        common_sampler_free(sampler);
        delete ctx_omni;
        return NULL;
    }

    ctx_omni->n_past = 0;

    if (media_type == 2) {
        LOG_INF("init vision....");
        const char * vision_path = ctx_omni->params->vpm_model.c_str();
        auto *       ctx_vision = vision_init(vision_path, vision_context_params{ true, GGML_LOG_LEVEL_INFO, nullptr });
        ctx_omni->ctx_vision    = ctx_vision;

        // Set CoreML model path if available (for vision ANE acceleration)
        // Note: .mlmodelc is a directory, not a file, so use stat instead of ifstream
        if (ctx_vision && !ctx_omni->params->vision_coreml_model_path.empty()) {
            struct stat coreml_stat;
            if (stat(ctx_omni->params->vision_coreml_model_path.c_str(), &coreml_stat) == 0) {
                vision_set_coreml_model_path(ctx_vision, ctx_omni->params->vision_coreml_model_path.c_str());
                LOG_INF("Vision CoreML model path set to: %s\n", ctx_omni->params->vision_coreml_model_path.c_str());
            } else {
                LOG_WRN("Vision CoreML model path does not exist: %s, skipping ANE\n",
                        ctx_omni->params->vision_coreml_model_path.c_str());
            }
        }
    }

    ctx_omni->llm_thread_info = new LLMThreadInfo(1000);
    if (ctx_omni->use_tts) {
        LOG_INF("init tts....");
        ctx_omni->tts_thread_info = new TTSThreadInfo(1);
        ctx_omni->omni_output     = new omni_output();
        ctx_omni->tts_bin_dir     = tts_bin_dir;

        // Initialize T2W thread info
        LOG_INF("init t2w....");
        ctx_omni->t2w_thread_info = new T2WThreadInfo(25);  // Queue size of 10 chunks

        // Initialize C++ Token2Wav session
        // Try to load token2wav GGUF models from {model_dir}/token2wav-gguf/
        // Fallback to tools/omni/token2wav-gguf if not found
        ctx_omni->token2wav_initialized = false;

        // ğŸ”§ å¦‚æœä½¿ç”¨ Python Token2Wavï¼Œè·³è¿‡ C++ çš„åˆå§‹åŒ–ä»¥èŠ‚çœæ˜¾å­˜
        bool skip_cpp_token2wav = ctx_omni->use_python_token2wav;

        // Check if token2wav model files exist
        // ä¼˜å…ˆæ£€æŸ¥ HF æ¨¡å‹ç›®å½•ä¸‹çš„ token2wav-gguf (tts_bin_dir çš„çˆ¶ç›®å½•)
        // ç›®å½•ç»“æ„: {model_dir}/token2wav-gguf/
        std::string gguf_root_dir = tts_bin_dir;
        size_t      last_slash    = gguf_root_dir.find_last_of("/\\");
        if (last_slash != std::string::npos) {
            gguf_root_dir = gguf_root_dir.substr(0, last_slash);  // è·å– tts çš„çˆ¶ç›®å½•
        }
        ctx_omni->token2wav_model_dir = gguf_root_dir + "/token2wav-gguf";

        std::string encoder_test = ctx_omni->token2wav_model_dir + "/encoder.gguf";
        {
            std::ifstream f(encoder_test);
            if (!f.good()) {
                // å°è¯•å¤‡ç”¨è·¯å¾„ (æœ¬åœ°å¼€å‘ç”¨)
                ctx_omni->token2wav_model_dir = "tools/omni/token2wav-gguf";
                print_with_timestamp("Token2Wav: trying fallback path %s\n", ctx_omni->token2wav_model_dir.c_str());
            } else {
                print_with_timestamp("Token2Wav: found models in %s\n", ctx_omni->token2wav_model_dir.c_str());
            }
        }
        std::string encoder_gguf       = ctx_omni->token2wav_model_dir + "/encoder.gguf";
        std::string flow_matching_gguf = ctx_omni->token2wav_model_dir + "/flow_matching.gguf";
        std::string flow_extra_gguf    = ctx_omni->token2wav_model_dir + "/flow_extra.gguf";
        std::string vocoder_gguf       = ctx_omni->token2wav_model_dir + "/hifigan2.gguf";
        std::string prompt_cache_gguf  = ctx_omni->token2wav_model_dir + "/prompt_cache.gguf";

        // Check if all files exist
        bool                     all_files_exist = true;
        std::vector<std::string> gguf_files      = { encoder_gguf, flow_matching_gguf, flow_extra_gguf, vocoder_gguf };
        for (const auto & file : gguf_files) {
            std::ifstream f(file);
            if (!f.good()) {
                all_files_exist = false;
                break;
            } else {
            }
        }

        if (all_files_exist && !skip_cpp_token2wav) {
            print_with_timestamp("Token2Wav: all model files found, initializing session...\n");
            ctx_omni->token2wav_session = std::make_unique<omni::flow::Token2WavSession>();

            // Device configuration - ä½¿ç”¨ omni_init ä¼ å…¥çš„ token2wav_device å‚æ•°
            // æ ¼å¼: "gpu", "gpu:0", "gpu:1", "cpu"
            // ğŸ”§ Token2Mel ç”¨ GPU (Metal) åŠ é€Ÿï¼ŒVocoder ç”¨ CPUï¼ˆå› ä¸º reshape/permute å¼€é”€å¤ªå¤§ï¼‰
            std::string device_token2mel = token2wav_device;
            std::string device_vocoder   = "cpu";  // Vocoder å¼ºåˆ¶ç”¨ CPUï¼Œé¿å… Metal ä¸­å¤§é‡å°æ“ä½œçš„å¼€é”€

            // ğŸ”§ ä¼˜å…ˆä½¿ç”¨ prompt_bundle (setup_cache è·¯å¾„)ï¼Œå¦åˆ™ fallback åˆ° prompt_cache.gguf
            std::string prompt_bundle_dir = "tools/omni/assets/default_ref_audio";
            std::string spk_file          = prompt_bundle_dir + "/spk_f32.bin";
            std::string tokens_file       = prompt_bundle_dir + "/prompt_tokens_i32.bin";
            std::string mel_file          = prompt_bundle_dir + "/prompt_mel_btc_f32.bin";

            bool use_prompt_bundle = false;
            {
                std::ifstream f1(spk_file), f2(tokens_file), f3(mel_file);
                use_prompt_bundle = f1.good() && f2.good() && f3.good();
            }

            bool init_ok = false;
            // ä¼˜å…ˆçº§: prompt_cache.gguf > prompt_bundle (å®æ—¶è®¡ç®— fallback)
            print_with_timestamp("Token2Wav: using prompt_cache from %s\n", prompt_cache_gguf.c_str());
            init_ok = ctx_omni->token2wav_session->init_from_prompt_cache_gguf(
                encoder_gguf, flow_matching_gguf, flow_extra_gguf, prompt_cache_gguf, vocoder_gguf, device_token2mel,
                device_vocoder, 5, 1.0f);
            if (!init_ok && use_prompt_bundle) {
                print_with_timestamp("Token2Wav: prompt_cache failed, fallback to prompt_bundle from %s\n",
                                     prompt_bundle_dir.c_str());
                init_ok = ctx_omni->token2wav_session->init_from_prompt_bundle(
                    encoder_gguf, flow_matching_gguf, flow_extra_gguf, prompt_bundle_dir, vocoder_gguf,
                    device_token2mel, device_vocoder, 5, 1.0f);
            }
            // Fallback to CPU
            if (!init_ok) {
                print_with_timestamp("Token2Wav: GPU init failed, trying CPU mode...\n");
                ctx_omni->token2wav_session.reset();
                ctx_omni->token2wav_session = std::make_unique<omni::flow::Token2WavSession>();
                init_ok = ctx_omni->token2wav_session->init_from_prompt_cache_gguf(encoder_gguf, flow_matching_gguf,
                                                                                   flow_extra_gguf, prompt_cache_gguf,
                                                                                   vocoder_gguf, "cpu", "cpu", 5, 1.0f);
            }

            if (init_ok) {
                ctx_omni->token2wav_initialized = true;
                // Initialize token2wav buffer with 3 silence tokens (4218) as Python does
                // Python: buffer = [4218] * 3  # é¢„å…ˆæ”¾å…¥3ä¸ªå‰ç¼€é™éŸ³token
                ctx_omni->token2wav_buffer.clear();
                ctx_omni->token2wav_buffer  = { 4218, 4218, 4218 };
                ctx_omni->token2wav_wav_idx = 0;
                print_with_timestamp("Token2Wav: initialized successfully\n");
            } else {
                ctx_omni->token2wav_session.reset();
                print_with_timestamp("Token2Wav: initialization failed\n");
            }
        } else {
            print_with_timestamp("Token2Wav: model files not found in %s\n", ctx_omni->token2wav_model_dir.c_str());
        }

        // ==================== åˆå§‹åŒ– Python Token2Wav ====================
        // ğŸ”§ é»˜è®¤ä½¿ç”¨ Python Token2Wavï¼ˆç²¾åº¦æ›´é«˜ï¼‰
        // è®¾ç½® Python T2W è„šæœ¬ç›®å½•å’Œæ¨¡å‹ç›®å½•
        // Python T2W è„šæœ¬ç›®å½•ï¼štools/omni/pyt2w/
        // Python T2W æ¨¡å‹ç›®å½•ï¼šdependencies/token2wav/

        // è®¡ç®— Python T2W è„šæœ¬ç›®å½•ï¼ˆç›¸å¯¹äº tts_bin_dirï¼‰
        // tts_bin_dir é€šå¸¸æ˜¯ /xxx/tools/omni/convert/gguf/token2wav-gguf
        // æˆ‘ä»¬éœ€è¦ /xxx/tools/omni/pyt2w
        std::string t2w_script_dir = tts_bin_dir;  // /xxx/tools/omni/convert/gguf/token2wav-gguf
        // å›é€€åˆ° tools/omni/
        size_t      convert_pos    = t2w_script_dir.find("/convert/gguf/tts");
        if (convert_pos != std::string::npos) {
            t2w_script_dir = t2w_script_dir.substr(0, convert_pos) + "/pyt2w";
        } else if ((convert_pos = t2w_script_dir.find("/convert/gguf")) != std::string::npos) {
            t2w_script_dir = t2w_script_dir.substr(0, convert_pos) + "/pyt2w";
        } else {
            // å°è¯•ä»å½“å‰å·¥ä½œç›®å½•æ„å»º
            t2w_script_dir = "./tools/omni/pyt2w";
        }
        ctx_omni->python_t2w_script_dir = t2w_script_dir;

        // Python T2W æ¨¡å‹ç›®å½•ï¼ˆstepaudio2 æ¨¡å‹ï¼‰
        // é»˜è®¤è·¯å¾„ï¼šç›¸å¯¹äº script_dir çš„ token2wav å­ç›®å½•
        ctx_omni->python_t2w_model_dir = t2w_script_dir + "/token2wav";

        // å‚è€ƒéŸ³é¢‘è·¯å¾„
        std::string ref_audio_path = "tools/omni/assets/default_ref_audio/default_ref_audio.wav";

        print_with_timestamp("Python T2W: script_dir=%s, model_dir=%s\n", ctx_omni->python_t2w_script_dir.c_str(),
                             ctx_omni->python_t2w_model_dir.c_str());

        if (ctx_omni->use_python_token2wav) {
            print_with_timestamp("Python T2W: ä½¿ç”¨ Python Token2Wav å®ç°\n");

            // ğŸ”§ Python T2W GPU é…ç½®
            // C++ LLM+TTS å ç”¨çº¦ 22GBï¼ŒPython T2W å ç”¨çº¦ 3.3GB
            // å•å¡ 24GB æ”¾ä¸ä¸‹ï¼Œéœ€è¦é…ç½®ç‹¬ç«‹ GPU
            //
            // é€šè¿‡ç¯å¢ƒå˜é‡ PYTHON_T2W_GPU é…ç½®ç‹¬ç«‹ GPU
            // ä¾‹å¦‚: export PYTHON_T2W_GPU=1  # Python T2W ä½¿ç”¨ GPU 1
            //
            // ä¼˜å…ˆçº§ï¼šPYTHON_T2W_GPU ç¯å¢ƒå˜é‡ > å¤–éƒ¨ CUDA_VISIBLE_DEVICES > token2wav_device
            const char * env_python_t2w_gpu = getenv("PYTHON_T2W_GPU");
            if (env_python_t2w_gpu && strlen(env_python_t2w_gpu) > 0) {
                ctx_omni->python_t2w_dedicated_gpu = env_python_t2w_gpu;
            }

            ctx_omni->python_t2w_gpu_id = "";

            if (!ctx_omni->python_t2w_dedicated_gpu.empty()) {
                // ä½¿ç”¨é…ç½®çš„ç‹¬ç«‹ GPU
                ctx_omni->python_t2w_gpu_id = ctx_omni->python_t2w_dedicated_gpu;
                print_with_timestamp("Python T2W: ä½¿ç”¨ç‹¬ç«‹ GPU %s (C++ å’Œ Python åˆ†å¼€)\n",
                                     ctx_omni->python_t2w_gpu_id.c_str());
            } else {
                const char * env_cuda_visible = getenv("CUDA_VISIBLE_DEVICES");
                if (env_cuda_visible && strlen(env_cuda_visible) > 0) {
                    // å¤–éƒ¨å·²è®¾ç½®ï¼ŒPython å­è¿›ç¨‹ä¼šç»§æ‰¿ï¼Œä¸éœ€è¦é¢å¤–è®¾ç½®
                    print_with_timestamp("Python T2W: ç»§æ‰¿å¤–éƒ¨ CUDA_VISIBLE_DEVICES=%s (ä¸ C++ å…±ç”¨)\n",
                                         env_cuda_visible);
                } else if (token2wav_device.find("gpu") != std::string::npos) {
                    // å¤–éƒ¨æœªè®¾ç½®ï¼Œä» token2wav_device æå–
                    size_t colon_pos = token2wav_device.find(':');
                    if (colon_pos != std::string::npos) {
                        ctx_omni->python_t2w_gpu_id = token2wav_device.substr(colon_pos + 1);
                    } else {
                        ctx_omni->python_t2w_gpu_id = "0";
                    }
                    print_with_timestamp("Python T2W: è®¾ç½® CUDA_VISIBLE_DEVICES=%s (ä¸ C++ å…±ç”¨)\n",
                                         ctx_omni->python_t2w_gpu_id.c_str());
                } else {
                    print_with_timestamp("Python T2W: CPU æ¨¡å¼\n");
                }
            }

            // å¯åŠ¨ Python æœåŠ¡
            if (start_python_t2w_service(ctx_omni)) {
                // åˆå§‹åŒ–æ¨¡å‹
                if (init_python_t2w_model(ctx_omni, token2wav_device)) {
                    // è®¾ç½®å‚è€ƒéŸ³é¢‘
                    if (set_python_t2w_ref_audio(ctx_omni, ref_audio_path)) {
                        print_with_timestamp("Python T2W: åˆå§‹åŒ–æˆåŠŸ\n");
                    } else {
                        print_with_timestamp("Python T2W: è®¾ç½®å‚è€ƒéŸ³é¢‘å¤±è´¥\n");
                        ctx_omni->use_python_token2wav = false;
                    }
                } else {
                    print_with_timestamp("Python T2W: åˆå§‹åŒ–æ¨¡å‹å¤±è´¥\n");
                    ctx_omni->use_python_token2wav = false;
                }
            } else {
                print_with_timestamp("Python T2W: å¯åŠ¨æœåŠ¡å¤±è´¥\n");
                ctx_omni->use_python_token2wav = false;
            }

            // å¦‚æœ Python åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ° C++ å®ç°
            if (!ctx_omni->use_python_token2wav) {
                print_with_timestamp("Python T2W: å›é€€åˆ° C++ å®ç°\n");
            }
        } else {
            print_with_timestamp("Token2Wav: ä½¿ç”¨ C++ å®ç°\n");
        }
    }
    ctx_omni->async = true;

    // ==================== åˆå§‹åŒ–ç‰¹æ®Š Token ID ====================
    // ä» LLM è¯è¡¨ä¸­æŸ¥æ‰¾å¹¶ç¼“å­˜ç‰¹æ®Š token ID
    // è¿™äº› token ç”¨äºæ§åˆ¶åŒå·¥æ¨¡å¼ä¸‹çš„çŠ¶æ€åˆ‡æ¢

    const struct llama_vocab * vocab = llama_model_get_vocab(model);
    if (vocab) {
        // ä½¿ç”¨ llama_tokenize ç›´æ¥å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º token ID
        // parse_special=true ç¡®ä¿ç‰¹æ®Š token è¢«æ­£ç¡®è§£æ
        auto find_token = [&](const char * token_str) -> llama_token {
            llama_token tokens[4];  // é¢„ç•™ç©ºé—´
            int         n_tokens = llama_tokenize(vocab, token_str, strlen(token_str), tokens, 4, false, true);
            if (n_tokens == 1) {
                return tokens[0];
            }
            // å¦‚æœ tokenize å¤±è´¥ï¼Œå°è¯•éå†è¯è¡¨æŸ¥æ‰¾ï¼ˆä½¿ç”¨ special=trueï¼‰
            int n_vocab = llama_vocab_n_tokens(vocab);
            for (int i = 0; i < n_vocab; i++) {
                char buf[128];
                int  len = llama_token_to_piece(vocab, i, buf, sizeof(buf), 0, true);  // special=true
                if (len > 0 && len < (int) sizeof(buf)) {
                    buf[len] = '\0';
                    if (strcmp(buf, token_str) == 0) {
                        return i;
                    }
                }
            }
            return -1;
        };

        ctx_omni->special_token_speak         = find_token("<|speak|>");
        ctx_omni->special_token_listen        = find_token("<|listen|>");
        ctx_omni->special_token_chunk_eos     = find_token("<|chunk_eos|>");
        ctx_omni->special_token_chunk_tts_eos = find_token("<|chunk_tts_eos|>");
        ctx_omni->special_token_turn_eos      = find_token("<|turn_eos|>");
        ctx_omni->special_token_tts_eos       = find_token("<|tts_eos|>");
        ctx_omni->special_token_eos           = llama_vocab_eos(vocab);

        // åŒæ—¶åˆå§‹åŒ– tts_bos_token_idï¼ˆç”¨äºåŒå·¥æ¨¡å¼å¼ºåˆ¶ç»§ç»­è¯´è¯ï¼‰
        llama_token tts_bos = find_token("<|tts_bos|>");
        if (tts_bos >= 0) {
            ctx_omni->tts_bos_token_id = tts_bos;
        }
        // åˆå§‹åŒ– </unit> tokenï¼ˆç”¨äºåŒå·¥æ¨¡å¼ chunk è¾¹ç•Œæ ‡è®°ï¼‰
        ctx_omni->special_token_unit_end = find_token("</unit>");

        // ğŸ”§ [åŒå·¥æ¨¡å¼] åˆå§‹åŒ– <|tts_pad|> tokenï¼ˆåŒå·¥æ¨¡å¼ä¸‹ç¦æ­¢é‡‡æ ·æ­¤ tokenï¼‰
        // Python: self.forbidden_token_ids = [self.tts_pad_id] + list(bad_token_ids)
        ctx_omni->special_token_tts_pad = find_token("<|tts_pad|>");
    }

    // ANE/CoreML warmup: pre-load models into NPU to avoid first-inference latency
    omni_warmup_ane(ctx_omni);

    print_with_timestamp("=== omni_init success: ctx_llama = %p\n", (void *) ctx_omni->ctx_llama);
    return ctx_omni;
}

//
// ANE/CoreML warmup â€” pre-load models into NPU to avoid first-inference latency
//
void omni_warmup_ane(struct omni_context * ctx_omni) {
#if defined(__APPLE__)
    if (!ctx_omni) {
        return;
    }

    LOG_INF("%s: starting ANE/CoreML warmup...\n", __func__);

    // 1. Vision ANE warmup
    if (ctx_omni->ctx_vision) {
        vision_coreml_warmup(ctx_omni->ctx_vision);
    }

    // 2. Future: audio ANE warmup
    // if (ctx_omni->ctx_audio) {
    //     audition_coreml_warmup(ctx_omni->ctx_audio);
    // }

    // 3. Future: other module ANE warmup
    // ...

    LOG_INF("%s: ANE/CoreML warmup finished\n", __func__);
#else
    (void) ctx_omni;
#endif
}

// åœæ­¢æ‰€æœ‰çº¿ç¨‹ï¼ˆå‘é€ä¿¡å·ï¼Œä¸ç­‰å¾…ï¼‰
void omni_stop_threads(struct omni_context * ctx_omni) {
    // å‘é€åœæ­¢ä¿¡å·
    llm_thread_running = false;
    tts_thread_running = false;
    t2w_thread_running = false;

    // å”¤é†’æ‰€æœ‰ç­‰å¾…çš„çº¿ç¨‹
    if (ctx_omni->llm_thread_info) {
        ctx_omni->llm_thread_info->cv.notify_all();
    }
    if (ctx_omni->tts_thread_info) {
        ctx_omni->tts_thread_info->cv.notify_all();
    }
    if (ctx_omni->t2w_thread_info) {
        ctx_omni->t2w_thread_info->cv.notify_all();
    }

    print_with_timestamp("omni_stop_threads: stop signals sent\n");
}

void omni_free(struct omni_context * ctx_omni) {
    // ç­‰å¾… llm å’Œ tts thread åœæ­¢
    llm_thread_running = false;                      // Signal the thread to stop
    if (ctx_omni->llm_thread.joinable()) {
        ctx_omni->llm_thread_info->cv.notify_all();  // Wake up the thread if it's waiting
        ctx_omni->llm_thread.join();                 // Wait for the thread to finish
    }

    if (ctx_omni->use_tts) {
        tts_thread_running = false;                      // Signal the thread to stop
        if (ctx_omni->tts_thread.joinable()) {
            ctx_omni->tts_thread_info->cv.notify_all();  // Wake up the thread if it's waiting
            ctx_omni->tts_thread.join();                 // Wait for the thread to finish
        }

        // Stop T2W thread
        t2w_thread_running = false;                      // Signal the thread to stop
        if (ctx_omni->t2w_thread.joinable()) {
            ctx_omni->t2w_thread_info->cv.notify_all();  // Wake up the thread if it's waiting
            ctx_omni->t2w_thread.join();                 // Wait for the thread to finish
        }
    }

    delete ctx_omni->ctx_vision;
    audition_free(ctx_omni->ctx_audio);

    if (ctx_omni->use_tts) {
        llama_free(ctx_omni->ctx_tts_llama);
        llama_free_model(ctx_omni->model_tts);
        common_sampler_free(ctx_omni->ctx_tts_sampler);

        // Free TTS weights
        if (ctx_omni->emb_code_weight) {
            free(ctx_omni->emb_code_weight);
            ctx_omni->emb_code_weight = nullptr;
        }
        if (ctx_omni->emb_text_weight) {
            free(ctx_omni->emb_text_weight);
            ctx_omni->emb_text_weight = nullptr;
        }
        if (ctx_omni->projector_semantic_linear1_weight) {
            free(ctx_omni->projector_semantic_linear1_weight);
            ctx_omni->projector_semantic_linear1_weight = nullptr;
        }
        if (ctx_omni->projector_semantic_linear1_bias) {
            free(ctx_omni->projector_semantic_linear1_bias);
            ctx_omni->projector_semantic_linear1_bias = nullptr;
        }
        if (ctx_omni->projector_semantic_linear2_weight) {
            free(ctx_omni->projector_semantic_linear2_weight);
            ctx_omni->projector_semantic_linear2_weight = nullptr;
        }
        if (ctx_omni->projector_semantic_linear2_bias) {
            free(ctx_omni->projector_semantic_linear2_bias);
            ctx_omni->projector_semantic_linear2_bias = nullptr;
        }
        if (ctx_omni->head_code_weight) {
            free(ctx_omni->head_code_weight);
            ctx_omni->head_code_weight = nullptr;
        }

        // Free C++ Token2Wav session
        if (ctx_omni->token2wav_session) {
            ctx_omni->token2wav_session.reset();
            ctx_omni->token2wav_initialized = false;
            LOG_INF("Token2Wav (C++): session released\n");
        }

        // ğŸ”§ åœæ­¢ Python Token2Wav æœåŠ¡
        if (ctx_omni->python_t2w_initialized) {
            stop_python_t2w_service(ctx_omni);
        }

        // Free ggml-based projector model
        if (ctx_omni->projector.initialized) {
            projector_free(ctx_omni->projector);
        }
    }

    // ğŸ”§ [å•åŒå·¥é€‚é…] åªæœ‰åœ¨æ‹¥æœ‰æ¨¡å‹æ—¶æ‰é‡Šæ”¾ LLM model å’Œ context
    // å¦‚æœæ˜¯å¤–éƒ¨ä¼ å…¥çš„æ¨¡å‹ï¼ˆæ¨¡å‹å¤ç”¨ï¼‰ï¼Œåˆ™ä¸é‡Šæ”¾
    if (ctx_omni->owns_model) {
        llama_free(ctx_omni->ctx_llama);
        llama_free_model(ctx_omni->model);
    }
    common_sampler_free(ctx_omni->ctx_sampler);
    // delete ctx_omni->ctx_tts;
    delete ctx_omni->llm_thread_info;
    delete ctx_omni->audio_input_manager;

    // omni_output è¿˜è¦æŠŠé‡Œé¢ output çš„æ¯ä¸ªå…ƒç´ ä¹Ÿ delete ä¸‹
    if (ctx_omni->use_tts) {
        delete ctx_omni->tts_thread_info;
        delete ctx_omni->t2w_thread_info;

        // omni_output è¿˜è¦æŠŠé‡Œé¢ output çš„æ¯ä¸ªå…ƒç´ ä¹Ÿ delete ä¸‹
        if (ctx_omni->omni_output) {
            for (auto & buffer : ctx_omni->omni_output->output) {
                delete buffer;
            }
            ctx_omni->omni_output->output.clear();  // Clear the vector
            delete ctx_omni->omni_output;
        }
    }

    llama_backend_free();

    delete ctx_omni;
}

// ==================== è¯­è¨€è®¾ç½®å‡½æ•° ====================
// è®¾ç½®è¯­è¨€å¹¶æ›´æ–° system promptï¼ˆzh=ä¸­æ–‡ï¼Œen=è‹±æ–‡ï¼‰
// åŸºäº Python MiniCPM-o-4_5 modeling_minicpmo.py ä¸­çš„ audio_assistant æ¨¡å¼ prompt
void omni_set_language(struct omni_context * ctx_omni, const std::string & lang) {
    if (ctx_omni == nullptr) {
        print_with_timestamp("omni_set_language: ctx_omni is null\n");
        return;
    }

    ctx_omni->language = lang;
    print_with_timestamp("omni_set_language: setting language to '%s'\n", lang.c_str());

    if (ctx_omni->duplex_mode) {
        // åŒå·¥æ¨¡å¼ï¼šprompt å›ºå®šä½¿ç”¨è‹±æ–‡ï¼ˆä¸ Python å¯¹é½ï¼‰
        ctx_omni->audio_voice_clone_prompt =
            "<|im_start|>system\nStreaming Duplex Conversation! You are a helpful assistant.\n<|audio_start|>";
        ctx_omni->audio_assistant_prompt = "<|audio_end|><|im_end|>\n";
        ctx_omni->omni_voice_clone_prompt =
            "<|im_start|>system\nStreaming Duplex Conversation! You are a helpful assistant.\n<|audio_start|>";
        ctx_omni->omni_assistant_prompt = "<|audio_end|><|im_end|>\n";
    } else {
        // éåŒå·¥æ¨¡å¼ï¼ˆaudio_assistant æ¨¡å¼ï¼‰ï¼šæ ¹æ®è¯­è¨€è®¾ç½® prompt
        if (lang == "en") {
            // è‹±æ–‡ promptï¼ˆæ¥è‡ª Python modeling_minicpmo.pyï¼‰
            ctx_omni->audio_voice_clone_prompt =
                "<|im_start|>system\nClone the voice in the provided audio prompt.\n<|audio_start|>";
            ctx_omni->audio_assistant_prompt =
                "<|audio_end|>Please assist users while maintaining this voice style. Please answer the user's "
                "questions seriously and in a high quality. Please chat with the user in a highly human-like and oral "
                "style. You are a helpful assistant developed by ModelBest: "
                "MiniCPM-Omni.<|im_end|>\n<|im_start|>user\n";

            ctx_omni->omni_voice_clone_prompt =
                "<|im_start|>system\nClone the voice in the provided audio prompt.\n<|audio_start|>";
            ctx_omni->omni_assistant_prompt =
                "<|audio_end|>Please assist users while maintaining this voice style. Please answer the user's "
                "questions seriously and in a high quality. Please chat with the user in a highly human-like and oral "
                "style.<|im_end|>\n<|im_start|>user\n";
        } else {
            // ä¸­æ–‡ promptï¼ˆé»˜è®¤ï¼Œæ¥è‡ª Python modeling_minicpmo.pyï¼‰
            ctx_omni->audio_voice_clone_prompt =
                "<|im_start|>system\næ¨¡ä»¿éŸ³é¢‘æ ·æœ¬çš„éŸ³è‰²å¹¶ç”Ÿæˆæ–°çš„å†…å®¹ã€‚\n<|audio_start|>";
            ctx_omni->audio_assistant_prompt =
                "<|audio_end|>"
                "ä½ çš„ä»»åŠ¡æ˜¯ç”¨è¿™ç§å£°éŸ³æ¨¡å¼æ¥å½“ä¸€ä¸ªåŠ©æ‰‹ã€‚è¯·è®¤çœŸã€é«˜è´¨é‡åœ°å›å¤ç”¨æˆ·çš„é—®é¢˜ã€‚è¯·ç”¨é«˜è‡ªç„¶åº¦çš„æ–¹å¼å’Œç”¨æˆ·èŠå¤©ã€‚ä½ "
                "æ˜¯ç”±é¢å£æ™ºèƒ½å¼€å‘çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼šé¢å£å°é’¢ç‚®ã€‚<|im_end|>\n<|im_start|>user\n";

            ctx_omni->omni_voice_clone_prompt =
                "<|im_start|>system\næ¨¡ä»¿éŸ³é¢‘æ ·æœ¬çš„éŸ³è‰²å¹¶ç”Ÿæˆæ–°çš„å†…å®¹ã€‚\n<|audio_start|>";
            ctx_omni->omni_assistant_prompt =
                "<|audio_end|>"
                "ä½ çš„ä»»åŠ¡æ˜¯ç”¨è¿™ç§å£°éŸ³æ¨¡å¼æ¥å½“ä¸€ä¸ªåŠ©æ‰‹ã€‚è¯·è®¤çœŸã€é«˜è´¨é‡åœ°å›å¤ç”¨æˆ·çš„é—®é¢˜ã€‚è¯·ç”¨é«˜è‡ªç„¶åº¦çš„æ–¹å¼å’Œç”¨æˆ·èŠå¤©ã€‚<|"
                "im_end|>\n<|im_start|>user\n";
        }
    }

    // ğŸ”§ [å…³é”®] é‡ç½® system_prompt_initializedï¼Œè®©ä¸‹æ¬¡ stream_prefill(index=0) é‡æ–° prefill system prompt
    ctx_omni->system_prompt_initialized = false;

    print_with_timestamp(
        "omni_set_language: prompts updated for language '%s', system_prompt_initialized reset to false\n",
        lang.c_str());
}

static void process_audio(struct omni_context * ctx_omni,
                          struct omni_embed *   embeds,
                          common_params *       params,
                          bool                  save_spk_emb = false) {
    LOG_INF("%s: audio token past: %d\n", __func__, ctx_omni->n_past);
    omni_eval_embed(ctx_omni->ctx_llama, embeds, params->n_batch, &ctx_omni->n_past);
    LOG_INF("%s: audio token past after eval: %d\n", __func__, ctx_omni->n_past);
}

void eval_prefix(struct omni_context * ctx_omni, common_params * params) {
    std::string prefix = "<|im_start|>user\n";
    std::cout << "prefix : " << prefix << std::endl;
    eval_string(ctx_omni, params, prefix.c_str(), params->n_batch, &ctx_omni->n_past, false);
}

void eval_prefix_with_hidden(struct omni_context * ctx_omni, common_params * params, float *& hidden_states) {
    std::string prefix = "<|im_start|>user\n";
    std::cout << "prefix : " << prefix << std::endl;
    eval_string_with_hidden(ctx_omni, params, prefix.c_str(), params->n_batch, &ctx_omni->n_past, false, hidden_states);
}

/**
 * LLMçº¿ç¨‹å‡½æ•°ï¼šè´Ÿè´£å¤„ç†å¤šæ¨¡æ€ï¼ˆè§†è§‰+éŸ³é¢‘ï¼‰åµŒå…¥çš„å‰ç¼€å¡«å……ï¼ˆprefillï¼‰
 * 
 * è¿™ä¸ªå‡½æ•°åœ¨ä¸€ä¸ªç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œï¼Œä¸»è¦èŒè´£æ˜¯ï¼š
 * 1. ä»é˜Ÿåˆ—ä¸­è·å–è§†è§‰å’ŒéŸ³é¢‘åµŒå…¥æ•°æ®
 * 2. å°†åµŒå…¥æ•°æ®ç»„åˆæˆLLMå¯ä»¥å¤„ç†çš„æ ¼å¼
 * 3. æ‰§è¡Œå‰ç¼€å¡«å……ï¼Œä¸ºåç»­çš„æ–‡æœ¬ç”Ÿæˆåšå‡†å¤‡
 * 4. åè°ƒä¸è§£ç çº¿ç¨‹çš„åŒæ­¥
 * 
 * è¿è¡Œé€»è¾‘ï¼š
 * - ä¸»å¾ªç¯æŒç»­è¿è¡Œï¼Œç›´åˆ° llm_thread_running ä¸º false
 * - ç­‰å¾…æ¡ä»¶ï¼šé˜Ÿåˆ—ä¸ä¸ºç©º OR need_speek ä¸º true OR çº¿ç¨‹éœ€è¦åœæ­¢
 * - ä¸¤ä¸ªä¸»è¦åˆ†æ”¯ï¼š
 *   åˆ†æ”¯1ï¼šé˜Ÿåˆ—ä¸ä¸ºç©º -> å¤„ç†åµŒå…¥æ•°æ®çš„å‰ç¼€å¡«å……
 *   åˆ†æ”¯2ï¼šé˜Ÿåˆ—ä¸ºç©ºä¸” need_speek ä¸º true -> é€šçŸ¥è§£ç çº¿ç¨‹å¯ä»¥å¼€å§‹ç”Ÿæˆ
 */
void llm_thread_func(omni_context * ctx_omni, common_params * params) {
    print_with_timestamp("LLM thread started\n");
    // è·å–æ¨¡å‹çš„éšè—å±‚ç»´åº¦ï¼Œç”¨äºè®¡ç®—tokenæ•°é‡
    const int hidden_size = llama_n_embd(llama_get_model(ctx_omni->ctx_llama));

    // ========== ä¸»å¾ªç¯ï¼šæŒç»­å¤„ç†åµŒå…¥æ•°æ® ==========
    while (llm_thread_running) {
        // è·å–é˜Ÿåˆ—çš„äº’æ–¥é”ï¼Œä¿æŠ¤å…±äº«èµ„æº
        std::unique_lock<std::mutex> lock(ctx_omni->llm_thread_info->mtx);
        auto &                       queue = ctx_omni->llm_thread_info->queue;

        // æ‰“å°å½“å‰çŠ¶æ€ï¼ˆè°ƒè¯•ç”¨ï¼‰

        // ========== ç­‰å¾…æ¡ä»¶æ»¡è¶³ ==========
        // ç­‰å¾…ä»¥ä¸‹ä»»ä¸€æ¡ä»¶æ»¡è¶³ï¼š
        // 1. é˜Ÿåˆ—ä¸ä¸ºç©ºï¼ˆæœ‰æ–°åµŒå…¥æ•°æ®éœ€è¦å¤„ç†ï¼‰
        // 2. need_speek ä¸º trueï¼ˆéœ€è¦å¼€å§‹ç”Ÿæˆæ–‡æœ¬ï¼‰
        // 3. llm_thread_running ä¸º falseï¼ˆçº¿ç¨‹éœ€è¦åœæ­¢ï¼‰
        ctx_omni->llm_thread_info->cv.wait(
            lock, [&] { return !queue.empty() || ctx_omni->need_speek || !llm_thread_running; });

        // æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢çº¿ç¨‹
        if (!llm_thread_running) {
            break;
        }

        // ========== åˆ†æ”¯1ï¼šå¤„ç†é˜Ÿåˆ—ä¸­çš„åµŒå…¥æ•°æ®ï¼ˆå‰ç¼€å¡«å……ï¼‰ ==========
        if (!queue.empty()) {
            // ğŸ”§ [è¯Šæ–­] æ‰“å° prefill å¼€å§‹æ—¶çš„ n_past
            print_with_timestamp("LLM thread: start prefill, n_past=%d, n_keep=%d, n_ctx=%d\n", ctx_omni->n_past,
                                 ctx_omni->n_keep, params->n_ctx);

            // ğŸ”§ [ä¿®å¤] prefill é˜¶æ®µä¸æ¸…é™¤ KV cacheï¼Œä¿æŒç´¯ç§¯
            // æ— è®ºå•å·¥è¿˜æ˜¯åŒå·¥æ¨¡å¼ï¼Œprefill éƒ½æ˜¯ç´¯ç§¯ç”¨æˆ·è¾“å…¥
            // KV cache åªåœ¨ä»¥ä¸‹æƒ…å†µæ¸…é™¤ï¼š
            //   1. æ–°ä¼šè¯å¼€å§‹ï¼ˆé€šè¿‡ reset APIï¼‰
            //   2. æ»‘åŠ¨çª—å£è§¦å‘ï¼ˆcontext æ»¡äº†ï¼‰
            print_with_timestamp("LLM thread: prefill continuing, n_past=%d (no KV cache clear)\n", ctx_omni->n_past);

            // æ ‡è®°å‰ç¼€å¡«å……æœªå®Œæˆï¼Œé˜²æ­¢è§£ç çº¿ç¨‹è¿‡æ—©å¼€å§‹
            prefill_done = false;

            // æ­¥éª¤1ï¼šæ‰¹é‡å–å‡ºé˜Ÿåˆ—ä¸­çš„æ‰€æœ‰åµŒå…¥æ•°æ®
            // è¿™æ ·å¯ä»¥ä¸€æ¬¡æ€§å¤„ç†å¤šä¸ªåµŒå…¥ï¼Œæé«˜æ•ˆç‡
            std::vector<omni_embeds *> llm_embeds;
            llm_embeds.clear();
            while (!queue.empty()) {
                llm_embeds.push_back(queue.front());
                queue.pop();
            }

            // é‡Šæ”¾é”ï¼Œå…è®¸å…¶ä»–çº¿ç¨‹ç»§ç»­å‘é˜Ÿåˆ—æ·»åŠ æ•°æ®
            lock.unlock();

            // å¦‚æœæ‰¹é‡å¤„ç†å¤šä¸ªåµŒå…¥ï¼Œæ‰“å°æ—¥å¿—
            print_with_timestamp("Batch processing %zu llm prefill\n", llm_embeds.size());
            if (llm_embeds.size() > 1) {
                // é€šçŸ¥ç­‰å¾…çš„ç”Ÿäº§è€…çº¿ç¨‹ï¼Œé˜Ÿåˆ—æœ‰ç©ºé—´äº†
                ctx_omni->llm_thread_info->cv.notify_all();
            }

            // ğŸ”§ [ä¸ Python å¯¹é½] åªæœ‰éåŒå·¥æ¨¡å¼æ‰æ·»åŠ  <|im_start|>user\n
            // åŒå·¥æ¨¡å¼: ç›´æ¥ç”¨ <unit> æ ‡è®°ç”¨æˆ·è¾“å…¥å¼€å§‹ï¼Œä¸éœ€è¦ <|im_start|>user\n
            // éåŒå·¥æ¨¡å¼: <|im_start|>system....<|im_end|>\n<|im_start|>user\n<|audio_start|>audio<|audio_end|><|im_end|>\n<|im_start|>assistant...
            // ğŸ”§ [æ•´åˆ] <|im_start|>user\n å·²åœ¨ sys prompt æœ«å°¾æ·»åŠ ï¼ˆç¬¬ä¸€è½®ï¼‰ï¼Œ
            // åç»­è½®æ¬¡åœ¨ stream_decode ç»“æŸæ—¶æ·»åŠ 
            // ä¸å†éœ€è¦åœ¨è¿™é‡ŒåŠ¨æ€æ·»åŠ 

            // ğŸ”§ [é‡æ„] é€ä¸ªå¤„ç†åµŒå…¥æ•°æ®ï¼Œæ­£ç¡®æ·»åŠ ç‰¹æ®Šæ ‡è®°
            // éå†æ‰€æœ‰åµŒå…¥æ•°æ®
            for (int il = 0; il < (int) llm_embeds.size(); ++il) {
                auto embeds = llm_embeds[il];

                // ğŸ”§ [#39 æ»‘åŠ¨çª—å£] æ³¨å†Œ unit å¼€å§‹
                if (ctx_omni->sliding_window_config.mode != "off") {
                    sliding_window_register_unit_start(ctx_omni);
                }

                // ========== å­åˆ†æ”¯1ï¼šå¤„ç†åŒ…å«è§†è§‰åµŒå…¥çš„æ•°æ® ==========
                // ğŸ”§ [é«˜æ¸…æ¨¡å¼] vision_embed ç°åœ¨æ˜¯äºŒç»´ vector: [0]=overview, [1..n]=slices
                if (embeds->vision_embed.size() > 0) {
                    int  n_chunks         = (int) embeds->vision_embed.size();
                    int  tokens_per_chunk = (int) embeds->vision_embed[0].size() / hidden_size;
                    int  n_audio_tokens   = embeds->audio_embed.size() / hidden_size;
                    bool has_audio        = (n_audio_tokens > 0);
                    bool has_slices       = (n_chunks > 1);

                    // ğŸ”§ [ä¸ Python å¯¹é½] æ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦æ·»åŠ  <unit>
                    if (ctx_omni->duplex_mode) {
                        eval_string(ctx_omni, params, "<unit><image>", params->n_batch, &ctx_omni->n_past, false);
                    } else {
                        eval_string(ctx_omni, params, "<image>", params->n_batch, &ctx_omni->n_past, false);
                    }

                    // Prefill overview embedding (ç¬¬ä¸€ä¸ª chunk)
                    prefill_with_emb(ctx_omni, params, embeds->vision_embed[0].data(), tokens_per_chunk,
                                     params->n_batch, &ctx_omni->n_past);
                    eval_string(ctx_omni, params, "</image>", params->n_batch, &ctx_omni->n_past, false);

                    // ğŸ”§ [é«˜æ¸…æ¨¡å¼ V2.6 schema] å¦‚æœæœ‰ slicesï¼Œæ·»åŠ  <slice> æ ‡è®°
                    // æ ¼å¼: <image>(overview)</image><slice>(slice1)</slice><slice>(slice2)</slice>\n
                    if (has_slices) {
                        for (int i = 1; i < n_chunks; i++) {
                            eval_string(ctx_omni, params, "<slice>", params->n_batch, &ctx_omni->n_past, false);
                            prefill_with_emb(ctx_omni, params, embeds->vision_embed[i].data(), tokens_per_chunk,
                                             params->n_batch, &ctx_omni->n_past);
                            eval_string(ctx_omni, params, "</slice>", params->n_batch, &ctx_omni->n_past, false);
                        }
                        // V2.6 æ ¼å¼åœ¨ slices åæ·»åŠ æ¢è¡Œ
                        eval_string(ctx_omni, params, "\n", params->n_batch, &ctx_omni->n_past, false);
                    }

                    print_with_timestamp(
                        "Omniæ¨¡å¼: %d vision chunks (%d tokens each), %d audio tokens, has_slices=%d\n", n_chunks,
                        tokens_per_chunk, n_audio_tokens, has_slices);

                    // éŸ³é¢‘éƒ¨åˆ†
                    if (has_audio) {
                        if (!ctx_omni->duplex_mode) {
                            // å•å·¥æ ¼å¼ï¼š<|audio_start|> + audio + <|audio_end|>
                            eval_string(ctx_omni, params, "<|audio_start|>", params->n_batch, &ctx_omni->n_past, false);
                        }
                        prefill_with_emb(ctx_omni, params, embeds->audio_embed.data(), n_audio_tokens, params->n_batch,
                                         &ctx_omni->n_past);
                        if (!ctx_omni->duplex_mode) {
                            eval_string(ctx_omni, params, "<|audio_end|>", params->n_batch, &ctx_omni->n_past, false);
                        }
                    }
                }
                // ========== å­åˆ†æ”¯2ï¼šå¤„ç†åªæœ‰éŸ³é¢‘åµŒå…¥çš„æ•°æ®ï¼ˆçº¯éŸ³é¢‘æ¨¡å¼ï¼‰ ==========
                else {
                    int n_audio_tokens = embeds->audio_embed.size() / hidden_size;
                    print_with_timestamp("ç”¨æˆ·è¯­éŸ³: %d audio tokens\n", n_audio_tokens);

                    // ğŸ”§ [æ ¹æ®æ¨¡å¼é€‰æ‹©æ ¼å¼]
                    if (ctx_omni->duplex_mode) {
                        // åŒå·¥æ ¼å¼ï¼š<unit> + audio_embeddingï¼ˆæ—  audio_start/endï¼‰
                        eval_string(ctx_omni, params, "<unit>", params->n_batch, &ctx_omni->n_past, false);
                    } else {
                        // å•å·¥æ ¼å¼ï¼š<|audio_start|> + audio + <|audio_end|>
                        eval_string(ctx_omni, params, "<|audio_start|>", params->n_batch, &ctx_omni->n_past, false);
                    }

                    // Prefill éŸ³é¢‘ embedding
                    prefill_with_emb(ctx_omni, params, embeds->audio_embed.data(), n_audio_tokens, params->n_batch,
                                     &ctx_omni->n_past);

                    // å•å·¥æ ¼å¼éœ€è¦ <|audio_end|>
                    if (!ctx_omni->duplex_mode) {
                        eval_string(ctx_omni, params, "<|audio_end|>", params->n_batch, &ctx_omni->n_past, false);
                    }
                }

                // ğŸ”§ [#39 æ»‘åŠ¨çª—å£] æ³¨å†Œ unit ç»“æŸ
                if (ctx_omni->sliding_window_config.mode != "off") {
                    std::string input_type = embeds->vision_embed.size() > 0 ? "omni" : "audio";
                    sliding_window_register_unit_end(ctx_omni, input_type, {}, false);
                }

                // é‡Šæ”¾åµŒå…¥æ•°æ®çš„å†…å­˜ï¼ˆç”±ç”Ÿäº§è€…çº¿ç¨‹åˆ†é…ï¼‰
                delete embeds;
            }

            // ğŸ”§ [è¯Šæ–­] æ‰“å° prefill ç»“æŸåçš„ n_past
            print_with_timestamp("LLM thread: prefill done, n_past=%d, n_keep=%d, æœ¬æ¬¡æ¶ˆè€— %d tokens, duplex_mode=%d\n",
                                 ctx_omni->n_past, ctx_omni->n_keep, ctx_omni->n_past - ctx_omni->n_keep,
                                 ctx_omni->duplex_mode);

            // ğŸ”§ [#39 æ»‘åŠ¨çª—å£] prefill å®Œæˆåæ£€æŸ¥æ˜¯å¦éœ€è¦æ»‘çª—
            if (ctx_omni->sliding_window_config.mode != "off") {
                sliding_window_enforce(ctx_omni);
            }
        }

        // ========== åˆ†æ”¯2ï¼šé˜Ÿåˆ—ä¸ºç©ºä¸”éœ€è¦å¼€å§‹ç”Ÿæˆæ–‡æœ¬ ==========
        // è¿™ä¸ªåˆ†æ”¯åœ¨ä»¥ä¸‹æƒ…å†µè§¦å‘ï¼š
        // 1. æ‰€æœ‰åµŒå…¥æ•°æ®éƒ½å·²å¤„ç†å®Œæˆï¼ˆé˜Ÿåˆ—ä¸ºç©ºï¼‰
        // 2. è§£ç çº¿ç¨‹è®¾ç½®äº† need_speek = trueï¼Œè¡¨ç¤ºéœ€è¦å¼€å§‹ç”Ÿæˆæ–‡æœ¬

        if (queue.empty() && ctx_omni->need_speek) {
            // æ ‡è®°å‰ç¼€å¡«å……å®Œæˆ
            prefill_done = true;

            // å¦‚æœä½¿ç”¨TTSï¼Œé‡ç½®speek_doneæ ‡å¿—ï¼Œå…è®¸TTSçº¿ç¨‹å¼€å§‹å·¥ä½œ
            if (ctx_omni->use_tts && !ctx_omni->duplex_mode) {
                ctx_omni->speek_done = false;
            }

            // é‡ç½®need_speekæ ‡å¿—
            ctx_omni->need_speek = false;

            // é€šçŸ¥ç­‰å¾…çš„è§£ç çº¿ç¨‹ï¼šå‰ç¼€å¡«å……å·²å®Œæˆï¼Œå¯ä»¥å¼€å§‹ç”Ÿæˆæ–‡æœ¬äº†
            g_decode_cv.notify_all();
        }
    }
}

// Special token IDs to filter (from file_loader.py)
// ğŸ”§ [ä¸ Python å¯¹é½] Python MiniCPMODuplex.streaming_generate ä¸­çš„è¿‡æ»¤é€»è¾‘ï¼š
//   1. chunk_speak_token_ids = [speak_token_id] ä¸­çš„ token ä¸ä¼šè¢«æ·»åŠ åˆ° TTS æ¡ä»¶
//   2. j != 0 æ¡ä»¶è·³è¿‡å¾ªç¯ä¸­çš„ç¬¬ä¸€ä¸ª token
// æ³¨æ„ï¼šè¿™äº› token å¤§éƒ¨åˆ†ä¹Ÿä¼šè¢« tid >= 150000 è§„åˆ™è¿‡æ»¤ï¼Œä½†æ˜¾å¼åˆ—å‡ºä¾¿äºç†è§£å’Œè°ƒè¯•
static const std::vector<llama_token> g_special_token_ids = {
    151667,  // <think>
    151668,  // </think>
    151704,  // <|tts_eos|> - TTS ç»“æŸæ ‡è®°
    151706,  // <|speak|> - ğŸ”§ Python çš„ chunk_speak_token_ids ä¼šè¿‡æ»¤æ­¤ token
    151705,  // <|listen|> - åŒå·¥æ¨¡å¼åˆ‡æ¢åˆ°å¬çš„æ ‡è®°
    151718,  // <|chunk_eos|> - chunk ç»“æŸæ ‡è®°
    151721,  // <|chunk_tts_eos|> - TTS chunk ç»“æŸæ ‡è®°
    151717,  // <|turn_eos|> - è½®æ¬¡ç»“æŸæ ‡è®°
    271,     // <reserved_182> (newline, appears near think tags)
};

// Known empty token IDs (from file_loader.py)
// WARNING: These tokens were incorrectly marked as "empty" but they actually decode to real text!
// 99692 = "å¥½çš„", 104314 = "ç»™ä½ ", 99526 = "è®²"
// DO NOT add tokens here without verifying they actually decode to empty string!
static const std::set<llama_token> g_known_empty_token_ids = {
    // Intentionally empty - no tokens confirmed to decode to truly empty strings
};

// Helper function to check if a token should be filtered out
// Returns true if the token is valid for TTS, false if it should be skipped
static bool is_valid_tts_token(llama_token tid) {
    // Skip special tokens
    for (llama_token sid : g_special_token_ids) {
        if (tid == sid) {
            return false;
        }
    }

    // Skip tokens >= 150000 (usually special tokens like <|im_end|>, <|tts_bos|>, etc.)
    if (tid >= 150000) {
        return false;
    }

    // Skip known empty tokens
    if (g_known_empty_token_ids.find(tid) != g_known_empty_token_ids.end()) {
        return false;
    }

    return true;
}

// Helper function to filter special tokens (matching Python file_loader.py logic)
static void filter_special_tokens(std::vector<llama_token> & token_ids,
                                  std::vector<float> &       hidden_states,
                                  int                        n_embd) {
    // Validate input: hidden_states should have size = token_ids.size() * n_embd
    if (hidden_states.size() != token_ids.size() * n_embd) {
        LOG_ERR("filter_special_tokens: hidden_states size (%zu) != token_ids.size() * n_embd (%zu * %d)\n",
                hidden_states.size(), token_ids.size(), n_embd);
        return;  // Don't filter if sizes don't match
    }

    size_t original_size = token_ids.size();

    // Filter out special tokens and tokens >= 150000
    // IMPORTANT: Keep token_ids and hidden_states aligned by filtering them together
    std::vector<llama_token> filtered_token_ids;
    std::vector<float>       filtered_hidden_states;

    for (size_t i = 0; i < token_ids.size(); ++i) {
        llama_token tid = token_ids[i];

        // Use the shared is_valid_tts_token function
        if (!is_valid_tts_token(tid)) {
            continue;
        }

        // Keep this token and its corresponding hidden state
        filtered_token_ids.push_back(tid);
        // Copy corresponding hidden state (n_embd floats per token)
        for (int j = 0; j < n_embd; ++j) {
            filtered_hidden_states.push_back(hidden_states[i * n_embd + j]);
        }
    }

    // Filter out leading empty tokens (already handled by is_valid_tts_token for known_empty_token_ids)
    size_t start_idx = 0;
    for (size_t i = 0; i < filtered_token_ids.size(); ++i) {
        if (g_known_empty_token_ids.find(filtered_token_ids[i]) == g_known_empty_token_ids.end()) {
            start_idx = i;
            break;
        }
    }

    // Apply start_idx filter to both token_ids and hidden_states
    if (start_idx > 0) {
        filtered_token_ids.erase(filtered_token_ids.begin(), filtered_token_ids.begin() + start_idx);
        filtered_hidden_states.erase(filtered_hidden_states.begin(),
                                     filtered_hidden_states.begin() + start_idx * n_embd);
    }

    // Validate alignment after filtering
    if (filtered_hidden_states.size() != filtered_token_ids.size() * n_embd) {
        LOG_ERR(
            "filter_special_tokens: alignment error after filtering! token_ids.size()=%zu, hidden_states.size()=%zu, "
            "n_embd=%d\n",
            filtered_token_ids.size(), filtered_hidden_states.size(), n_embd);
        return;  // Don't update if alignment is broken
    }

    // Update input vectors
    token_ids     = filtered_token_ids;
    hidden_states = filtered_hidden_states;

    if (original_size != token_ids.size()) {
    }
}

// ==============================================================================
// å•å·¥ç‰ˆæœ¬çš„ TTS Audio Token Generation
// ç›´æ¥ä» omni_sinplex.cpp å¤åˆ¶ï¼Œä¿è¯å•å·¥æ¨¡å¼è¡Œä¸ºå®Œå…¨ä¸€è‡´
// ==============================================================================
static bool generate_audio_tokens_local_simplex(
    struct omni_context *      ctx_omni,
    common_params *            params,
    const std::vector<float> & merged_embeddings,
    int                        n_tokens,
    int                        tts_n_embd,
    int                        chunk_idx,
    std::vector<int32_t> &     output_audio_tokens,
    const std::string &        output_dir          = "",
    bool                       is_final_text_chunk = false  // ğŸ”§ [ä¸ Python å¯¹é½] æ˜¯å¦æ˜¯æœ€åä¸€ä¸ª text chunk
) {
    print_with_timestamp("TTS Simplex: generating audio tokens for chunk %d (n_tokens=%d, tts_n_embd=%d)\n", chunk_idx,
                         n_tokens, tts_n_embd);

    const int audio_bos_token_id = 151687;
    const int num_audio_tokens   = 6562;
    // ğŸ”§ [ä¸ Python å¯¹é½] Python: max_new_token=500ï¼Œæ¯ä¸ª LLM condition ç”Ÿæˆç›´åˆ° EOS
    // ç„¶åæ¯ 25 ä¸ª tokens yield ä¸€æ¬¡
    const int max_audio_tokens   = 500;

    if (!ctx_omni->ctx_tts_llama || !ctx_omni->model_tts) {
        LOG_ERR("TTS Simplex: TTS model not loaded\n");
        return false;
    }

    if (!ctx_omni->head_code_weight || !ctx_omni->emb_code_weight) {
        LOG_ERR("TTS Simplex: TTS weights not loaded\n");
        return false;
    }

    if (merged_embeddings.size() != (size_t) (n_tokens * tts_n_embd)) {
        LOG_ERR("TTS Simplex: merged_embeddings size mismatch: %zu != %d * %d\n", merged_embeddings.size(), n_tokens,
                tts_n_embd);
        return false;
    }

    // ğŸ”§ [ä¿®å¤] åœ¨ prefill ä¹‹å‰åŠ¨æ€æ·»åŠ  audio_bos embedding
    // Python ä¸­ audio_bos æ˜¯åœ¨ TTS ç±»å†…éƒ¨ï¼ˆTTSStreamingGenerator.generate_with_bufferï¼‰æ·»åŠ çš„
    // æ¯ä¸ª chunk éƒ½ä¼šåŠ  audio_bos: condition = torch.cat([condition, self.audio_bos_embeds], dim=1)
    std::vector<float> condition_with_bos = merged_embeddings;  // å¤åˆ¶ä¸€ä»½
    int                extra_tokens       = 0;                  // é¢å¤–æ·»åŠ çš„ tokens æ•°é‡

    // ğŸ”§ [ä¿®å¤ text_eos_embed æ—¶æœº] text_eos_embed ä¸å†åœ¨ condition æ„å»ºé˜¶æ®µæ·»åŠ 
    // åŸå› ï¼šä¸€ä¸ª text chunk ä¼šç”Ÿæˆå¤šä¸ª audio chunkï¼Œtext_eos_embed æ”¾åœ¨ condition ä¸­
    // ä¼šå¯¼è‡´æ‰€æœ‰ audio chunk éƒ½å—åˆ°å½±å“ã€‚æ­£ç¡®åšæ³•æ˜¯åœ¨ç¬¬ä¸€è½® audio ç”Ÿæˆç»“æŸï¼ˆEOSï¼‰åï¼Œ
    // å†æ³¨å…¥ text_eos_embed + audio_bos åšç¬¬äºŒè½®ç”Ÿæˆï¼Œè¿™æ ·åªå½±å“æœ€åä¸€æ‰¹ audio tokensã€‚
    const int text_eos_token_id = 151692;  // TTS çš„ text_eos_token_id

    // ğŸ”§ [ä¸ Python å¯¹é½] åªæ·»åŠ  audio_bosï¼ˆæ€»æ˜¯æ·»åŠ ï¼‰
    // Python: condition = torch.cat([condition, self.audio_bos_embeds], dim=1)
    std::vector<float> audio_bos_embed(tts_n_embd, 0.0f);
    if (tts_emb_text(ctx_omni, audio_bos_token_id, audio_bos_embed.data(), tts_n_embd)) {
        condition_with_bos.insert(condition_with_bos.end(), audio_bos_embed.begin(), audio_bos_embed.end());
        extra_tokens++;
        print_with_timestamp("TTS Simplex: åœ¨ prefill å‰æ·»åŠ  audio_bos (chunk_idx=%d, new_size=%zu)\n", chunk_idx,
                             condition_with_bos.size() / tts_n_embd);
    } else {
        LOG_ERR("TTS Simplex: failed to get audio_bos embedding\n");
    }
    int n_tokens_with_bos = n_tokens + extra_tokens;  // åŒ…å« audio_bos

    // Save condition embeddings (åŒ…å« audio_bos)
    ctx_omni->tts_condition_embeddings = condition_with_bos;
    ctx_omni->tts_condition_length     = n_tokens_with_bos;
    ctx_omni->tts_condition_n_embd     = tts_n_embd;
    ctx_omni->tts_condition_saved      = true;

    int n_past_tts = 0;
    if (chunk_idx == 0) {
        // ç¬¬ä¸€ä¸ª chunkï¼šæ¸…ç©º KV cache
        llama_memory_t mem = llama_get_memory(ctx_omni->ctx_tts_llama);
        if (mem) {
            llama_memory_seq_rm(mem, 0, 0, -1);
            print_with_timestamp("TTS Simplex: first chunk - cleared KV cache\n");
        }
        ctx_omni->tts_n_past_accumulated = 0;
        ctx_omni->tts_all_generated_tokens.clear();
        ctx_omni->tts_token_buffer.clear();  // ğŸ”§ [ä¸ Python å¯¹é½] æ–°è½®å¯¹è¯æ¸…ç©º buffer
        print_with_timestamp("TTS Simplex: first chunk - cleared tts_all_generated_tokens and tts_token_buffer\n");
    } else {
        n_past_tts = ctx_omni->tts_n_past_accumulated;
        print_with_timestamp("TTS Simplex: chunk %d - keeping KV cache, n_past_tts=%d\n", chunk_idx, n_past_tts);
    }

    // ä½¿ç”¨åŒ…å« audio_bos çš„ condition è¿›è¡Œ prefill
    if (!prefill_with_emb_tts(ctx_omni, params, condition_with_bos.data(), n_tokens_with_bos, params->n_batch,
                              &n_past_tts)) {
        LOG_ERR("TTS Simplex: prefill_with_emb_tts failed\n");
        return false;
    }
    print_with_timestamp("TTS Simplex: prefill completed, n_past_tts=%d\n", n_past_tts);

    // Create sampler - matching Python TTSStreamingGenerator
    // Create sampler - matching Python TTSStreamingGenerator
    // Python TTSSamplingParams é»˜è®¤ temperature=0.8 (modeling_minicpmo.py line 75)
    common_params_sampling tts_sampling = params->sampling;
    tts_sampling.temp                   = 0.8f;  // ğŸ”§ [ä¸ Python å¯¹é½] TTSSamplingParams.temperature=0.8
    tts_sampling.top_p =
        0.85f;  // ğŸ”§ [ä¸ Python å¯¹é½] TTSSamplingParams.top_p=0.85   // ğŸ”§ [ä¸ Python streaming å¯¹é½] top_p=0.8
    tts_sampling.top_k          = 25;
    tts_sampling.penalty_repeat = 1.05f;
    tts_sampling.min_p          = 0.01f;
    tts_sampling.penalty_last_n = 16;

    struct common_sampler * tts_sampler = common_sampler_init(ctx_omni->model_tts, tts_sampling);
    if (!tts_sampler) {
        LOG_ERR("TTS Simplex: failed to create sampler\n");
        return false;
    }
    print_with_timestamp("TTS Simplex: sampler created\n");

    output_audio_tokens.clear();

    // ğŸ”§ [ä¸ Python å¯¹é½] ç»Ÿä¸€ä½¿ç”¨ tts_token_buffer ç®¡ç†ï¼Œå’Œ Python _token_buffer ä¸€è‡´
    // Python chunk_size=25ï¼Œæ¯å‡‘å¤Ÿ 25 ä¸ªæ‰ yield
    const int CHUNK_SIZE = 25;  // ä¸ Python TTSStreamingGenerator.chunk_size=25 å¯¹é½

    // ğŸ”§ [ä¸ Python å¯¹é½] ä¸å¼ºåˆ¶æœ€å°ç”Ÿæˆæ•°é‡ï¼Œè®© TTS è‡ªç„¶å†³å®šä½•æ—¶ç»“æŸ
    const int min_new_tokens = 0;

    // ğŸ”§ [ä¿®å¤ text_eos_embed æ—¶æœº] ä¸¤é˜¶æ®µç”Ÿæˆï¼š
    // Phase 1: ä¸å¸¦ text_eos_embedï¼Œæ­£å¸¸ç”Ÿæˆ audio tokens ç›´åˆ° EOS
    // Phase 2 (ä»… is_final_text_chunk): æ³¨å…¥ text_eos_embed + audio_bosï¼Œç”Ÿæˆæœ€åä¸€æ‰¹ audio tokens
    // è¿™æ · text_eos_embed åªå½±å“æœ€åä¸€æ‰¹ audio tokensï¼Œè€Œéæ•´ä¸ª text chunk çš„æ‰€æœ‰ audio
    bool need_phase2 = false;  // æ˜¯å¦éœ€è¦ç¬¬äºŒé˜¶æ®µç”Ÿæˆ

    // ===== Phase 1: æ­£å¸¸ç”Ÿæˆï¼ˆä¸å¸¦ text_eos_embedï¼‰ =====
    for (int t = 0; t < max_audio_tokens; ++t) {
        // ğŸ”§ [P0-ç«‹å³æ‰“æ–­] æ£€æµ‹ break_eventï¼Œç«‹å³åœæ­¢ TTS ç”Ÿæˆ
        if (ctx_omni->break_event.load()) {
            print_with_timestamp("TTS Simplex: break_event detected at step %d, stopping immediately\n", t);
            break;
        }

        // ğŸ”§ [ä¿®å¤è¿‡æ—©EOS] å¦‚æœè¿˜æ²¡è¾¾åˆ° min_new_tokensï¼Œé˜»æ­¢ EOS è¢«é‡‡æ ·
        bool force_no_eos = (t < min_new_tokens);

        // Phase 1 å§‹ç»ˆä½¿ç”¨ is_final_text_chunk=falseï¼šEOS ä¸ prefillï¼Œä¿æŒ KV cache å¹²å‡€
        llama_token sampled_token_abs = sample_tts_token_simplex(tts_sampler, ctx_omni, params, &n_past_tts,
                                                                 &ctx_omni->tts_all_generated_tokens, t, force_no_eos,
                                                                 false  // Phase 1: ä¸ prefill EOSï¼Œç•™ç»™ Phase 2 å¤„ç†
        );

        if (sampled_token_abs == 0) {
            LOG_ERR("TTS Simplex: sample_tts_token failed at step %d\n", t);
            break;
        }

        int relative_idx = sampled_token_abs - audio_bos_token_id;
        if (relative_idx < 0 || relative_idx >= num_audio_tokens) {
            LOG_ERR("TTS Simplex: invalid token ID %d at step %d\n", sampled_token_abs, t);
            break;
        }

        output_audio_tokens.push_back(relative_idx);
        ctx_omni->tts_all_generated_tokens.push_back(sampled_token_abs);

        // ğŸ”§ [ä¸ Python å¯¹é½] EOS token æ£€æµ‹
        bool is_eos = (relative_idx == num_audio_tokens - 1);
        if (is_eos) {
            print_with_timestamp("TTS Simplex Phase1: EOS token at step %d\n", t + 1);
            output_audio_tokens.pop_back();
            ctx_omni->tts_all_generated_tokens.pop_back();
            // å¦‚æœæ˜¯æœ€åä¸€ä¸ª text chunkï¼Œéœ€è¦è¿›å…¥ Phase 2
            if (is_final_text_chunk) {
                need_phase2 = true;
                print_with_timestamp("TTS Simplex: is_final_text_chunk=true, will enter Phase 2 for text_eos_embed\n");
            }
        } else {
            // ğŸ”§ [ä¸ Python å¯¹é½] é EOS token åŠ å…¥ tts_token_buffer
            ctx_omni->tts_token_buffer.push_back(relative_idx);
        }

        // ğŸ”§ [ä¸ Python å¯¹é½] å½“ buffer >= chunk_size æ—¶ï¼Œyield å‡º chunk_size ä¸ª
        while ((int) ctx_omni->tts_token_buffer.size() >= CHUNK_SIZE && ctx_omni->t2w_thread_info) {
            T2WOut * t2w_out = new T2WOut();
            t2w_out->audio_tokens.assign(ctx_omni->tts_token_buffer.begin(),
                                         ctx_omni->tts_token_buffer.begin() + CHUNK_SIZE);
            t2w_out->is_final  = false;
            t2w_out->round_idx = ctx_omni->simplex_round_idx;

            {
                std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                ctx_omni->t2w_thread_info->queue.push(t2w_out);
            }
            ctx_omni->t2w_thread_info->cv.notify_one();

            print_with_timestamp("TTS Simplex Phase1: yield %d tokens åˆ° T2W (step %d, buffer=%zu)\n", CHUNK_SIZE,
                                 t + 1, ctx_omni->tts_token_buffer.size());
            ctx_omni->tts_token_buffer.erase(ctx_omni->tts_token_buffer.begin(),
                                             ctx_omni->tts_token_buffer.begin() + CHUNK_SIZE);
        }

        if (t < 5 || (t + 1) % 25 == 0) {
            print_with_timestamp("TTS Simplex Phase1: token %d/%d: rel_id=%d\n", t + 1, max_audio_tokens, relative_idx);
        }

        // å¦‚æœæ˜¯ EOSï¼Œé€€å‡º Phase 1 å¾ªç¯
        if (is_eos) {
            break;
        }
    }

    // ===== Phase 2: æ³¨å…¥ text_eos_embedï¼Œç”Ÿæˆæœ€åä¸€æ‰¹ audio tokens =====
    // ä»…åœ¨ is_final_text_chunk ä¸” Phase 1 æ­£å¸¸ç»“æŸï¼ˆEOSï¼‰æ—¶æ‰§è¡Œ
    if (need_phase2 && !ctx_omni->break_event.load()) {
        print_with_timestamp("TTS Simplex Phase2: injecting text_eos_embed + audio_bos at n_past=%d\n", n_past_tts);

        // æ³¨å…¥ text_eos_embed åˆ° TTS KV cache
        std::vector<float> text_eos_embed(tts_n_embd, 0.0f);
        bool               inject_ok = false;
        if (tts_emb_text(ctx_omni, text_eos_token_id, text_eos_embed.data(), tts_n_embd)) {
            if (prefill_with_emb_tts(ctx_omni, params, text_eos_embed.data(), 1, 1, &n_past_tts)) {
                print_with_timestamp("TTS Simplex Phase2: text_eos_embed injected, n_past=%d\n", n_past_tts);

                // å†æ³¨å…¥ audio_bosï¼Œå¼€å§‹æ–°ä¸€è½® audio ç”Ÿæˆ
                std::vector<float> audio_bos_embed2(tts_n_embd, 0.0f);
                if (tts_emb_text(ctx_omni, audio_bos_token_id, audio_bos_embed2.data(), tts_n_embd)) {
                    if (prefill_with_emb_tts(ctx_omni, params, audio_bos_embed2.data(), 1, 1, &n_past_tts)) {
                        print_with_timestamp(
                            "TTS Simplex Phase2: audio_bos injected, n_past=%d, starting final generation\n",
                            n_past_tts);
                        inject_ok = true;
                    }
                }
            }
        }

        if (inject_ok) {
            // Phase 2 ç”Ÿæˆå¾ªç¯ï¼štext_eos_embed å·²æ³¨å…¥ï¼Œç”Ÿæˆæœ€åçš„ audio tokens
            for (int t2 = 0; t2 < max_audio_tokens; ++t2) {
                if (ctx_omni->break_event.load()) {
                    print_with_timestamp("TTS Simplex Phase2: break_event at step %d\n", t2);
                    break;
                }

                // Phase 2 ä½¿ç”¨ is_final_text_chunk=trueï¼šEOS ä¼šè¢« prefill
                llama_token sampled_token_abs = sample_tts_token_simplex(tts_sampler, ctx_omni, params, &n_past_tts,
                                                                         &ctx_omni->tts_all_generated_tokens, t2,
                                                                         false,  // ä¸å¼ºåˆ¶é˜»æ­¢ EOS
                                                                         true    // Phase 2: is_finalï¼ŒEOS ä¼šè¢« prefill
                );

                if (sampled_token_abs == 0) {
                    LOG_ERR("TTS Simplex Phase2: sample failed at step %d\n", t2);
                    break;
                }

                int relative_idx = sampled_token_abs - audio_bos_token_id;
                if (relative_idx < 0 || relative_idx >= num_audio_tokens) {
                    LOG_ERR("TTS Simplex Phase2: invalid token %d at step %d\n", sampled_token_abs, t2);
                    break;
                }

                output_audio_tokens.push_back(relative_idx);
                ctx_omni->tts_all_generated_tokens.push_back(sampled_token_abs);

                bool is_eos = (relative_idx == num_audio_tokens - 1);
                if (is_eos) {
                    print_with_timestamp("TTS Simplex Phase2: EOS at step %d (final end)\n", t2 + 1);
                    output_audio_tokens.pop_back();
                    ctx_omni->tts_all_generated_tokens.pop_back();
                } else {
                    ctx_omni->tts_token_buffer.push_back(relative_idx);
                }

                // yield audio chunks
                while ((int) ctx_omni->tts_token_buffer.size() >= CHUNK_SIZE && ctx_omni->t2w_thread_info) {
                    T2WOut * t2w_out = new T2WOut();
                    t2w_out->audio_tokens.assign(ctx_omni->tts_token_buffer.begin(),
                                                 ctx_omni->tts_token_buffer.begin() + CHUNK_SIZE);
                    t2w_out->is_final  = false;
                    t2w_out->round_idx = ctx_omni->simplex_round_idx;
                    {
                        std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                        ctx_omni->t2w_thread_info->queue.push(t2w_out);
                    }
                    ctx_omni->t2w_thread_info->cv.notify_one();
                    print_with_timestamp("TTS Simplex Phase2: yield %d tokens åˆ° T2W\n", CHUNK_SIZE);
                    ctx_omni->tts_token_buffer.erase(ctx_omni->tts_token_buffer.begin(),
                                                     ctx_omni->tts_token_buffer.begin() + CHUNK_SIZE);
                }

                if (is_eos) {
                    break;
                }
            }
        } else {
            LOG_ERR("TTS Simplex Phase2: failed to inject text_eos_embed/audio_bos\n");
        }
    }

    // ğŸ”§ [ä¸ Python å¯¹é½] chunk ç»“æŸæ—¶ï¼Œtts_token_buffer ä¸­å¯èƒ½æœ‰å‰©ä½™çš„ tokens (< CHUNK_SIZE)
    // è¿™äº› tokens ä¿ç•™åœ¨ buffer ä¸­ï¼Œç­‰ä¸‹ä¸€ä¸ª text chunk ç»§ç»­ç´¯ç§¯
    // åªæœ‰ is_final_text_chunk æ—¶æ‰ flush æ‰€æœ‰å‰©ä½™
    print_with_timestamp("TTS Simplex: chunk ç»“æŸï¼Œtts_token_buffer å‰©ä½™ %zu tokens (ä¿ç•™ç­‰ä¸‹ä¸€ä¸ª chunk)\n",
                         ctx_omni->tts_token_buffer.size());

    // ğŸ”§ [ä¸ Python å¯¹é½] åªæœ‰æœ€åä¸€ä¸ª text chunk æ—¶æ‰ flush å‰©ä½™çš„ buffer
    // Python: if finished.all() and text_finished: yield all remaining; buffer = []
    if (is_final_text_chunk && !ctx_omni->tts_token_buffer.empty() && ctx_omni->t2w_thread_info) {
        T2WOut * t2w_out = new T2WOut();
        t2w_out->audio_tokens.assign(ctx_omni->tts_token_buffer.begin(), ctx_omni->tts_token_buffer.end());
        t2w_out->is_final  = false;  // æ³¨æ„ï¼šè¿™é‡Œä¸è®¾ is_final=trueï¼Œis_final ç”± tts_thread_func åœ¨ llm_finish æ—¶å‘é€
        t2w_out->round_idx = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•

        {
            std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
            ctx_omni->t2w_thread_info->queue.push(t2w_out);
        }
        ctx_omni->t2w_thread_info->cv.notify_one();

        print_with_timestamp("TTS Simplex: is_final_text_chunk=true, flush å‰©ä½™ %zu tokens ä» tts_token_buffer\n",
                             ctx_omni->tts_token_buffer.size());
        ctx_omni->tts_token_buffer.clear();
    }

    // ğŸ”§ [ä¸ Python å¯¹é½] åªæœ‰ duplex_mode æ—¶æ‰å‘é€ is_chunk_end ä¿¡å·
    // å•å·¥æ¨¡å¼ä¸‹ï¼ŒT2W ä¾èµ–æ»‘åŠ¨çª—å£æœºåˆ¶ï¼Œä¸­é—´ chunk ä¸éœ€è¦ flush
    if (ctx_omni->duplex_mode && ctx_omni->t2w_thread_info) {
        T2WOut * t2w_out = new T2WOut();
        t2w_out->audio_tokens.clear();                        // ç©ºçš„ token åˆ—è¡¨
        t2w_out->is_final     = false;                        // Not final (turn not ended)
        t2w_out->is_chunk_end = true;                         // ğŸ”§ æ ‡è®° chunk ç»“æŸï¼ŒT2W éœ€è¦ flush buffer
        t2w_out->round_idx    = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•

        {
            std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
            ctx_omni->t2w_thread_info->queue.push(t2w_out);
        }
        ctx_omni->t2w_thread_info->cv.notify_one();
        print_with_timestamp("TTS Simplex: å‘é€ is_chunk_end=true ä¿¡å·\n");
    }

    common_sampler_free(tts_sampler);

    print_with_timestamp("TTS Simplex: generated %zu audio tokens for chunk %d\n", output_audio_tokens.size(),
                         chunk_idx);

    // ğŸ”§ [è¯Šæ–­] è¾“å‡ºå‰å‡ ä¸ªå’Œåå‡ ä¸ª audio tokensï¼Œå¸®åŠ©å®šä½é‡å¤é—®é¢˜
    if (output_audio_tokens.size() > 0) {
        std::string first_tokens = "";
        std::string last_tokens  = "";
        int         show_count   = std::min((int) output_audio_tokens.size(), 5);
        for (int i = 0; i < show_count; i++) {
            first_tokens += std::to_string(output_audio_tokens[i]) + " ";
        }
        for (int i = std::max(0, (int) output_audio_tokens.size() - 5); i < (int) output_audio_tokens.size(); i++) {
            last_tokens += std::to_string(output_audio_tokens[i]) + " ";
        }
        print_with_timestamp("TTS Simplex: chunk %d first tokens: [%s], last tokens: [%s]\n", chunk_idx,
                             first_tokens.c_str(), last_tokens.c_str());
    }

    ctx_omni->tts_n_past_accumulated = n_past_tts;
    print_with_timestamp("TTS Simplex: updated tts_n_past_accumulated=%d, total_generated_tokens=%zu\n",
                         ctx_omni->tts_n_past_accumulated, ctx_omni->tts_all_generated_tokens.size());

    // Save tokens to file if output_dir is specified
    if (!output_dir.empty() && !output_audio_tokens.empty()) {
        std::string tokens_file = output_dir + "/audio_tokens_chunk_" + std::to_string(chunk_idx) + ".bin";
        FILE *      f           = fopen(tokens_file.c_str(), "wb");
        if (f) {
            fwrite(output_audio_tokens.data(), sizeof(int32_t), output_audio_tokens.size(), f);
            fclose(f);
        }
    }

    return !output_audio_tokens.empty();
}

// ==============================================================================
// Local TTS Audio Token Generation
// Uses the verified TTS model to generate audio tokens from merged_embeddings
// ==============================================================================
static bool generate_audio_tokens_local(struct omni_context *      ctx_omni,
                                        common_params *            params,
                                        const std::vector<float> & merged_embeddings,
                                        int                        n_tokens,
                                        int                        tts_n_embd,
                                        int                        chunk_idx,
                                        std::vector<int32_t> &     output_audio_tokens,
                                        bool is_end_of_turn            = false,  // ğŸ”§ [ä¸ Python å¯¹é½] æ˜¯å¦æ˜¯è½®æ¬¡ç»“æŸ
                                        const std::string & output_dir = "") {
    print_with_timestamp("TTS Local: generating audio tokens for chunk %d (n_tokens=%d, tts_n_embd=%d, emb_size=%zu)\n",
                         chunk_idx, n_tokens, tts_n_embd, merged_embeddings.size());

    // ğŸ”§ [å®‰å…¨æ£€æŸ¥] éªŒè¯è¾“å…¥å‚æ•°
    // ğŸ”§ [ä¿®å¤å°¾éŸ³é—®é¢˜] å½“ is_end_of_turn=true æ—¶ï¼Œå…è®¸ n_tokens=0
    // å› ä¸ºæˆ‘ä»¬ä¼šæ·»åŠ  text_eos_embed å’Œ audio_bosï¼Œè®© TTS ç”Ÿæˆæœ€åçš„ audio tokens
    if (n_tokens < 0) {
        LOG_ERR("TTS Local: invalid n_tokens=%d\n", n_tokens);
        return false;
    }
    if (n_tokens == 0 && !is_end_of_turn) {
        LOG_ERR("TTS Local: n_tokens=0 but is_end_of_turn=false, nothing to generate\n");
        return false;
    }
    if (n_tokens > 10000) {
        LOG_ERR("TTS Local: n_tokens=%d seems too large, likely data corruption\n", n_tokens);
        return false;
    }
    if (tts_n_embd <= 0 || tts_n_embd > 10000) {
        LOG_ERR("TTS Local: invalid tts_n_embd=%d\n", tts_n_embd);
        return false;
    }

    // ğŸ”§ [DEBUG] è®°å½•ç‰¹æ®Šæƒ…å†µ
    if (n_tokens == 0 && is_end_of_turn) {
        print_with_timestamp(
            "TTS Local: n_tokens=0 but is_end_of_turn=true, will add text_eos_embed and generate final tokens\n");
    }

    // TTS model constants
    const int audio_bos_token_id = 151687;
    const int num_audio_tokens   = 6562;
    // ğŸ”§ [å•åŒå·¥é€‚é…] max_audio_tokens:
    // - åŒå·¥æ¨¡å¼: 26 (ä¸ Python å¯¹é½ï¼Œmax_token_per_chunk = 25 + 1)
    // - å•å·¥æ¨¡å¼: 500 (å…è®¸æ›´é•¿çš„ç”Ÿæˆï¼Œé  EOS ç»“æŸ)
    const int max_audio_tokens   = ctx_omni->duplex_mode ? 26 : 500;
    print_with_timestamp("TTS Local: mode=%s, max_audio_tokens=%d\n", ctx_omni->duplex_mode ? "duplex" : "simplex",
                         max_audio_tokens);

    // Verify TTS model is loaded
    if (!ctx_omni->ctx_tts_llama || !ctx_omni->model_tts) {
        LOG_ERR("TTS Local: TTS model not loaded\n");
        return false;
    }

    // Verify TTS weights are loaded
    if (!ctx_omni->head_code_weight || !ctx_omni->emb_code_weight) {
        LOG_ERR("TTS Local: TTS weights not loaded (head_code or emb_code)\n");
        return false;
    }

    // Verify merged_embeddings size
    if (merged_embeddings.size() != (size_t) (n_tokens * tts_n_embd)) {
        LOG_ERR("TTS Local: merged_embeddings size mismatch: %zu != %d * %d\n", merged_embeddings.size(), n_tokens,
                tts_n_embd);
        return false;
    }

    // ğŸ”§ [ä¿®å¤] åœ¨ prefill ä¹‹å‰åŠ¨æ€æ·»åŠ  text_eos_embedï¼ˆå¦‚æœæ˜¯è½®æ¬¡ç»“æŸï¼‰å’Œ audio_bos embedding
    // Python TTSStreamingGenerator.generate_with_buffer é€»è¾‘ï¼š
    //   if text_finished: condition = torch.cat([condition, self.text_eos_embed], dim=1)
    //   condition = torch.cat([condition, self.audio_bos_embeds], dim=1)
    std::vector<float> condition_with_bos = merged_embeddings;  // å¤åˆ¶ä¸€ä»½
    int                extra_tokens       = 0;

    // ğŸ”§ [ä¸ Python å¯¹é½] å¦‚æœæ˜¯è½®æ¬¡ç»“æŸï¼Œå…ˆæ·»åŠ  text_eos_embed
    // Python: if text_finished: condition = torch.cat([condition, self.text_eos_embed], dim=1)
    const int text_eos_token_id = 151692;  // TTS çš„ text_eos_token_id
    if (is_end_of_turn) {
        std::vector<float> text_eos_embed(tts_n_embd, 0.0f);
        if (tts_emb_text(ctx_omni, text_eos_token_id, text_eos_embed.data(), tts_n_embd)) {
            condition_with_bos.insert(condition_with_bos.end(), text_eos_embed.begin(), text_eos_embed.end());
            extra_tokens++;
            print_with_timestamp("TTS Local: is_end_of_turn=true, æ·»åŠ  text_eos_embed (chunk_idx=%d, new_size=%zu)\n",
                                 chunk_idx, condition_with_bos.size() / tts_n_embd);
        } else {
            LOG_WRN("TTS Local: failed to get text_eos embedding\n");
        }
    }

    // ğŸ”§ [ä¸ Python å¯¹é½] ç„¶åæ·»åŠ  audio_bosï¼ˆæ€»æ˜¯æ·»åŠ ï¼‰
    // Python: condition = torch.cat([condition, self.audio_bos_embeds], dim=1)
    std::vector<float> audio_bos_embed(tts_n_embd, 0.0f);
    if (tts_emb_text(ctx_omni, audio_bos_token_id, audio_bos_embed.data(), tts_n_embd)) {
        condition_with_bos.insert(condition_with_bos.end(), audio_bos_embed.begin(), audio_bos_embed.end());
        extra_tokens++;
        print_with_timestamp("TTS Local: åœ¨ prefill å‰æ·»åŠ  audio_bos (chunk_idx=%d, new_size=%zu)\n", chunk_idx,
                             condition_with_bos.size() / tts_n_embd);
    } else {
        LOG_ERR("TTS Local: failed to get audio_bos embedding\n");
    }
    int n_tokens_with_bos = n_tokens + extra_tokens;  // åŒ…å« text_eos_embedï¼ˆå¦‚æœæœ‰ï¼‰å’Œ audio_bos

    // Save condition embeddings for re-forward in sample_tts_token (åŒ…å« audio_bos)
    ctx_omni->tts_condition_embeddings = condition_with_bos;
    ctx_omni->tts_condition_length     = n_tokens_with_bos;
    ctx_omni->tts_condition_n_embd     = tts_n_embd;
    ctx_omni->tts_condition_saved      = true;
    // Python TTSStreamingGenerator é€»è¾‘ï¼š
    // - idx == 0ï¼šæ¸…ç©º KV cacheï¼Œä»å¤´å¼€å§‹ï¼Œå¹¶æ‹¼æ¥ spk_emb
    // - idx > 0ï¼šä¿æŒ past_key_valuesï¼Œç»§ç»­ç”Ÿæˆ
    // è¿™æ · TTS æ¨¡å‹å¯ä»¥ä¿æŒä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼Œé¿å…æå‰ç”Ÿæˆ EOS
    int n_past_tts                     = 0;
    if (chunk_idx == 0) {
        // ç¬¬ä¸€ä¸ª chunkï¼šæ¸…ç©º KV cache å’Œç´¯ç§¯çŠ¶æ€
        llama_memory_t mem = llama_get_memory(ctx_omni->ctx_tts_llama);
        if (mem) {
            llama_memory_seq_rm(mem, 0, 0, -1);
            print_with_timestamp("TTS Local: first chunk - cleared KV cache\n");
        }
        ctx_omni->tts_n_past_accumulated = 0;  // é‡ç½®ç´¯è®¡ n_past
        ctx_omni->tts_all_generated_tokens.clear();
        if (!ctx_omni->duplex_mode) {
            ctx_omni->tts_token_buffer.clear();  // ğŸ”§ [ä¸ Python å¯¹é½] æ–°è½®å¯¹è¯æ¸…ç©º bufferï¼ˆä»…å•å·¥æ¨¡å¼ï¼‰
        }
        print_with_timestamp("TTS Local: first chunk - cleared tts_all_generated_tokens and tts_token_buffer\n");
    } else {
        // åç»­ chunkï¼šä¿æŒ KV cacheï¼Œç»§ç»­ä½¿ç”¨ç´¯è®¡çš„ n_past
        n_past_tts = ctx_omni->tts_n_past_accumulated;
        print_with_timestamp("TTS Local: chunk %d - keeping KV cache, n_past_tts=%d\n", chunk_idx, n_past_tts);
    }
    // ä½¿ç”¨åŒ…å« audio_bos çš„ condition è¿›è¡Œ prefill
    if (!prefill_with_emb_tts(ctx_omni, params, condition_with_bos.data(), n_tokens_with_bos, params->n_batch,
                              &n_past_tts)) {
        LOG_ERR("TTS Local: prefill_with_emb_tts failed\n");
        return false;
    }
    print_with_timestamp("TTS Local: prefill completed, n_past_tts=%d\n", n_past_tts);

    // 2. Create sampler for TTS with correct TTS sampling parameters
    // ğŸ”§ TTSæµå¼é‡‡æ ·å‚æ•° - ä¸ Python TTSStreamingGenerator å¯¹é½
    // Python TTSSamplingParams é»˜è®¤ temperature=0.8 (modeling_minicpmo.py line 75)
    common_params_sampling tts_sampling = params->sampling;
    tts_sampling.temp                   = 0.8f;  // ğŸ”§ [ä¸ Python å¯¹é½] TTSSamplingParams.temperature=0.8
    tts_sampling.top_p =
        0.85f;  // ğŸ”§ [ä¸ Python å¯¹é½] TTSSamplingParams.top_p=0.85             // ğŸ”§ [ä¸ Python streaming å¯¹é½] top_p=0.8
    tts_sampling.top_k          = 25;     // top_k = 25
    tts_sampling.penalty_repeat = 1.05f;  // repetition_penalty = 1.05
    tts_sampling.min_p          = 0.01f;  // min_p = 0.01
    tts_sampling.penalty_last_n = 16;     // past_window = 16 (ä¸Pythonå¯¹é½)

    struct common_sampler * tts_sampler = common_sampler_init(ctx_omni->model_tts, tts_sampling);
    if (!tts_sampler) {
        LOG_ERR("TTS Local: failed to create sampler\n");
        return false;
    }

    // 3. Generate audio tokens with streaming to T2W queue
    output_audio_tokens.clear();
    // Python: self.all_generated_tokens æ˜¯ç±»æˆå‘˜å˜é‡ï¼Œè·¨ chunk æŒç»­ç´¯ç§¯
    // ç”¨äºï¼š1. æ­£ç¡®åˆ¤æ–­æ˜¯å¦æ˜¯æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹çš„ç¬¬ä¸€ä¸ª tokenï¼ˆre-forward conditionï¼‰

    // ğŸ”§ [å·®å¼‚3ä¿®å¤] å½“å‰ chunk çš„ tokensï¼Œç”¨äº repetition penalty
    // Python generate_chunk: input_ids_sliced = new_tokens[:, 0:t]  # åªç”¨å½“å‰ chunk å†…çš„ tokens
    std::vector<llama_token> chunk_generated_tokens;

    // ğŸ”§ [å•åŒå·¥é€‚é…] min_new_tokens é€»è¾‘
    // - åŒå·¥æ¨¡å¼: ä¸ Python streaming_generate å¯¹é½
    //   max_token_per_chunk = 25 + 1  # 26
    //   min_token_per_chunk = 25 + 1  # 26
    //   if end_of_turn: min_token_per_chunk = 0
    // - å•å·¥æ¨¡å¼: è®¾ç½®æœ€å° 100 ä¸ª tokensï¼Œé˜²æ­¢ TTS è¿‡æ—©ç”Ÿæˆ EOS
    //   10 ä¸ªä¸­æ–‡å­—çº¦éœ€è¦ 100-150 ä¸ª audio tokens (æ¯å­— 10-15 tokens)
    const int min_new_tokens =
        ctx_omni->duplex_mode ? (is_end_of_turn ? 0 : 26) : 100;  // ğŸ”§ å•å·¥æ¨¡å¼ï¼šè‡³å°‘ç”Ÿæˆ 100 ä¸ª tokens é˜²æ­¢è¿‡æ—© EOS

    // ğŸš€ æµæ°´çº¿ä¼˜åŒ–ï¼šToken2Wavéœ€è¦28ä¸ªtokens (25+3 lookahead)æ‰èƒ½è¾“å‡ºéŸ³é¢‘
    // é¦–æ‰¹28ä¸ªtokensåæ¨é€ï¼Œåç»­æ¯25ä¸ªtokensæ¨é€ä¸€æ¬¡
    const int            STREAM_CHUNK_SIZE  = 25;
    const int            FIRST_CHUNK_SIZE   = 28;  // é¦–æ‰¹æ¨é€é˜ˆå€¼ï¼Œå‡å°‘é¦–å“æ—¶é—´
    bool                 first_chunk_pushed = false;
    std::vector<int32_t> stream_buffer;

    for (int t = 0; t < max_audio_tokens; ++t) {
        // ğŸ”§ [å·®å¼‚1ä¿®å¤] è®¡ç®— force_no_eos
        // Python generate_chunk: if force_no_stop or t < min_new_tokens: logits[:, eos_token] = -torch.inf
        // å¦‚æœè¿˜æ²¡è¾¾åˆ° min_new_tokensï¼Œé˜»æ­¢ EOS è¢«é‡‡æ ·ï¼ˆåœ¨é‡‡æ ·å‰è®¾ç½® EOS logit ä¸º -infï¼‰
        bool force_no_eos = (t < min_new_tokens);

        // Sample next token
        // ğŸ”§ [å·®å¼‚2&3ä¿®å¤] ä¼ å…¥ï¼š
        // - all_generated_tokens: ç”¨äºåˆ¤æ–­æ˜¯å¦æ˜¯æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹çš„ç¬¬ä¸€ä¸ª token
        // - chunk_generated_tokens: ç”¨äº repetition penaltyï¼ˆåªç”¨å½“å‰ chunk çš„ tokensï¼‰
        // - t: token_index_in_chunkï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦è·³è¿‡ sampling processors
        // - force_no_eos: æ˜¯å¦é˜»æ­¢ EOSï¼ˆç”¨äº min_new_tokens é€»è¾‘ï¼‰
        // - is_end_of_turn: æ˜¯å¦æ˜¯ final chunkï¼ˆEOS æ˜¯å¦åº”åŠ å…¥ KV cacheï¼‰
        llama_token sampled_token_abs =
            sample_tts_token(tts_sampler, ctx_omni, params, &n_past_tts,
                             &ctx_omni->tts_all_generated_tokens,  // ç”¨äºåˆ¤æ–­ is_first_token_overall
                             &chunk_generated_tokens,              // ğŸ”§ [å·®å¼‚3ä¿®å¤] ç”¨äº repetition penalty
                             t,                                    // token_index_in_chunk
                             force_no_eos,                         // ğŸ”§ [å·®å¼‚1ä¿®å¤] é˜»æ­¢ EOS
                             is_end_of_turn                        // ğŸ”§ [ä¸ Python å¯¹é½] EOS æ˜¯å¦åŠ å…¥ KV cache
            );

        if (sampled_token_abs == 0) {
            LOG_ERR("TTS Local: sample_tts_token failed at step %d\n", t);
            break;
        }

        // Convert to relative index and check EOS
        int relative_idx = sampled_token_abs - audio_bos_token_id;
        if (relative_idx < 0 || relative_idx >= num_audio_tokens) {
            LOG_ERR("TTS Local: invalid token ID %d (relative_idx: %d) at step %d\n", sampled_token_abs, relative_idx,
                    t);
            break;
        }

        // Store token (as absolute ID for internal use, will convert to relative for output)
        output_audio_tokens.push_back(relative_idx);  // Store relative ID for token2wav
        stream_buffer.push_back(relative_idx);        // Also add to stream buffer
        ctx_omni->tts_all_generated_tokens.push_back(sampled_token_abs);
        // ğŸ”§ [å·®å¼‚3ä¿®å¤] æ·»åŠ åˆ°å½“å‰ chunk çš„åˆ—è¡¨
        chunk_generated_tokens.push_back(sampled_token_abs);

        // ğŸ”§ [ä¸ Python å¯¹é½] EOS token æ£€æµ‹ - å¿…é¡»åœ¨æµå¼æ¨é€ä¹‹å‰
        // Python: if next_id.eq(self.eos_token).any(): finished[:] = True; else: æ·»åŠ åˆ° buffer
        // å¦‚æœæ˜¯ EOSï¼Œç«‹å³ä» buffer ä¸­ç§»é™¤ï¼Œé˜²æ­¢è¢«æ¨é€åˆ° T2W
        bool is_eos = (relative_idx == num_audio_tokens - 1);
        if (is_eos) {
            output_audio_tokens.pop_back();
            stream_buffer.pop_back();
            chunk_generated_tokens.pop_back();
            ctx_omni->tts_all_generated_tokens.pop_back();
            // ä¸ breakï¼Œç»§ç»­æ‰§è¡Œåç»­é€»è¾‘ï¼ˆåŒ…æ‹¬å¯èƒ½çš„æµå¼æ¨é€å‰©ä½™ tokensï¼‰
        }

        // ğŸ”§ [ä¸ Python æµå¼åŒå·¥å¯¹é½] æµå¼æ¨é€ï¼Œä½†ä¿ç•™ lookahead
        // Python _generate_waveform_from_tokens é€»è¾‘ï¼š
        //   while len(buffer) >= CHUNK_SIZE + pre_lookahead:  # 28
        //       stream(buffer[:28])
        //       buffer = buffer[CHUNK_SIZE:]  # åªç§»é™¤ 25 ä¸ªï¼Œä¿ç•™ 3 ä¸ª lookahead
        //
        // å…³é”®ï¼šæˆ‘ä»¬æ¨é€æ‰€æœ‰å¯ç”¨çš„ tokensï¼Œä½† T2W ç«¯è´Ÿè´£ä¿ç•™ lookahead
        // è¿™é‡Œæˆ‘ä»¬æ¯ 25 ä¸ª tokens æ¨é€ä¸€æ¬¡ï¼Œè®© T2W ç«¯çš„æ»‘åŠ¨çª—å£æ­£ç¡®å¤„ç†
        // ğŸ”§ [ä¸ Python å¯¹é½] is_end_of_turn æ—¶ä¸è¿›è¡Œæµå¼æ¨é€ï¼Œè®©æ‰€æœ‰ tokens åœ¨æœ€åä¸€èµ·å‘é€
        // è¿™æ · T2W æ‰èƒ½ä¸€æ¬¡æ€§ flush æ‰€æœ‰ bufferï¼Œè¾“å‡ºå®Œæ•´éŸ³é¢‘
        int push_threshold = first_chunk_pushed ? STREAM_CHUNK_SIZE : FIRST_CHUNK_SIZE;
        if ((int) stream_buffer.size() >= push_threshold && ctx_omni->t2w_thread_info && !is_end_of_turn) {
            first_chunk_pushed = true;
            T2WOut * t2w_out   = new T2WOut();
            t2w_out->audio_tokens.assign(stream_buffer.begin(), stream_buffer.end());
            t2w_out->is_final     = false;
            t2w_out->is_chunk_end = false;                        // ğŸ”§ ä¸­é—´æ¨é€ï¼Œä¸æ˜¯ chunk ç»“æŸ
            t2w_out->round_idx    = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•

            {
                std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                ctx_omni->t2w_thread_info->queue.push(t2w_out);
            }
            ctx_omni->t2w_thread_info->cv.notify_one();
            stream_buffer.clear();
        }

        if (t < 5 || (t + 1) % 25 == 0) {
        }

        // å¦‚æœæ˜¯ EOSï¼Œåœ¨å®Œæˆä¸Šè¿°å¤„ç†åé€€å‡ºå¾ªç¯
        if (is_eos) {
            break;
        }
    }
    // é—®é¢˜ï¼šå¦‚æœåªæ¨é€ 25 tokensï¼ŒT2W buffer ä» 3->28ï¼Œå¤„ç†åå‰©ä½™ 3 ä¸ª tokens
    //       è¿™ 3 ä¸ª tokens æ˜¯å½“å‰ chunk çš„æœ€å 3 ä¸ªï¼Œè¦ç­‰åˆ°ä¸‹ä¸€ä¸ª chunk æ‰è¢«å¤„ç†
    //       å¯¼è‡´å½“å‰ chunk çš„å°¾éŸ³è¢«å»¶è¿Ÿï¼Œå¬èµ·æ¥"åå­—"
    // è§£å†³ï¼šåœ¨ chunk ç»“æŸæ—¶å‘é€ is_chunk_end=true ä¿¡å·ï¼Œè®© T2W flush æ‰ buffer ä¸­çš„å‰©ä½™ tokens
    if (ctx_omni->t2w_thread_info) {
        T2WOut * t2w_out = new T2WOut();
        t2w_out->audio_tokens.assign(stream_buffer.begin(), stream_buffer.end());
        // ğŸ”§ [ä¸ Python å¯¹é½] is_end_of_turn æ—¶ä¼  is_final=trueï¼Œè®© T2W ç«‹å³ flush æ‰€æœ‰ buffer
        // Python: token2wav.stream(..., last_chunk=is_last_chunk) å…¶ä¸­ is_last_chunk = end_of_turn
        t2w_out->is_final     = is_end_of_turn;
        t2w_out->is_chunk_end = !is_end_of_turn;              // é turn ç»“æŸæ—¶æ‰ç”¨ is_chunk_end
        t2w_out->round_idx    = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•

        {
            std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
            ctx_omni->t2w_thread_info->queue.push(t2w_out);
        }
        ctx_omni->t2w_thread_info->cv.notify_one();
    }

    // Cleanup sampler
    common_sampler_free(tts_sampler);

    // ğŸ”§ æ›´æ–°ç´¯è®¡ n_pastï¼Œç”¨äºä¸‹ä¸€ä¸ª chunk çš„ KV cache ä½ç½®
    // Python: self.text_start_pos += condition_length + len(chunk_generated_tokens)
    ctx_omni->tts_n_past_accumulated = n_past_tts;

    // Save tokens to file if output_dir is specified
    if (!output_dir.empty() && !output_audio_tokens.empty()) {
        std::string tokens_file = output_dir + "/audio_tokens_chunk_" + std::to_string(chunk_idx) + ".bin";
        FILE *      f           = fopen(tokens_file.c_str(), "wb");
        if (f) {
            fwrite(output_audio_tokens.data(), sizeof(int32_t), output_audio_tokens.size(), f);
            fclose(f);
        }
    }

    return !output_audio_tokens.empty();
}

// Helper function to play WAV file
static void play_wav_file(const std::string & wav_file_path) {
#ifndef _WIN32
    // Play audio asynchronously using fork() to avoid blocking TTS thread
    pid_t pid = fork();
    if (pid == 0) {
#    ifdef __APPLE__
        execl("/usr/bin/afplay", "afplay", wav_file_path.c_str(), (char *) NULL);
#    else
        execl("/usr/bin/aplay", "aplay", wav_file_path.c_str(), (char *) NULL);
#    endif
        _exit(1);
    } else if (pid > 0) {
        // Parent process: continue without waiting
    } else {
        std::string play_cmd;
#    ifdef __APPLE__
        play_cmd = "afplay \"" + wav_file_path + "\" &";
#    else
        play_cmd = "aplay \"" + wav_file_path + "\" &";
#    endif
        LOG_WRN("TTS: fork() failed, using system() fallback for audio playback\n");
        system(play_cmd.c_str());
    }
#endif
    // Windows: no-op (audio playback handled by frontend)
}

// Helper function to move old output directory to old_output/<id>/
static void move_old_output_to_archive() {
    const std::string base_output_dir     = "./tools/omni/output";
    const std::string old_output_base_dir = "./old_output";

    // Helper function to check if directory exists and has content
    auto dir_has_content = [](const std::string & dir_path) -> bool {
        struct stat info;
        if (stat(dir_path.c_str(), &info) != 0) {
            return false;  // Directory doesn't exist
        }
        if (!(info.st_mode & S_IFDIR)) {
            return false;  // Not a directory
        }

        // Check if directory has any files/subdirectories
#ifdef _WIN32
        std::string cmd = "dir /b \"" + dir_path + "\" 2>NUL | findstr /r \".\" >NUL 2>&1";
#else
        std::string cmd = "test -n \"$(ls -A " + dir_path + " 2>/dev/null)\"";
#endif
        int ret = system(cmd.c_str());
        return (ret == 0);  // Returns 0 if directory has content
    };

    // Helper function to create directory
    auto create_dir = [](const std::string & dir_path) -> bool {
        struct stat info;
        if (stat(dir_path.c_str(), &info) != 0) {
            // Directory doesn't exist, try to create it
            if (!cross_platform_mkdir_p(dir_path)) {
                LOG_ERR("Failed to create output directory: %s\n", dir_path.c_str());
                return false;
            }
            return true;
        } else if (!(info.st_mode & S_IFDIR)) {
            LOG_ERR("Output path exists but is not a directory: %s\n", dir_path.c_str());
            return false;
        }
        return true;
    };

    // Helper function to find next available ID in old_output directory
    auto get_next_output_id = [](const std::string & old_output_base) -> int {
        // Ensure old_output base directory exists
        cross_platform_mkdir_p(old_output_base);

        // Find maximum ID in old_output directory
        int max_id = -1;
#ifdef _WIN32
        std::string find_cmd = "dir /b \"" + old_output_base + "\" 2>NUL";
#else
        std::string find_cmd = "ls -1 " + old_output_base + " 2>/dev/null | grep -E '^[0-9]+$' | sort -n | tail -1";
#endif
        FILE * pipe = popen(find_cmd.c_str(), "r");
        if (pipe) {
            char buffer[128];
#ifdef _WIN32
            // On Windows, read all entries and find the max numeric ID
            while (fgets(buffer, sizeof(buffer), pipe) != nullptr) {
                std::string result(buffer);
                while (!result.empty() && (result.back() == '\n' || result.back() == '\r')) {
                    result.pop_back();
                }
                if (!result.empty()) {
                    try {
                        int id = std::stoi(result);
                        if (id > max_id)
                            max_id = id;
                    } catch (...) {
                    }
                }
            }
#else
            if (fgets(buffer, sizeof(buffer), pipe) != nullptr) {
                std::string result(buffer);
                // Remove trailing newline
                while (!result.empty() && (result.back() == '\n' || result.back() == '\r')) {
                    result.pop_back();
                }
                if (!result.empty()) {
                    try {
                        max_id = std::stoi(result);
                    } catch (...) {
                        max_id = -1;
                    }
                }
            }
#endif
            pclose(pipe);
        }

        return max_id + 1;  // Next ID is max_id + 1 (or 0 if no existing IDs)
    };

    // Check if output directory has content
    bool output_has_content = false;

    // Check if base output directory exists and has content
    if (dir_has_content(base_output_dir)) {
        output_has_content = true;
    } else {
        // Check subdirectories
        if (dir_has_content(base_output_dir + "/llm_debug") || dir_has_content(base_output_dir + "/tts_txt") ||
            dir_has_content(base_output_dir + "/tts_wav")) {
            output_has_content = true;
        }
    }

    if (output_has_content) {
        int         next_id        = get_next_output_id(old_output_base_dir);
        std::string old_output_dir = old_output_base_dir + "/" + std::to_string(next_id);

        // Create old_output/<id> directory
        if (!create_dir(old_output_dir)) {
            LOG_ERR("Failed to create old_output directory: %s\n", old_output_dir.c_str());
        } else {
            // Move entire output directory contents to old_output/<id>/
            // Use find + xargs for more reliable moving
#ifdef _WIN32
            std::string move_cmd = "robocopy \"" + base_output_dir + "\" \"" + old_output_dir + "\" /E /MOVE >NUL 2>&1";
            system(move_cmd.c_str());
            // robocopy returns non-zero on success (exit codes < 8 are success)
            // Re-create the base output dir since robocopy /MOVE removes it
            cross_platform_mkdir_p(base_output_dir);
#else
            std::string move_cmd = "find " + base_output_dir + " -mindepth 1 -maxdepth 1 -exec mv {} " +
                                   old_output_dir + "/ \\; 2>/dev/null";
            int ret = system(move_cmd.c_str());
            if (ret == 0) {
            } else {
                // Fallback: try simple mv command
                std::string fallback_cmd =
                    "sh -c 'cd " + base_output_dir + " && mv * " + old_output_dir + "/ 2>/dev/null || true'";
                ret = system(fallback_cmd.c_str());
                if (ret == 0) {
                } else {
                    LOG_WRN("Failed to move old output directory (may be empty or already moved)\n");
                }
            }
#endif
        }
    } else {
    }
}

// Helper function to merge all WAV files into a single file
static void merge_wav_files(const std::string & output_dir, int num_chunks) {
    if (num_chunks == 0) {
        LOG_WRN("TTS: no chunks to merge\n");
        return;
    }

    std::string merged_file = output_dir + "/tts_output_merged.wav";

    // Check all chunk files exist
    std::vector<std::string> chunk_files;
    for (int i = 0; i < num_chunks; ++i) {
        std::string chunk_file = output_dir + "/tts_output_chunk_" + std::to_string(i) + ".wav";
        struct stat st;
        if (stat(chunk_file.c_str(), &st) == 0 && st.st_size > 0) {
            chunk_files.push_back(chunk_file);
        } else {
            LOG_WRN("TTS: chunk file %s does not exist or is empty\n", chunk_file.c_str());
        }
    }

    if (chunk_files.empty()) {
        LOG_WRN("TTS: no valid WAV files to merge\n");
        return;
    }

    // Method 1: Use ffmpeg with concat demuxer (most reliable)
    std::string concat_list_file = output_dir + "/concat_list.txt";
    FILE *      f_list           = fopen(concat_list_file.c_str(), "w");
    if (f_list) {
        for (const auto & chunk_file : chunk_files) {
            fprintf(f_list, "file '%s'\n", chunk_file.c_str());
        }
        fclose(f_list);

        std::string ffmpeg_cmd = "ffmpeg -f concat -safe 0 -i \"" + concat_list_file + "\" -c copy \"" + merged_file +
                                 "\" -y -loglevel error 2>&1";
        int ret = system(ffmpeg_cmd.c_str());
        unlink(concat_list_file.c_str());  // Clean up temp file

        if (ret == 0) {
            struct stat st;
            if (stat(merged_file.c_str(), &st) == 0 && st.st_size > 0) {
                return;  // Success
            }
        }
    }

    // Method 2: Fallback to sox (if available)
    std::string sox_cmd = "sox";
    for (const auto & chunk_file : chunk_files) {
        sox_cmd += " \"" + chunk_file + "\"";
    }
    sox_cmd += " \"" + merged_file + "\"";
    int ret = system(sox_cmd.c_str());

    if (ret == 0) {
        struct stat st;
        if (stat(merged_file.c_str(), &st) == 0 && st.st_size > 0) {
        } else {
            LOG_WRN("TTS: merged file was not created or is empty (sox)\n");
        }
    } else {
        LOG_WRN("TTS: failed to merge WAV files (tried ffmpeg and sox). Please install ffmpeg or sox.\n");
    }
}

// ==============================================================================
// TTS Thread Function - Duplex Mode
// åŒå·¥æ¨¡å¼ä¸“ç”¨çš„ TTS çº¿ç¨‹å‡½æ•°
// ä¸å•å·¥ç‰ˆæœ¬çš„ä¸»è¦å·®å¼‚ï¼š
// 1. ä¸éœ€è¦ simplex_round_idx ç®¡ç†å’Œ round_XXX è¾“å‡ºç›®å½•
// 2. TTS KV cache è·¨ chunk ä¿æŒï¼ˆç”± is_end_of_turn æ§åˆ¶æ˜¯å¦é‡ç½®ï¼‰
// 3. ä½¿ç”¨ generate_audio_tokens_localï¼ˆåŒå·¥ç‰ˆæœ¬ï¼Œmax_audio_tokens=26ï¼‰
// ==============================================================================
void tts_thread_func_duplex(struct omni_context * ctx_omni, common_params * params) {
    // TTS model state
    int                      tts_n_past = 0;
    std::vector<llama_token> audio_tokens;
    std::vector<llama_token> all_audio_tokens;
    std::string              debug_dir  = "";
    bool                     tts_finish = false;
    bool                     llm_finish = false;
    int                      chunk_idx  = 0;
    std::string              incomplete_bytes;

    // åŒå·¥æ¨¡å¼ï¼šå›ºå®šè¾“å‡ºç›®å½•ï¼ˆä¸ä½¿ç”¨ round_XXX å­ç›®å½•ï¼‰
    // ğŸ”§ [å¤šå®ä¾‹æ”¯æŒ] ä½¿ç”¨å¯é…ç½®çš„ base_output_dir
    const std::string & base_output_dir      = ctx_omni->base_output_dir;
    const std::string   tts_output_dir       = base_output_dir + "/tts_txt";
    const std::string   llm_debug_output_dir = base_output_dir + "/llm_debug";
    const std::string   tts_wav_output_dir   = base_output_dir + "/tts_wav";

    // Helper function to create directory
    auto create_dir = [](const std::string & dir_path) {
        if (!cross_platform_mkdir_p(dir_path)) {
            LOG_ERR("Failed to create output directory: %s\n", dir_path.c_str());
            return false;
        }
        return true;
    };

    // åˆ›å»ºè¾“å‡ºç›®å½•
    create_dir(tts_output_dir);
    create_dir(llm_debug_output_dir);
    create_dir(tts_wav_output_dir);

    // TTS model constants
    const int audio_bos_token_id = 151687;
    const int audio_eos_token_id = audio_bos_token_id + 6561;
    const int text_eos_token_id  = 151692;
    const int num_audio_tokens   = 6562;

    // ğŸ”§ [è¯Šæ–­] ç”¨äºè¿½è¸ªæ‰€æœ‰ decode è°ƒç”¨
    int decode_call_idx = 0;

    // ğŸ”§ [ä¿®å¤é‡å¤ç”Ÿæˆé—®é¢˜] æ ‡å¿—ä½ï¼šå½“å‰ turn æ˜¯å¦å·²ç»æ‰§è¡Œè¿‡ turn_eos flush
    bool turn_eos_flushed = false;

    print_with_timestamp("TTS thread (duplex mode) started\n");

    // Multi Round Persistent Loop
    while (tts_thread_running) {
        if (!tts_thread_running) {
            break;
        }

        // ğŸ”§ [åŒå·¥æ¨¡å¼] æ‰“æ–­æ£€æµ‹
        if (ctx_omni->break_event.load()) {
            // æ¸…ç©º TTS é˜Ÿåˆ—
            {
                std::lock_guard<std::mutex> lock(ctx_omni->tts_thread_info->mtx);
                auto &                      queue = ctx_omni->tts_thread_info->queue;
                while (!queue.empty()) {
                    LLMOut * llm_out = queue.front();
                    queue.pop();
                    delete llm_out;
                }
            }
            // é‡ç½®çŠ¶æ€
            llm_finish = false;
            tts_finish = false;
            chunk_idx  = 0;
            tts_n_past = 0;
            audio_tokens.clear();
            all_audio_tokens.clear();
            incomplete_bytes.clear();
            // æ¸…é™¤ TTS KV cache
            llama_memory_t mem = llama_get_memory(ctx_omni->ctx_tts_llama);
            if (mem) {
                llama_memory_seq_rm(mem, 0, 0, -1);
                print_with_timestamp("TTS Duplex: break_event - cleared TTS KV cache\n");
            }
            ctx_omni->tts_n_past_accumulated = 0;
            ctx_omni->tts_all_generated_tokens.clear();
            ctx_omni->tts_condition_saved = false;
            continue;
        }

        std::string              llm_text = "";
        std::vector<llama_token> current_chunk_token_ids;
        std::vector<float>       current_chunk_hidden_states;
        int                      current_chunk_n_embd = 0;

        // ğŸ”§ [ä¿®å¤åŒå·¥ç¼ºå­—é—®é¢˜] ä» LLMOut è·å– is_end_of_turn çŠ¶æ€
        bool accumulated_is_end_of_turn = false;

        // Wait for queue
        if (!llm_finish || (llm_finish && llm_text.empty())) {
            std::unique_lock<std::mutex> lock(ctx_omni->tts_thread_info->mtx);
            auto &                       queue = ctx_omni->tts_thread_info->queue;
            ctx_omni->tts_thread_info->cv.wait(
                lock, [&] { return !queue.empty() || !tts_thread_running || ctx_omni->break_event.load(); });

            if (ctx_omni->break_event.load()) {
                lock.unlock();
                continue;
            }

            if (!tts_thread_running) {
                break;
            }

            // æ¸…ç©º current_chunk æ•°æ®
            current_chunk_token_ids.clear();
            current_chunk_hidden_states.clear();
            current_chunk_n_embd       = 0;
            accumulated_is_end_of_turn = false;

            // ç´¯ç§¯æ‰€æœ‰é˜Ÿåˆ—ä¸­çš„æ•°æ®
            while (!queue.empty()) {
                LLMOut * llm_out = queue.front();
                llm_finish |= llm_out->llm_finish;
                accumulated_is_end_of_turn |= llm_out->is_end_of_turn;

                if (!ctx_omni->speek_done || ctx_omni->duplex_mode) {
                    llm_text += llm_out->text;
                    debug_dir = llm_out->debug_dir;
                }

                // ç´¯ç§¯æ•°æ®
                if (!llm_out->token_ids.empty() && !llm_out->hidden_states.empty()) {
                    current_chunk_token_ids.insert(current_chunk_token_ids.end(), llm_out->token_ids.begin(),
                                                   llm_out->token_ids.end());
                    current_chunk_hidden_states.insert(current_chunk_hidden_states.end(),
                                                       llm_out->hidden_states.begin(), llm_out->hidden_states.end());
                    current_chunk_n_embd = llm_out->n_embd;
                }
                delete llm_out;
                queue.pop();
            }
            lock.unlock();
            ctx_omni->tts_thread_info->cv.notify_all();

            // åŒå·¥æ¨¡å¼ï¼šå¦‚æœæœ‰æ–°æ•°æ®ï¼Œç»§ç»­å¤„ç†
            // ğŸ”§ [å…³é”®è¯Šæ–­] æ¯æ¬¡å–å‡º LLMOut åéƒ½æ‰“å°çŠ¶æ€
            // ğŸ”§ [ä¿®å¤åŒå·¥ç¼ºå­—é—®é¢˜] ä½¿ç”¨ accumulated_is_end_of_turn è€Œéå…¨å±€çŠ¶æ€
            print_with_timestamp(
                "TTS Duplex: after queue - speek_done=%d, llm_finish=%d, token_ids.size=%zu, is_end_of_turn=%d, "
                "llm_text.len=%zu\n",
                ctx_omni->speek_done ? 1 : 0, llm_finish ? 1 : 0, current_chunk_token_ids.size(),
                accumulated_is_end_of_turn ? 1 : 0, llm_text.size());

            if (ctx_omni->speek_done && llm_finish) {
                if (ctx_omni->duplex_mode && !current_chunk_token_ids.empty()) {
                    ctx_omni->speek_done = false;
                } else if (ctx_omni->duplex_mode && accumulated_is_end_of_turn) {
                    ctx_omni->speek_done = false;
                    print_with_timestamp("TTS Duplex: is_end_of_turn=true, will call TTS to flush buffer\n");
                } else {
                    // LISTEN/CHUNK_EOS ä¸”æ²¡æœ‰å®é™…æ–‡æœ¬
                    decode_call_idx++;
                    llm_finish = false;
                    llm_text.clear();

                    if (ctx_omni->t2w_thread_info) {
                        T2WOut * t2w_out = new T2WOut();
                        t2w_out->audio_tokens.clear();
                        t2w_out->is_final     = false;
                        t2w_out->is_chunk_end = true;
                        t2w_out->round_idx    = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•
                        {
                            std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                            ctx_omni->t2w_thread_info->queue.push(t2w_out);
                        }
                        ctx_omni->t2w_thread_info->cv.notify_one();
                    }
                    continue;
                }
            }
        }

        std::string & response = llm_text;
        // å¤„ç†ä¸å®Œæ•´çš„ UTF-8 å­—èŠ‚
        if (!incomplete_bytes.empty()) {
            response = incomplete_bytes + response;
            incomplete_bytes.clear();
        }
        size_t incomplete_len = findIncompleteUtf8(response);
        if (incomplete_len > 0) {
            incomplete_bytes = response.substr(response.size() - incomplete_len, incomplete_len);
            response         = response.substr(0, response.size() - incomplete_len);
        }

        // Skip empty responses
        if (response.empty() && !llm_finish) {
            if (ctx_omni->speek_done) {
                llm_finish = false;
                if (ctx_omni->duplex_mode && !accumulated_is_end_of_turn) {
                    // ä¿æŒçŠ¶æ€
                } else {
                    // è½®æ¬¡ç»“æŸï¼Œé‡ç½® TTS çŠ¶æ€
                    chunk_idx  = 0;
                    tts_n_past = 0;
                    audio_tokens.clear();
                    llama_memory_t mem = llama_get_memory(ctx_omni->ctx_tts_llama);
                    if (mem) {
                        llama_memory_seq_rm(mem, 0, 0, -1);
                    }
                    ctx_omni->tts_n_past_accumulated = 0;
                    ctx_omni->tts_all_generated_tokens.clear();
                    ctx_omni->tts_condition_saved = false;
                }
            }
            continue;
        }

        // Tokenize text input
        std::vector<llama_token> text_tokens = common_tokenize(ctx_omni->ctx_tts_llama, response, false, true);

        if (text_tokens.empty() && !llm_finish) {
            continue;
        }

        // Handle empty final chunk
        if (text_tokens.empty() && response.empty() && llm_finish) {
            ctx_omni->speek_done  = true;
            ctx_omni->warmup_done = true;
            speek_cv.notify_all();

            if (ctx_omni->duplex_mode && !accumulated_is_end_of_turn) {
                // LISTEN/CHUNK_EOS
                if (ctx_omni->t2w_thread_info) {
                    T2WOut * t2w_out = new T2WOut();
                    t2w_out->audio_tokens.clear();
                    t2w_out->is_final     = false;
                    t2w_out->is_chunk_end = true;
                    t2w_out->round_idx    = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•
                    {
                        std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                        ctx_omni->t2w_thread_info->queue.push(t2w_out);
                    }
                    ctx_omni->t2w_thread_info->cv.notify_one();
                }
                tts_finish = false;
                llm_finish = false;
                continue;
            } else if (ctx_omni->duplex_mode && accumulated_is_end_of_turn) {
                // turn ç»“æŸï¼Œç»§ç»­è°ƒç”¨ TTS flush buffer
                print_with_timestamp(
                    "TTS Duplex: empty final chunk but is_end_of_turn=true, will call TTS to flush buffer\n");
            } else {
                // éåŒå·¥æ¨¡å¼
                if (ctx_omni->t2w_thread_info) {
                    T2WOut * t2w_out = new T2WOut();
                    t2w_out->audio_tokens.clear();
                    t2w_out->is_final     = true;
                    t2w_out->is_chunk_end = false;
                    t2w_out->round_idx    = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•
                    {
                        std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                        ctx_omni->t2w_thread_info->queue.push(t2w_out);
                    }
                    ctx_omni->t2w_thread_info->cv.notify_one();
                }
                tts_finish = false;
                llm_finish = false;
                chunk_idx  = 0;
                tts_n_past = 0;
                audio_tokens.clear();
                llama_memory_t mem = llama_get_memory(ctx_omni->ctx_tts_llama);
                if (mem && !ctx_omni->duplex_mode) {
                    llama_memory_seq_rm(mem, 0, 0, -1);
                }
                ctx_omni->tts_n_past_accumulated = 0;
                ctx_omni->tts_all_generated_tokens.clear();
                ctx_omni->tts_condition_saved = false;
                continue;
            }
        }

        // Check for LLM data
        bool has_llm_data =
            (!current_chunk_token_ids.empty() && !current_chunk_hidden_states.empty() && current_chunk_n_embd > 0);

        if (has_llm_data) {
            int current_chunk_idx = chunk_idx;

            // æ”¶åˆ°æœ‰æ•ˆ LLM æ•°æ®ï¼Œé‡ç½® turn_eos_flushed æ ‡å¿—ä½
            if (turn_eos_flushed) {
                turn_eos_flushed = false;
            }

            print_with_timestamp("TTS Duplex: processing chunk_idx=%d, n_tokens=%zu, is_end_of_turn=%d\n", chunk_idx,
                                 current_chunk_token_ids.size(), accumulated_is_end_of_turn ? 1 : 0);

            // å®‰å…¨æ£€æŸ¥
            if (current_chunk_n_embd <= 0 || current_chunk_n_embd > 16384) {
                LOG_ERR("TTS Duplex: invalid current_chunk_n_embd=%d\n", current_chunk_n_embd);
                continue;
            }

            size_t expected_hidden_size = current_chunk_token_ids.size() * current_chunk_n_embd;
            if (current_chunk_hidden_states.size() != expected_hidden_size) {
                LOG_ERR("TTS Duplex: hidden_states size mismatch\n");
                continue;
            }

            // Filter special tokens
            int                      n_tokens_orig = (int) (current_chunk_hidden_states.size() / current_chunk_n_embd);
            std::vector<llama_token> filtered_token_ids     = current_chunk_token_ids;
            std::vector<float>       filtered_hidden_states = current_chunk_hidden_states;
            filter_special_tokens(filtered_token_ids, filtered_hidden_states, current_chunk_n_embd);
            int n_tokens_filtered = (int) (filtered_hidden_states.size() / current_chunk_n_embd);

            if (n_tokens_filtered <= 0) {
                continue;
            }

            // Compute merged embeddings
            const int          tts_n_embd = llama_n_embd(llama_get_model(ctx_omni->ctx_tts_llama));
            std::vector<float> merged_embeddings;
            bool               merged_success = false;

            if (ctx_omni->emb_text_weight && ctx_omni->projector_semantic_linear1_weight) {
                // Step 1: emb_text
                std::vector<float> llm_embeds(n_tokens_filtered * tts_n_embd, 0.0f);
                bool               emb_text_success = true;
                for (int i = 0; i < n_tokens_filtered; i++) {
                    if (!tts_emb_text(ctx_omni, filtered_token_ids[i], llm_embeds.data() + i * tts_n_embd,
                                      tts_n_embd)) {
                        emb_text_success = false;
                        break;
                    }
                }

                if (emb_text_success) {
                    // Step 2: projector_semantic
                    std::vector<float> projected_hidden(n_tokens_filtered * tts_n_embd, 0.0f);
                    bool               projector_success =
                        tts_projector_semantic(ctx_omni, filtered_hidden_states.data(), n_tokens_filtered,
                                               current_chunk_n_embd, projected_hidden.data(), tts_n_embd);

                    if (projector_success) {
                        // Step 3: Normalize
                        normalize_l2_per_token(projected_hidden.data(), n_tokens_filtered, tts_n_embd);

                        // Step 4: Merge
                        size_t merge_size = (size_t) n_tokens_filtered * tts_n_embd;
                        merged_embeddings.resize(merge_size);
                        for (size_t i = 0; i < merge_size; i++) {
                            merged_embeddings[i] = llm_embeds[i] + projected_hidden[i];
                        }

                        // Add audio_bos_embed
                        std::vector<float> audio_bos_embed(tts_n_embd, 0.0f);
                        if (tts_emb_text(ctx_omni, audio_bos_token_id, audio_bos_embed.data(), tts_n_embd)) {
                            merged_embeddings.insert(merged_embeddings.end(), audio_bos_embed.begin(),
                                                     audio_bos_embed.end());
                            n_tokens_filtered += 1;
                        }

                        merged_success = true;
                    }
                }
            }

            // ğŸ”§ [åŒå·¥æ¨¡å¼] ä¿å­˜ LLM debug æ•°æ®ï¼ˆè¿½åŠ æ¨¡å¼ï¼Œç»Ÿä¸€æ”¾åœ¨ llm_debug ç›®å½•ï¼‰
            // Save LLM debug data: text, token_ids, hidden_states, and merged embeddings
            {
                // 1. Save LLM text output (è¿½åŠ æ¨¡å¼ï¼Œåªè®°å½•çº¯æ–‡æœ¬ï¼Œä¸è®°å½• special tokens)
                {
                    // ä» llm_text ä¸­è¿‡æ»¤æ‰ special tokens
                    std::string clean_text = llm_text;
                    // ç§»é™¤æ‰€æœ‰ [[XXX]] æ ¼å¼çš„ special token æ ‡è®°
                    size_t      pos        = 0;
                    while ((pos = clean_text.find("[[")) != std::string::npos) {
                        size_t end_pos = clean_text.find("]]", pos);
                        if (end_pos != std::string::npos) {
                            clean_text.erase(pos, end_pos - pos + 2);
                        } else {
                            break;
                        }
                    }
                    // ç§»é™¤å¤šä½™çš„ç©ºæ ¼
                    while (clean_text.find("  ") != std::string::npos) {
                        size_t space_pos = clean_text.find("  ");
                        clean_text.erase(space_pos, 1);
                    }
                    // å»é™¤é¦–å°¾ç©ºæ ¼
                    while (!clean_text.empty() && clean_text[0] == ' ') {
                        clean_text.erase(0, 1);
                    }
                    while (!clean_text.empty() && clean_text.back() == ' ') {
                        clean_text.pop_back();
                    }

                    // åªæœ‰éç©ºæ–‡æœ¬æ‰è®°å½•
                    if (!clean_text.empty()) {
                        std::string text_file = llm_debug_output_dir + "/llm_text.txt";
                        FILE *      f_text    = fopen(text_file.c_str(), "a");
                        if (f_text) {
                            fprintf(f_text, "%s\n", clean_text.c_str());
                            fclose(f_text);
                        }
                    }
                    decode_call_idx++;
                }

                // 2. Save LLM token IDs (è¿½åŠ æ¨¡å¼)
                std::string token_ids_file = llm_debug_output_dir + "/llm_token_ids.txt";
                FILE *      f_tokens       = fopen(token_ids_file.c_str(), "a");
                if (f_tokens) {
                    fprintf(f_tokens, "[chunk_%d] ", current_chunk_idx);
                    for (size_t i = 0; i < current_chunk_token_ids.size(); ++i) {
                        fprintf(f_tokens, "%d", current_chunk_token_ids[i]);
                        if (i < current_chunk_token_ids.size() - 1) {
                            fprintf(f_tokens, " ");
                        }
                    }
                    fprintf(f_tokens, "\n");
                    fclose(f_tokens);
                }

                // 3. Save LLM hidden states (è¿½åŠ æ¨¡å¼ï¼Œæ–‡æœ¬æ ¼å¼)
                int         n_tokens_orig   = (int) (current_chunk_hidden_states.size() / current_chunk_n_embd);
                std::string hidden_txt_file = llm_debug_output_dir + "/llm_hidden_states.txt";
                FILE *      f_hidden_txt    = fopen(hidden_txt_file.c_str(), "a");
                if (f_hidden_txt) {
                    fprintf(f_hidden_txt, "[chunk_%d] Hidden States (shape: [%d, %d]):\n", current_chunk_idx,
                            n_tokens_orig, current_chunk_n_embd);
                    for (int i = 0; i < n_tokens_orig; ++i) {
                        fprintf(f_hidden_txt, "  Token %d: %.6f %.6f %.6f ... (first 3 values)\n", i,
                                current_chunk_hidden_states[i * current_chunk_n_embd + 0],
                                current_chunk_hidden_states[i * current_chunk_n_embd + 1],
                                current_chunk_hidden_states[i * current_chunk_n_embd + 2]);
                    }
                    fclose(f_hidden_txt);
                }

                // 4. Save merged embeddings (è¿½åŠ æ¨¡å¼) if successfully computed
                if (merged_success && !merged_embeddings.empty()) {
                    std::string merged_txt_file = llm_debug_output_dir + "/merged_embeddings.txt";
                    FILE *      f_merged_txt    = fopen(merged_txt_file.c_str(), "a");
                    if (f_merged_txt) {
                        fprintf(f_merged_txt, "[chunk_%d] Merged Embeddings (shape: [%d, %d]):\n", current_chunk_idx,
                                n_tokens_filtered, tts_n_embd);
                        for (int i = 0; i < n_tokens_filtered; ++i) {
                            fprintf(f_merged_txt, "  Token %d: %.6f %.6f %.6f ... (first 3 values)\n", i,
                                    merged_embeddings[i * tts_n_embd + 0], merged_embeddings[i * tts_n_embd + 1],
                                    merged_embeddings[i * tts_n_embd + 2]);
                        }
                        fclose(f_merged_txt);
                    }
                }
            }

            // Generate audio tokens using duplex version
            // ğŸ”§ [ä¿®å¤å°¾éŸ³é—®é¢˜] å½“ is_end_of_turn=true æ—¶ï¼Œå³ä½¿ merged_embeddings ä¸ºç©ºï¼Œ
            // ä¹Ÿè¦è°ƒç”¨ TTS ç”Ÿæˆï¼ˆåªæ·»åŠ  text_eos_embedï¼‰ï¼Œè®© TTS flush å®ƒçš„ buffer
            bool should_call_tts =
                (merged_success && !merged_embeddings.empty()) || (accumulated_is_end_of_turn && ctx_omni->duplex_mode);

            if (should_call_tts) {
                std::vector<int32_t> audio_tokens_out;
                bool                 is_end_of_turn = accumulated_is_end_of_turn;

                if (merged_embeddings.empty() && is_end_of_turn) {
                    print_with_timestamp(
                        "TTS Duplex: is_end_of_turn=true with empty embeddings, calling TTS to flush\n");
                    n_tokens_filtered = 0;
                }

                bool tts_gen_success = generate_audio_tokens_local(
                    ctx_omni, params, merged_embeddings, n_tokens_filtered, tts_n_embd, current_chunk_idx,
                    audio_tokens_out, is_end_of_turn, tts_wav_output_dir);

                if (tts_gen_success) {
                    all_audio_tokens.insert(all_audio_tokens.end(), audio_tokens_out.begin(), audio_tokens_out.end());

                    if (is_end_of_turn && ctx_omni->duplex_mode) {
                        turn_eos_flushed = true;
                    }
                }
            }

            ++chunk_idx;
            llm_text.clear();
            response.clear();

            // Handle final chunk
            if (llm_finish) {
                tts_finish            = true;
                ctx_omni->speek_done  = true;
                ctx_omni->warmup_done = true;
                speek_cv.notify_all();

                merge_wav_files(tts_wav_output_dir, chunk_idx + 1);

                if (ctx_omni->duplex_mode && !accumulated_is_end_of_turn) {
                    // LISTEN/CHUNK_EOS: ä¿æŒ TTS çŠ¶æ€
                    if (ctx_omni->t2w_thread_info) {
                        T2WOut * t2w_out = new T2WOut();
                        t2w_out->audio_tokens.clear();
                        t2w_out->is_final     = false;
                        t2w_out->is_chunk_end = true;
                        t2w_out->round_idx    = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•
                        {
                            std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                            ctx_omni->t2w_thread_info->queue.push(t2w_out);
                        }
                        ctx_omni->t2w_thread_info->cv.notify_one();
                    }
                    llm_finish = false;
                    tts_finish = false;
                } else {
                    // çœŸæ­£çš„è½®æ¬¡ç»“æŸ
                    if (ctx_omni->t2w_thread_info && !turn_eos_flushed) {
                        T2WOut * t2w_out = new T2WOut();
                        t2w_out->audio_tokens.clear();
                        t2w_out->is_final  = true;
                        t2w_out->round_idx = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•
                        {
                            std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                            ctx_omni->t2w_thread_info->queue.push(t2w_out);
                        }
                        ctx_omni->t2w_thread_info->cv.notify_one();
                    }
                    // æ¸…é™¤ TTS KV cache
                    llama_memory_t mem = llama_get_memory(ctx_omni->ctx_tts_llama);
                    if (mem) {
                        llama_memory_seq_rm(mem, 0, 0, -1);
                    }
                    ctx_omni->tts_n_past_accumulated = 0;
                    ctx_omni->tts_all_generated_tokens.clear();
                    ctx_omni->tts_condition_saved = false;
                    tts_n_past                    = 0;
                    audio_tokens.clear();
                    all_audio_tokens.clear();
                    llm_finish = false;
                    tts_finish = false;
                }
            }
            continue;
        } else if (ctx_omni->duplex_mode && accumulated_is_end_of_turn && llm_finish) {
            // turn ç»“æŸä½†æ²¡æœ‰æ–°æ•°æ®ï¼Œè°ƒç”¨ TTS flush buffer
            if (turn_eos_flushed) {
                print_with_timestamp("TTS Duplex: turn_eos already flushed, skipping TTS generation\n");
            } else {
                print_with_timestamp("TTS Duplex: no LLM data but is_end_of_turn=true, calling TTS to flush buffer\n");

                const int            tts_n_embd = llama_n_embd(llama_get_model(ctx_omni->ctx_tts_llama));
                std::vector<float>   empty_embeddings;
                std::vector<int32_t> audio_tokens_out;
                int                  n_tokens_for_tts  = 0;
                int                  current_chunk_idx = chunk_idx;

                bool tts_gen_success =
                    generate_audio_tokens_local(ctx_omni, params, empty_embeddings, n_tokens_for_tts, tts_n_embd,
                                                current_chunk_idx, audio_tokens_out, true, tts_wav_output_dir);

                if (tts_gen_success) {
                    all_audio_tokens.insert(all_audio_tokens.end(), audio_tokens_out.begin(), audio_tokens_out.end());
                } else {
                    if (ctx_omni->t2w_thread_info) {
                        T2WOut * t2w_out = new T2WOut();
                        t2w_out->audio_tokens.clear();
                        t2w_out->is_final     = true;
                        t2w_out->is_chunk_end = false;
                        t2w_out->round_idx    = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•
                        {
                            std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                            ctx_omni->t2w_thread_info->queue.push(t2w_out);
                        }
                        ctx_omni->t2w_thread_info->cv.notify_one();
                    }
                }

                turn_eos_flushed = true;
            }

            // é‡ç½® TTS çŠ¶æ€
            merge_wav_files(tts_wav_output_dir, chunk_idx + 1);
            llama_memory_t mem = llama_get_memory(ctx_omni->ctx_tts_llama);
            if (mem) {
                llama_memory_seq_rm(mem, 0, 0, -1);
            }
            ctx_omni->tts_n_past_accumulated = 0;
            ctx_omni->tts_all_generated_tokens.clear();
            ctx_omni->tts_condition_saved = false;
            tts_n_past                    = 0;
            audio_tokens.clear();
            all_audio_tokens.clear();
            llm_finish            = false;
            tts_finish            = false;
            ctx_omni->speek_done  = true;
            ctx_omni->warmup_done = true;
            speek_cv.notify_all();

            llm_text.clear();
            response.clear();
            continue;
        } else {
            llm_text.clear();
            response.clear();
            continue;
        }
    }

    print_with_timestamp("TTS thread (duplex mode) stopped\n");
}

void tts_thread_func(struct omni_context * ctx_omni, common_params * params) {
    // TTS model state
    int                      tts_n_past = 0;    // TTS model's n_past counter
    std::vector<llama_token> audio_tokens;      // Collected audio tokens
    std::vector<llama_token> all_audio_tokens;  // All audio tokens collected across all chunks
    std::string              debug_dir  = "";
    bool                     tts_finish = false;
    bool                     llm_finish = false;
    int                      chunk_idx  = 0;
    std::string              incomplete_bytes;

    // ğŸ”§ [å¤šå®ä¾‹æ”¯æŒ] ä½¿ç”¨å¯é…ç½®çš„ base_output_dir
    const std::string & base_output_dir = ctx_omni->base_output_dir;

    // Helper function to create directory
    struct stat info;
    auto        create_dir = [](const std::string & dir_path) {
        struct stat info;
        if (stat(dir_path.c_str(), &info) != 0) {
            // Directory doesn't exist, try to create it
            if (!cross_platform_mkdir_p(dir_path)) {
                LOG_ERR("Failed to create output directory: %s\n", dir_path.c_str());
                return false;
            }
            return true;
        } else if (!(info.st_mode & S_IFDIR)) {
            LOG_ERR("Output path exists but is not a directory: %s\n", dir_path.c_str());
            return false;
        }
        return true;
    };

    // ğŸ”§ [å•å·¥æ¨¡å¼] Helper function to get round-specific output directory
    // å•å·¥æ¨¡å¼ä¸‹è¿”å› output/round_XXXï¼ŒåŒå·¥æ¨¡å¼ä¸‹è¿”å› output
    auto get_round_output_dir = [&]() -> std::string {
        if (!ctx_omni->duplex_mode) {
            // å•å·¥æ¨¡å¼ï¼šä½¿ç”¨ round_XXX å­ç›®å½•
            char round_dir[512];
            snprintf(round_dir, sizeof(round_dir), "%s/round_%03d", base_output_dir.c_str(),
                     ctx_omni->simplex_round_idx);
            return std::string(round_dir);
        } else {
            // åŒå·¥æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨ base_output_dir
            return base_output_dir;
        }
    };

    // ğŸ”§ [å•å·¥æ¨¡å¼] åŠ¨æ€ç›®å½•è·¯å¾„ï¼ˆæ¯è½®å¼€å§‹æ—¶æ›´æ–°ï¼‰
    std::string current_round_dir    = get_round_output_dir();
    std::string tts_output_dir       = current_round_dir + "/tts_txt";
    std::string llm_debug_output_dir = current_round_dir + "/llm_debug";
    std::string tts_wav_output_dir   = current_round_dir + "/tts_wav";

    // è®°å½•ä¸Šä¸€æ¬¡åˆ›å»ºç›®å½•çš„ round_idxï¼Œé¿å…é‡å¤åˆ›å»º
    int last_created_round_idx = -1;

    // ğŸ”§ [å•å·¥æ¨¡å¼] Helper function to update output directories for current round
    auto update_output_dirs = [&]() {
        current_round_dir    = get_round_output_dir();
        tts_output_dir       = current_round_dir + "/tts_txt";
        llm_debug_output_dir = current_round_dir + "/llm_debug";
        tts_wav_output_dir   = current_round_dir + "/tts_wav";

        // åªåœ¨æ–°çš„ round æ—¶åˆ›å»ºç›®å½•
        if (ctx_omni->simplex_round_idx != last_created_round_idx || ctx_omni->duplex_mode) {
            create_dir(tts_output_dir);
            create_dir(llm_debug_output_dir);
            create_dir(tts_wav_output_dir);
            last_created_round_idx = ctx_omni->simplex_round_idx;

            if (!ctx_omni->duplex_mode) {
                print_with_timestamp("TTS: åˆ›å»ºå•å·¥æ¨¡å¼è¾“å‡ºç›®å½•: %s\n", current_round_dir.c_str());
            }
        }
    };

    // åˆå§‹åˆ›å»ºç›®å½•
    update_output_dirs();

    // TTS model constants from config.json
    const int audio_bos_token_id = 151687;
    // Audio EOS token: relative index 6561, absolute ID = 151687 + 6561 = 158248
    const int audio_eos_token_id = audio_bos_token_id + 6561;  // 158248
    const int text_eos_token_id  = 151692;                     // ç”¨äºæ–‡æœ¬ç»“æŸæ£€æµ‹
    const int spk_emb_token_id   = 21143;
    const int num_audio_tokens   = 6562;
    const int max_audio_tokens   = 1000;  // Maximum audio tokens to generate per text chunk

    // WAV timing log file (will be created in current round directory)
    auto create_wav_timing_file = [&]() {
        std::string wav_timing_file = tts_wav_output_dir + "/wav_timing.txt";
        FILE *      f_timing        = fopen(wav_timing_file.c_str(), "w");
        if (f_timing) {
            fprintf(f_timing, "# WAV file generation timing log\n");
            fprintf(f_timing,
                    "# Format: chunk_index, elapsed_time_ms (since stream_decode start), file_size_bytes, "
                    "request_duration_ms\n");
            fprintf(f_timing, "# Time 0 is when stream_decode() function starts\n");
            fclose(f_timing);
        }
    };
    create_wav_timing_file();

    print_with_timestamp("TTS thread started\n");

    // ğŸ”§ [å•å·¥æ¨¡å¼] æ ‡å¿—ä½ï¼šå½“å‰ break_event æ˜¯å¦å·²ç»é€’å¢è¿‡ round_idx
    // é˜²æ­¢åœ¨ç­‰å¾… T2W çº¿ç¨‹æ¸…é™¤ break_event æœŸé—´é‡å¤é€’å¢
    bool break_round_incremented = false;

    // Multi Round Persistent Loop
    while (tts_thread_running) {
        if (!tts_thread_running) {
            break;
        }

        // ğŸ”§ [P0-æ‰“æ–­æ£€æµ‹] æ£€æµ‹ break_event å¹¶æ¸…ç©ºé˜Ÿåˆ—ã€é‡ç½®çŠ¶æ€
        if (ctx_omni->break_event.load()) {
            // æ¸…ç©º TTS é˜Ÿåˆ—ï¼ˆé˜Ÿåˆ—å…ƒç´ ç±»å‹æ˜¯ LLMOut*ï¼‰
            {
                std::lock_guard<std::mutex> lock(ctx_omni->tts_thread_info->mtx);
                auto &                      queue = ctx_omni->tts_thread_info->queue;
                while (!queue.empty()) {
                    LLMOut * llm_out = queue.front();
                    queue.pop();
                    delete llm_out;
                }
            }

            // ğŸ”§ [å•å·¥æ¨¡å¼] æ‰“æ–­æ—¶é€’å¢ round ç´¢å¼•ï¼ˆåªé€’å¢ä¸€æ¬¡ï¼ï¼‰
            if (!ctx_omni->duplex_mode && !break_round_incremented) {
                ctx_omni->simplex_round_idx++;
                // ğŸ”§ [ç§»é™¤] wav_turn_base çš„é€’å¢ç§»åˆ° T2W çº¿ç¨‹çš„æ‰“æ–­å¤„ç†ä¸­
                // åŸå› ï¼šé¿å…ç«æ€æ¡ä»¶ï¼Œç¡®ä¿ T2W å…ˆå¤„ç†å®Œå½“å‰è½®æ¬¡çš„æ‰€æœ‰æ•°æ®å†é€’å¢
                // ctx_omni->wav_turn_base += 1000;  // å·²ç§»åˆ° T2W çº¿ç¨‹
                break_round_incremented = true;  // æ ‡è®°å·²é€’å¢ï¼Œé˜²æ­¢é‡å¤
                print_with_timestamp("TTS: æ‰“æ–­è§¦å‘ï¼Œä¸‹ä¸€è½® round_idx=%d\n", ctx_omni->simplex_round_idx);
            }

            // é‡ç½®çŠ¶æ€
            llm_finish = false;
            tts_finish = false;
            chunk_idx  = 0;
            tts_n_past = 0;
            audio_tokens.clear();
            all_audio_tokens.clear();
            incomplete_bytes.clear();  // ğŸ”§ [å¤šè½®å¯¹è¯ä¿®å¤] æ¸…ç†ä¸å®Œæ•´çš„ UTF-8 å­—èŠ‚
            // ğŸ”§ [å¤šè½®å¯¹è¯ä¿®å¤] æ¸…ç† TTS ç´¯ç§¯çŠ¶æ€ï¼Œé¿å…æ··æ·†
            ctx_omni->tts_n_past_accumulated = 0;
            ctx_omni->tts_all_generated_tokens.clear();
            ctx_omni->tts_condition_saved = false;
            // ä¸æ¸…é™¤ break_eventï¼Œè®© T2W çº¿ç¨‹ä¹Ÿèƒ½æ£€æµ‹åˆ°
            continue;
        }

        // ğŸ”§ [å•å·¥æ¨¡å¼] break_event è¢« T2W çº¿ç¨‹æ¸…é™¤åï¼Œé‡ç½®æ ‡å¿—ä½
        if (break_round_incremented && !ctx_omni->break_event.load()) {
            break_round_incremented = false;
        }

        std::string              llm_text = "";
        // ä¿å­˜å½“å‰chunkçš„token IDså’Œhidden statesç”¨äºTTSæ¡ä»¶ç”Ÿæˆ
        std::vector<llama_token> current_chunk_token_ids;
        std::vector<float>       current_chunk_hidden_states;
        int                      current_chunk_n_embd = 0;

        // Always wait for queue if not finished, or if finished but need to reset state
        if (!llm_finish || (llm_finish && llm_text.empty())) {
            std::unique_lock<std::mutex> lock(ctx_omni->tts_thread_info->mtx);

            auto & queue = ctx_omni->tts_thread_info->queue;
            // ğŸ”§ [P0-æ‰“æ–­æ£€æµ‹] åœ¨ç­‰å¾…æ—¶ä¹Ÿç›‘å¬ break_event
            ctx_omni->tts_thread_info->cv.wait(
                lock, [&] { return !queue.empty() || !tts_thread_running || ctx_omni->break_event.load(); });

            // æ£€æµ‹åˆ° break_event æ—¶è·³è¿‡å½“å‰å¤„ç†
            if (ctx_omni->break_event.load()) {
                lock.unlock();
                continue;
            }

            if (!tts_thread_running) {
                break;
            }
            // ğŸ”§ [å…³é”®ä¿®å¤] æ¯æ¬¡åªå¤„ç†ä¸€ä¸ª chunkï¼Œä¸è¦ä¸€æ¬¡æ€§å–å‡ºæ‰€æœ‰
            // ä¹‹å‰çš„é—®é¢˜ï¼šwhile (!queue.empty()) ä¼šå–å‡ºæ‰€æœ‰ chunkï¼Œå¯¼è‡´ï¼š
            // - llm_text ç´¯ç§¯äº†å¤šä¸ª chunk çš„æ–‡æœ¬
            // - ä½† token_ids/hidden_states è¢«è¦†ç›–ï¼Œåªä¿ç•™æœ€åä¸€ä¸ª chunk
            // - TTS ç”¨ 10 token çš„ condition å»ç”Ÿæˆ 20 token æ–‡æœ¬çš„è¯­éŸ³ â†’ å†…å®¹ä¸¢å¤±ï¼
            //
            // Python é€»è¾‘ï¼šæ¯æ¬¡åªå¤„ç†ä¸€ä¸ª chunkï¼Œç”Ÿæˆå¯¹åº”çš„ audio tokens
            if (!queue.empty()) {
                LLMOut * llm_out = queue.front();
                llm_finish |= llm_out->llm_finish;
                // åªå–ä¸€ä¸ª chunk çš„æ•°æ®
                if (!ctx_omni->speek_done || ctx_omni->duplex_mode) {
                    llm_text  = llm_out->text;  // æ³¨æ„ï¼š= è€Œä¸æ˜¯ +=
                    debug_dir = llm_out->debug_dir;
                }
                // ä¿å­˜è¿™ä¸€ä¸ª chunk çš„ token IDs å’Œ hidden states
                if (!llm_out->token_ids.empty() && !llm_out->hidden_states.empty()) {
                    current_chunk_token_ids     = llm_out->token_ids;
                    current_chunk_hidden_states = llm_out->hidden_states;
                    current_chunk_n_embd        = llm_out->n_embd;

                    // ğŸ”§ [è¯Šæ–­æ—¥å¿—] æ‰“å° TTS æ¥æ”¶åˆ°çš„æ•°æ®
                    std::string token_ids_str = "";
                    for (size_t i = 0; i < current_chunk_token_ids.size() && i < 20; i++) {
                        token_ids_str += std::to_string(current_chunk_token_ids[i]);
                        if (i < current_chunk_token_ids.size() - 1 && i < 19) {
                            token_ids_str += " ";
                        }
                    }
                    if (current_chunk_token_ids.size() > 20) {
                        token_ids_str += "...";
                    }

                    print_with_timestamp(
                        "TTS<-LLM: chunk_idx=%d, text='%s', n_tokens=%zu, hidden_size=%zu, token_ids=[%s]\n", chunk_idx,
                        llm_text.c_str(), current_chunk_token_ids.size(), current_chunk_hidden_states.size(),
                        token_ids_str.c_str());
                }
                delete llm_out;
                queue.pop();
            }
            lock.unlock();
            ctx_omni->tts_thread_info->cv.notify_all();

            // ğŸ”§ [è¯Šæ–­] æ‰“å°å–å‡ºæ•°æ®åçš„å…³é”®çŠ¶æ€
            print_with_timestamp(
                "TTS: after queue pop - speek_done=%d, llm_finish=%d, llm_text.empty=%d, token_ids.size=%zu\n",
                ctx_omni->speek_done, llm_finish, llm_text.empty(), current_chunk_token_ids.size());

            // If speek_done is true but we received llm_finish=true, handle state transition
            if (ctx_omni->speek_done && llm_finish) {
                print_with_timestamp("TTS: speek_done=true and llm_finish=true, resetting state for next round\n");
                // ğŸ”§ [å…³é”®ä¿®å¤ - ä¸ Python å¯¹é½] åœ¨åŒå·¥æ¨¡å¼ä¸‹ï¼Œå¦‚æœæœ‰æ–°æ•°æ®ï¼Œåº”è¯¥ç»§ç»­å¤„ç†
                // Python: æ¯æ¬¡ streaming_generate è°ƒç”¨éƒ½ä¼šç‹¬ç«‹å¤„ç†ï¼Œä¸ä¼šå› ä¸ºä¹‹å‰çš„çŠ¶æ€è·³è¿‡
                if (ctx_omni->duplex_mode && !current_chunk_token_ids.empty()) {
                    // åŒå·¥æ¨¡å¼ä¸‹æœ‰æ–°æ•°æ®ï¼Œé‡ç½® speek_done å¹¶ç»§ç»­å¤„ç†
                    ctx_omni->speek_done = false;
                    // ä¸æ‰§è¡Œ continueï¼Œç»§ç»­åç»­çš„ TTS å¤„ç†
                } else {
                    // æ²¡æœ‰æ–°æ•°æ®ï¼Œæˆ–è€…éåŒå·¥æ¨¡å¼ï¼šé‡ç½®çŠ¶æ€å¹¶è·³è¿‡
                    llm_finish = false;
                    llm_text.clear();
                    chunk_idx  = 0;
                    tts_n_past = 0;
                    audio_tokens.clear();
                    // ğŸ”§ [å¤šè½®å¯¹è¯ä¿®å¤] æ¸…ç† TTS ç´¯ç§¯çŠ¶æ€
                    ctx_omni->tts_n_past_accumulated = 0;
                    ctx_omni->tts_all_generated_tokens.clear();
                    ctx_omni->tts_condition_saved = false;
                    continue;  // Skip processing and wait for next input
                }
            }
        }

        std::string & response = llm_text;
        // æ‹¼æ¥ä¸Šä¸€ä¸ªå¾ªç¯ä¿å­˜çš„ä¸å®Œæ•´å­—èŠ‚
        if (!incomplete_bytes.empty()) {
            print_with_timestamp("TTS: prepending incomplete_bytes (len=%zu) to response (len=%zu)\n",
                                 incomplete_bytes.length(), response.length());
            response = incomplete_bytes + response;
            incomplete_bytes.clear();
        }
        // æ£€æŸ¥å½“å‰å“åº”æ˜¯å¦æœ‰ä¸å®Œæ•´çš„ UTF-8 åºåˆ—
        size_t incomplete_len = findIncompleteUtf8(response);
        if (incomplete_len > 0) {
            print_with_timestamp(
                "TTS: detected incomplete UTF-8 sequence at end: incomplete_len=%zu, response_len=%zu\n",
                incomplete_len, response.length());
            // ä¿å­˜ä¸å®Œæ•´çš„å­—èŠ‚
            incomplete_bytes = response.substr(response.size() - incomplete_len, incomplete_len);
            // ä»…å¤„ç†å®Œæ•´çš„éƒ¨åˆ†
            response         = response.substr(0, response.size() - incomplete_len);
            print_with_timestamp("TTS: after truncation: response_len=%zu, incomplete_bytes_len=%zu\n",
                                 response.length(), incomplete_bytes.length());
        } else {
            // ç¡®ä¿æ²¡æœ‰æ®‹ç•™çš„ä¸å®Œæ•´å­—èŠ‚
            incomplete_bytes.clear();
        }

        // ğŸ”§ [è¯Šæ–­] æ‰“å° response çŠ¶æ€
        print_with_timestamp("TTS: before empty check - response.empty=%d, response='%s', llm_finish=%d\n",
                             response.empty(), response.substr(0, 50).c_str(), llm_finish);

        // Skip empty responses (but allow processing if llm_finish is true to handle end of generation)
        if (response.empty() && !llm_finish) {
            // If speek_done is true but we're still getting empty responses, just continue waiting
            // Don't reset speek_done here - let stream_prefill reset it after it wakes up
            if (ctx_omni->speek_done) {
                print_with_timestamp(
                    "TTS: speek_done=true with empty response, keeping state (waiting for stream_prefill)\n");
                llm_finish = false;
                chunk_idx  = 0;
                tts_n_past = 0;
                audio_tokens.clear();
                // ğŸ”§ [å¤šè½®å¯¹è¯ä¿®å¤] æ¸…ç† TTS ç´¯ç§¯çŠ¶æ€
                ctx_omni->tts_n_past_accumulated = 0;
                ctx_omni->tts_all_generated_tokens.clear();
                ctx_omni->tts_condition_saved = false;
                // NOTE: ä¸é‡ç½® speek_doneï¼Œè®© stream_prefill å®Œæˆç­‰å¾…åé‡ç½®
            }
            continue;
        }
        fflush(stdout);

        // ğŸ”§ [ä¿®å¤] ç©º response + llm_finish çš„æå‰æ£€æŸ¥
        // å¿…é¡»åœ¨ tokenize ä¹‹å‰æ£€æŸ¥ï¼Œå› ä¸ºç©ºå­—ç¬¦ä¸² tokenize å¯èƒ½è¿”å›éç©ºç»“æœï¼ˆBOS tokenï¼‰
        if (response.empty() && llm_finish) {
            // ğŸ”§ [ä¿®å¤] å½“æ”¶åˆ° llm_finish=true ä½†æ²¡æœ‰æ–°æ•°æ®æ—¶ï¼Œ
            // éœ€è¦ flush tts_token_buffer ä¸­å‰©ä½™çš„ tokensï¼Œå¹¶å‘é€ is_final=true åˆ° T2W
            print_with_timestamp("TTS: received llm_finish=true with no data, finalizing (tts_token_buffer=%zu)\n",
                                 ctx_omni->tts_token_buffer.size());

            // ğŸ”§ [ä¿®å¤] Flush tts_token_buffer ä¸­å‰©ä½™çš„ tokens åˆ° T2W
            if (ctx_omni->t2w_thread_info && !ctx_omni->tts_token_buffer.empty()) {
                T2WOut * t2w_out = new T2WOut();
                t2w_out->audio_tokens.assign(ctx_omni->tts_token_buffer.begin(), ctx_omni->tts_token_buffer.end());
                t2w_out->is_final  = false;                        // å…ˆå‘é€å‰©ä½™ tokens
                t2w_out->round_idx = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•
                {
                    std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                    ctx_omni->t2w_thread_info->queue.push(t2w_out);
                }
                ctx_omni->t2w_thread_info->cv.notify_one();
                print_with_timestamp("TTS: flushed %zu remaining tokens from tts_token_buffer\n",
                                     ctx_omni->tts_token_buffer.size());
                ctx_omni->tts_token_buffer.clear();
            }

            // ğŸ”§ [ä¿®å¤] å‘é€ is_final=true åˆ° T2Wï¼Œè®© T2W å†™å…¥ generation_done.flag
            if (ctx_omni->t2w_thread_info) {
                // ğŸ”§ ä¿å­˜å½“å‰ round_idx ç”¨äº T2Wï¼ˆé€’å¢å‰çš„å€¼ï¼‰
                int current_round_idx = ctx_omni->simplex_round_idx;

                // å•å·¥æ¨¡å¼ï¼šé€’å¢ round_idx
                if (!ctx_omni->duplex_mode) {
                    ctx_omni->simplex_round_idx++;
                    print_with_timestamp("TTS: å•å·¥æ¨¡å¼è½®æ¬¡ç»“æŸï¼Œä¸‹ä¸€è½® round_idx=%d\n", ctx_omni->simplex_round_idx);
                }

                T2WOut * t2w_final = new T2WOut();
                t2w_final->audio_tokens.clear();
                t2w_final->is_final  = true;
                t2w_final->round_idx = current_round_idx;  // ğŸ”§ ä½¿ç”¨é€’å¢å‰çš„å€¼
                {
                    std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                    ctx_omni->t2w_thread_info->queue.push(t2w_final);
                }
                ctx_omni->t2w_thread_info->cv.notify_one();
                print_with_timestamp("TTS: sent is_final=true to T2W (llm_finish with no data)\n");
            }

            ctx_omni->speek_done  = true;
            ctx_omni->warmup_done = true;  // ç¬¬ä¸€è½®å¯¹è¯ç»“æŸï¼Œåç»­ prefill éœ€è¦ç­‰å¾…
            speek_cv.notify_all();
            print_with_timestamp("TTS: finished processing all chunks (llm_finish with no data path)\n");
            // éåŒå·¥æ¨¡å¼æˆ–çœŸæ­£çš„è½®æ¬¡ç»“æŸï¼šå®Œå…¨é‡ç½®
            tts_finish = false;
            llm_finish = false;
            chunk_idx  = 0;
            tts_n_past = 0;
            audio_tokens.clear();
            // ğŸ”§ [å¤šè½®å¯¹è¯ä¿®å¤] æ¸…ç† TTS ç´¯ç§¯çŠ¶æ€
            ctx_omni->tts_n_past_accumulated = 0;
            ctx_omni->tts_all_generated_tokens.clear();
            ctx_omni->tts_condition_saved = false;
            continue;
        }

        // 2. æ ¹æ®Pythonå®ç°ï¼Œå°†LLMè¾“å‡ºè½¬æ¢ä¸ºTTSæ¡ä»¶ï¼ˆhidden_text_mergeæ¨¡å¼ï¼‰
        // Pythonæµç¨‹ï¼š
        //   1. ä½¿ç”¨TTSçš„emb_textå±‚ï¼ˆ152064è¯è¡¨ï¼‰å¤„ç†LLM token: llm_embeds = self.tts.emb_text(yield_chunk_token_ids)
        //   2. ä½¿ç”¨projector_semanticå°†LLM hidden statesï¼ˆ4096ç»´ï¼‰æŠ•å½±åˆ°TTS hidden_dimï¼ˆ768ç»´ï¼‰:
        //      hidden_embeds = self.tts.projector_semantic(output.last_hidden_states)
        //   3. å½’ä¸€åŒ–: hidden_embeds = F.normalize(hidden_embeds, p=2, dim=-1)
        //   4. åˆå¹¶: tts_embeds = llm_embeds + hidden_embeds
        //   5. æ·»åŠ audio_bos_tokençš„embedding
        //   6. å°†tts_embedsä½œä¸ºconditionä¼ é€’ç»™TTSï¼ˆä½¿ç”¨batch.embdè€Œä¸æ˜¯token IDsï¼‰
        fflush(stdout);

        // ğŸ”§ [è¯Šæ–­] æ‰“å° current_chunk_n_embd çš„å€¼ï¼Œç¡®è®¤æ•°æ®æ˜¯å¦æ­£ç¡®ä¼ é€’
        print_with_timestamp("TTS: DEBUG before has_llm_data - token_ids.size=%zu, hidden_states.size=%zu, n_embd=%d\n",
                             current_chunk_token_ids.size(), current_chunk_hidden_states.size(), current_chunk_n_embd);

        // ä½¿ç”¨ä»é˜Ÿåˆ—ä¸­è·å–çš„token IDså’Œhidden states
        bool has_llm_data =
            (!current_chunk_token_ids.empty() && !current_chunk_hidden_states.empty() && current_chunk_n_embd > 0);

        // ğŸ”§ [ç§»é™¤] ä¹‹å‰è¿™é‡Œæœ‰ä¸€æ®µ"ç­‰å¾… 50ms å¹¶ç´¯ç§¯æ›´å¤šæ¶ˆæ¯"çš„é€»è¾‘
        // è¿™ä¼šå¯¼è‡´å¤šä¸ª chunk è¢«åˆå¹¶ï¼Œç ´åäº†"æ¯æ¬¡åªå¤„ç†ä¸€ä¸ª chunk"çš„é€»è¾‘
        // Python ä¸ä¼šç´¯ç§¯å¤šä¸ª chunkï¼Œè€Œæ˜¯æ¯ä¸ª chunk ç‹¬ç«‹å¤„ç†
        // llm_finish æ ‡å¿—ä¼šåœ¨ä¸‹ä¸€æ¬¡ä»é˜Ÿåˆ—å–æ•°æ®æ—¶æ­£ç¡®æ•è·

        // ğŸ”§ [è¯Šæ–­æ—¥å¿—] æ‰“å°å…³é”®æ•°æ®çŠ¶æ€
        print_with_timestamp("TTS: has_llm_data=%d, token_ids=%zu, hidden_states=%zu, n_embd=%d, llm_finish=%d\n",
                             has_llm_data, current_chunk_token_ids.size(), current_chunk_hidden_states.size(),
                             current_chunk_n_embd, llm_finish);

        // // ğŸ”§ [è°ƒè¯•] æ‰“å°ä¼ ç»™ TTS çš„ token IDs
        // if (has_llm_data) {
        //     for (size_t i = 0; i < current_chunk_token_ids.size(); i++) {
        //     }

        //     // æ‰“å°æ¯ä¸ª token å¯¹åº”çš„ hidden state å‰3ä¸ªå€¼
        //     for (size_t i = 0; i < current_chunk_token_ids.size(); i++) {
        //         size_t offset = i * current_chunk_n_embd;
        //     }
        // }

        if (has_llm_data) {
            // ğŸ”§ [å•å·¥æ¨¡å¼] åœ¨æ¯è½®ç¬¬ä¸€ä¸ª chunk æ—¶æ›´æ–°è¾“å‡ºç›®å½•
            // ç¡®ä¿æ¯è½®æ•°æ®ä¿å­˜åœ¨ç‹¬ç«‹çš„ round_XXX å­ç›®å½•ä¸‹
            if (chunk_idx == 0 && !ctx_omni->duplex_mode) {
                update_output_dirs();
                create_wav_timing_file();
            }

            // Save current chunk_idx to ensure consistent directory naming
            // This is important because chunk_idx will be incremented after processing
            int current_chunk_idx = chunk_idx;

            // ğŸ”§ [å®‰å…¨æ£€æŸ¥] é˜²æ­¢é™¤é›¶å’Œå¼‚å¸¸å€¼å¯¼è‡´çš„å´©æºƒ
            if (current_chunk_n_embd <= 0 || current_chunk_n_embd > 16384) {
                LOG_ERR("TTS: invalid current_chunk_n_embd=%d, skipping chunk %d\n", current_chunk_n_embd,
                        current_chunk_idx);
                continue;
            }

            // ğŸ”§ [å®‰å…¨æ£€æŸ¥] éªŒè¯ hidden_states å¤§å°åˆç†æ€§
            if (current_chunk_hidden_states.size() > 100000000) {  // 100M floats = ~400MBï¼Œä½œä¸ºä¸Šé™
                LOG_ERR("TTS: hidden_states size too large (%zu), possible corruption, skipping chunk %d\n",
                        current_chunk_hidden_states.size(), current_chunk_idx);
                continue;
            }

            // ğŸ”§ [å®‰å…¨æ£€æŸ¥] éªŒè¯ token_ids å’Œ hidden_states çš„å¯¹é½å…³ç³»
            size_t expected_hidden_size = current_chunk_token_ids.size() * current_chunk_n_embd;
            if (current_chunk_hidden_states.size() != expected_hidden_size) {
                LOG_ERR(
                    "TTS: hidden_states size mismatch: got %zu, expected %zu (tokens=%zu * n_embd=%d), skipping chunk "
                    "%d\n",
                    current_chunk_hidden_states.size(), expected_hidden_size, current_chunk_token_ids.size(),
                    current_chunk_n_embd, current_chunk_idx);
                continue;
            }

            // CRITICAL FIX: Filter special tokens before computing merged_embeddings
            // This ensures merged_embeddings match Python's computation (which filters tokens)
            // Note: We keep original data for saving debug files, but use filtered data for merged_embeddings
            int n_tokens_orig = (int) (current_chunk_hidden_states.size() / current_chunk_n_embd);

            std::vector<llama_token> filtered_token_ids     = current_chunk_token_ids;
            std::vector<float>       filtered_hidden_states = current_chunk_hidden_states;
            filter_special_tokens(filtered_token_ids, filtered_hidden_states, current_chunk_n_embd);

            int n_tokens_filtered = (int) (filtered_hidden_states.size() / current_chunk_n_embd);

            // ğŸ”§ [è¯Šæ–­æ—¥å¿—] æ‰“å°è¿‡æ»¤å‰åçš„ token æ•°é‡
            print_with_timestamp("TTS: n_tokens_orig=%d, n_tokens_filtered=%d (filtered %d special tokens)\n",
                                 n_tokens_orig, n_tokens_filtered, n_tokens_orig - n_tokens_filtered);

            // æ³¨æ„ï¼šC++ çš„ hidden state æ”¶é›†æ–¹å¼å’Œ Python ä¸åŒï¼š
            // - Python: forward(T_{i-1}) â†’ æ”¶é›† H_{i-1} â†’ é‡‡æ · T_iï¼ˆéœ€è¦å»¶è¿Ÿè°ƒæ•´ï¼‰
            // - C++: é‡‡æ · T_i â†’ forward(T_i) â†’ æ”¶é›† H_iï¼ˆä¸éœ€è¦å»¶è¿Ÿï¼ï¼‰
            // æ‰€ä»¥ C++ çš„ T_i ç›´æ¥å¯¹åº” H_i = forward(T_i)ï¼Œå¯¹é½å·²ç»æ­£ç¡®

            // ğŸ”§ [å®‰å…¨æ£€æŸ¥] å¦‚æœæ‰€æœ‰ token éƒ½è¢«è¿‡æ»¤æ‰äº†ï¼Œè·³è¿‡å¤„ç†
            if (n_tokens_filtered <= 0) {
                LOG_WRN("TTS: all tokens filtered out, skipping chunk %d\n", current_chunk_idx);
                continue;  // è·³è¿‡è¿™ä¸ª chunk
            }

            // Compute merged embeddings (llm_embeds + projected_hidden) for saving
            // This matches Python implementation: tts_embeds = llm_embeds + hidden_embeds
            // IMPORTANT: Use filtered data to match Python's behavior
            const int          tts_n_embd = llama_n_embd(llama_get_model(ctx_omni->ctx_tts_llama));
            std::vector<float> merged_embeddings;  // åˆå¹¶åçš„embedding
            bool               merged_success = false;

            // ğŸ”§ [ä¸ Python å¯¹é½] is_final_text_chunk éœ€è¦åœ¨å¤–å±‚å£°æ˜ï¼Œä¾›åé¢è°ƒç”¨ä½¿ç”¨
            // ğŸ”§ [ä¿®å¤] å½“ llm_finish=true æ—¶ï¼Œè¿™æ˜¯æœ€åä¸€ä¸ª text chunkï¼Œéœ€è¦è®¾ç½® is_final_text_chunk=true
            // è¿™æ · TTS ä¼š flush å‰©ä½™çš„ tts_token_bufferï¼Œå¹¶æ­£ç¡®å¤„ç† text_eos_embed
            bool is_final_text_chunk = llm_finish;

            // Try to compute merged embeddings if weights are available
            if (ctx_omni->emb_text_weight && ctx_omni->projector_semantic_linear1_weight) {
                // Step 1: Convert token IDs to embeddings using emb_text (using filtered tokens)
                std::vector<float> llm_embeds(n_tokens_filtered * tts_n_embd, 0.0f);
                bool               emb_text_success = true;

                for (int i = 0; i < n_tokens_filtered; i++) {
                    llama_token token_id = filtered_token_ids[i];
                    float *     emb      = llm_embeds.data() + i * tts_n_embd;
                    if (!tts_emb_text(ctx_omni, token_id, emb, tts_n_embd)) {
                        emb_text_success = false;
                        break;
                    }
                }

                if (emb_text_success) {
                    // Debug: Save llm_embeds for comparison
                    {
                        std::string chunk_dir = llm_debug_output_dir + "/chunk_" + std::to_string(current_chunk_idx);
                        create_dir(chunk_dir);
                        std::string llm_embeds_file = chunk_dir + "/llm_embeds_cpp.txt";
                        FILE *      f_llm_embeds    = fopen(llm_embeds_file.c_str(), "w");
                        if (f_llm_embeds) {
                            fprintf(f_llm_embeds, "LLM Embeddings from emb_text (C++ computed, shape: [%d, %d]):\n",
                                    n_tokens_filtered, tts_n_embd);
                            for (int i = 0; i < n_tokens_filtered; ++i) {
                                fprintf(f_llm_embeds, "Token %d: ", i);
                                for (int j = 0; j < tts_n_embd; ++j) {
                                    fprintf(f_llm_embeds, "%.6f", llm_embeds[i * tts_n_embd + j]);
                                    if (j < tts_n_embd - 1) {
                                        fprintf(f_llm_embeds, " ");
                                    }
                                }
                                fprintf(f_llm_embeds, "\n");
                            }
                            fclose(f_llm_embeds);
                        }
                    }

                    // Step 2: Project hidden states using projector_semantic (using filtered hidden states)
                    std::vector<float> projected_hidden(n_tokens_filtered * tts_n_embd, 0.0f);
                    bool               projector_success =
                        tts_projector_semantic(ctx_omni, filtered_hidden_states.data(), n_tokens_filtered,
                                               current_chunk_n_embd, projected_hidden.data(), tts_n_embd);

                    if (projector_success) {
                        // Debug: Save projected_hidden before normalization for comparison
                        {
                            std::string chunk_dir =
                                llm_debug_output_dir + "/chunk_" + std::to_string(current_chunk_idx);
                            create_dir(chunk_dir);
                            std::string projected_file = chunk_dir + "/projected_hidden_before_norm_cpp.txt";
                            FILE *      f_projected    = fopen(projected_file.c_str(), "w");
                            if (f_projected) {
                                fprintf(
                                    f_projected,
                                    "Projected Hidden States BEFORE normalization (C++ computed, shape: [%d, %d]):\n",
                                    n_tokens_filtered, tts_n_embd);
                                for (int i = 0; i < n_tokens_filtered; ++i) {
                                    fprintf(f_projected, "Token %d: ", i);
                                    for (int j = 0; j < tts_n_embd; ++j) {
                                        fprintf(f_projected, "%.6f", projected_hidden[i * tts_n_embd + j]);
                                        if (j < tts_n_embd - 1) {
                                            fprintf(f_projected, " ");
                                        }
                                    }
                                    fprintf(f_projected, "\n");
                                }
                                fclose(f_projected);
                            }
                        }

                        // Step 3: Normalize projected hidden states (CRITICAL: must normalize before merging)
                        // Check L2 norm before normalization for debugging
                        if (n_tokens_filtered > 0) {
                            // Check all tokens, not just first one
                            float avg_norm_before = 0.0f;
                            float min_norm_before = 1e10f;
                            float max_norm_before = 0.0f;
                            for (int t = 0; t < n_tokens_filtered; t++) {
                                float * vec     = projected_hidden.data() + t * tts_n_embd;
                                float   norm_sq = 0.0f;
                                for (int i = 0; i < tts_n_embd; i++) {
                                    norm_sq += vec[i] * vec[i];
                                }
                                float norm = std::sqrt(norm_sq);
                                avg_norm_before += norm;
                                if (norm < min_norm_before) {
                                    min_norm_before = norm;
                                }
                                if (norm > max_norm_before) {
                                    max_norm_before = norm;
                                }
                            }
                            avg_norm_before /= n_tokens_filtered;
                        }

                        // CRITICAL: Normalize projected_hidden before merging
                        normalize_l2_per_token(projected_hidden.data(), n_tokens_filtered, tts_n_embd);

                        // Debug: Save projected_hidden after normalization for comparison
                        {
                            std::string chunk_dir =
                                llm_debug_output_dir + "/chunk_" + std::to_string(current_chunk_idx);
                            create_dir(chunk_dir);
                            std::string projected_file = chunk_dir + "/projected_hidden_after_norm_cpp.txt";
                            FILE *      f_projected    = fopen(projected_file.c_str(), "w");
                            if (f_projected) {
                                fprintf(
                                    f_projected,
                                    "Projected Hidden States AFTER normalization (C++ computed, shape: [%d, %d]):\n",
                                    n_tokens_filtered, tts_n_embd);
                                for (int i = 0; i < n_tokens_filtered; ++i) {
                                    fprintf(f_projected, "Token %d: ", i);
                                    for (int j = 0; j < tts_n_embd; ++j) {
                                        fprintf(f_projected, "%.6f", projected_hidden[i * tts_n_embd + j]);
                                        if (j < tts_n_embd - 1) {
                                            fprintf(f_projected, " ");
                                        }
                                    }
                                    fprintf(f_projected, "\n");
                                }
                                fclose(f_projected);
                            }
                        }

                        // Verify normalization after normalization (check all tokens)
                        if (n_tokens_filtered > 0) {
                            float avg_norm_after   = 0.0f;
                            float min_norm_after   = 1e10f;
                            float max_norm_after   = 0.0f;
                            int   norm_error_count = 0;
                            for (int t = 0; t < n_tokens_filtered; t++) {
                                float * vec     = projected_hidden.data() + t * tts_n_embd;
                                float   norm_sq = 0.0f;
                                for (int i = 0; i < tts_n_embd; i++) {
                                    norm_sq += vec[i] * vec[i];
                                }
                                float norm = std::sqrt(norm_sq);
                                avg_norm_after += norm;
                                if (norm < min_norm_after) {
                                    min_norm_after = norm;
                                }
                                if (norm > max_norm_after) {
                                    max_norm_after = norm;
                                }
                                if (std::abs(norm - 1.0f) > 0.01f) {
                                    norm_error_count++;
                                    LOG_ERR("TTS: ERROR - token %d normalization failed: norm=%.6f (expected ~1.0)\n",
                                            t, norm);
                                }
                            }
                            avg_norm_after /= n_tokens_filtered;
                            if (norm_error_count > 0) {
                                LOG_ERR(
                                    "TTS: ERROR - normalization failed for %d/%d tokens! Expected all norms to be "
                                    "~1.0\n",
                                    norm_error_count, n_tokens_filtered);
                            } else {
                            }
                        }

                        // Step 4: Merge: merged_embeds = llm_embeds + projected_hidden
                        // CRITICAL: Use normalized projected_hidden for merging
                        // Verify projected_hidden is normalized before merging
                        if (n_tokens_filtered > 0) {
                            float   verify_norm_check = 0.0f;
                            float * vec_check         = projected_hidden.data() + 0 * tts_n_embd;
                            for (int i = 0; i < tts_n_embd; i++) {
                                verify_norm_check += vec_check[i] * vec_check[i];
                            }
                            float verify_norm_val = std::sqrt(verify_norm_check);
                            if (std::abs(verify_norm_val - 1.0f) > 0.01f) {
                                LOG_ERR(
                                    "TTS: CRITICAL ERROR - projected_hidden is NOT normalized before merge! "
                                    "norm=%.6f\n",
                                    verify_norm_val);
                            }
                        }

                        // ğŸ”§ [å®‰å…¨æ£€æŸ¥] é˜²æ­¢åˆ›å»ºè¿‡å¤§çš„ vector å¯¼è‡´å´©æºƒ
                        size_t merge_size = (size_t) n_tokens_filtered * tts_n_embd;
                        if (n_tokens_filtered <= 0 || n_tokens_filtered > 10000 || tts_n_embd <= 0 ||
                            tts_n_embd > 10000 || merge_size > 100000000) {  // 100M elements max
                            LOG_ERR("TTS: invalid merge size: n_tokens_filtered=%d, tts_n_embd=%d, merge_size=%zu\n",
                                    n_tokens_filtered, tts_n_embd, merge_size);
                            break;  // è·³è¿‡è¿™ä¸ª chunkï¼Œé¿å…å´©æºƒ
                        }

                        merged_embeddings.resize(merge_size);
                        for (size_t i = 0; i < merge_size; i++) {
                            merged_embeddings[i] = llm_embeds[i] + projected_hidden[i];
                        }

                        // ğŸ”§ [ä¿®å¤] ä¸åœ¨ merge embed é˜¶æ®µæ·»åŠ  audio_bos
                        // Python ä¸­ audio_bos æ˜¯åœ¨ TTS ç±»å†…éƒ¨ï¼ˆprefill å‰ï¼‰æ·»åŠ çš„
                        // ç”± tts_thread_func åœ¨ prefill ä¹‹å‰åŠ¨æ€æ·»åŠ  audio_bos
                        // è¿™æ ·å¯ä»¥ç¡®ä¿ audio_bos ä½¿ç”¨æ­£ç¡®çš„ embedding æƒé‡å’Œä½ç½®

                        merged_success = true;

                        // Debug: Verify merged_embeddings calculation
                        if (n_tokens_filtered > 0) {
                            float * llm_emb_check     = llm_embeds.data() + 0 * tts_n_embd;
                            float * proj_hidden_check = projected_hidden.data() + 0 * tts_n_embd;
                            float * merged_check      = merged_embeddings.data() + 0 * tts_n_embd;
                        }
                    } else {
                        print_with_timestamp(
                            "TTS: WARNING - projector_semantic failed, skipping merged embedding save\n");
                    }
                }
            } else {
                print_with_timestamp("TTS: WARNING - TTS weights not loaded, skipping merged embedding computation\n");
            }

            // Save LLM debug data: text, token_ids, hidden_states, and merged embeddings
            {
                // Create chunk-specific directory
                std::string chunk_dir = llm_debug_output_dir + "/chunk_" + std::to_string(current_chunk_idx);
                create_dir(chunk_dir);

                // 1. Save LLM text output
                std::string text_file = chunk_dir + "/llm_text.txt";
                FILE *      f_text    = fopen(text_file.c_str(), "w");
                if (f_text) {
                    fprintf(f_text, "%s", response.c_str());
                    fclose(f_text);
                }

                // 2. Save LLM token IDs (original, before filtering)
                std::string token_ids_file = chunk_dir + "/llm_token_ids.txt";
                FILE *      f_tokens       = fopen(token_ids_file.c_str(), "w");
                if (f_tokens) {
                    for (size_t i = 0; i < current_chunk_token_ids.size(); ++i) {
                        fprintf(f_tokens, "%d", current_chunk_token_ids[i]);
                        if (i < current_chunk_token_ids.size() - 1) {
                            fprintf(f_tokens, " ");
                        }
                    }
                    fprintf(f_tokens, "\n");
                    fclose(f_tokens);
                }

                // 3. Save LLM hidden states (binary format, original before filtering)
                std::string hidden_file = chunk_dir + "/llm_hidden_states.bin";
                FILE *      f_hidden    = fopen(hidden_file.c_str(), "wb");
                if (f_hidden) {
                    // Write header: n_tokens, n_embd
                    int32_t header[2] = { n_tokens_orig, current_chunk_n_embd };
                    fwrite(header, sizeof(int32_t), 2, f_hidden);
                    // Write hidden states data
                    fwrite(current_chunk_hidden_states.data(), sizeof(float), current_chunk_hidden_states.size(),
                           f_hidden);
                    fclose(f_hidden);
                }

                // 4. Save LLM hidden states as text (for easy inspection)
                std::string hidden_txt_file = chunk_dir + "/llm_hidden_states.txt";
                FILE *      f_hidden_txt    = fopen(hidden_txt_file.c_str(), "w");
                if (f_hidden_txt) {
                    fprintf(f_hidden_txt, "Hidden States (shape: [%d, %d]):\n", n_tokens_orig, current_chunk_n_embd);
                    for (int i = 0; i < n_tokens_orig; ++i) {
                        fprintf(f_hidden_txt, "Token %d: ", i);
                        for (int j = 0; j < current_chunk_n_embd; ++j) {
                            fprintf(f_hidden_txt, "%.6f", current_chunk_hidden_states[i * current_chunk_n_embd + j]);
                            if (j < current_chunk_n_embd - 1) {
                                fprintf(f_hidden_txt, " ");
                            }
                        }
                        fprintf(f_hidden_txt, "\n");
                    }
                    fclose(f_hidden_txt);
                }

                // 5. Save merged embeddings (binary format) if successfully computed
                if (merged_success && !merged_embeddings.empty()) {
                    std::string merged_file = chunk_dir + "/merged_embeddings.bin";
                    FILE *      f_merged    = fopen(merged_file.c_str(), "wb");
                    if (f_merged) {
                        // Write header: n_tokens, tts_n_embd (using filtered token count)
                        int32_t header[2] = { n_tokens_filtered, tts_n_embd };
                        fwrite(header, sizeof(int32_t), 2, f_merged);
                        // Write merged embeddings data
                        fwrite(merged_embeddings.data(), sizeof(float), merged_embeddings.size(), f_merged);
                        fclose(f_merged);
                    }

                    // 6. Save merged embeddings as text (for easy inspection)
                    std::string merged_txt_file = chunk_dir + "/merged_embeddings.txt";
                    FILE *      f_merged_txt    = fopen(merged_txt_file.c_str(), "w");
                    if (f_merged_txt) {
                        fprintf(f_merged_txt, "Merged Embeddings (shape: [%d, %d]):\n", n_tokens_filtered, tts_n_embd);
                        fprintf(f_merged_txt,
                                "# Formula: merged_embeds = emb_text(filtered_token_ids) + "
                                "normalize(projector_semantic(filtered_hidden_states))\n");
                        fprintf(f_merged_txt,
                                "# Note: Special tokens have been filtered before computation (matching Python "
                                "behavior)\n");
                        for (int i = 0; i < n_tokens_filtered; ++i) {
                            fprintf(f_merged_txt, "Token %d: ", i);
                            for (int j = 0; j < tts_n_embd; ++j) {
                                fprintf(f_merged_txt, "%.6f", merged_embeddings[i * tts_n_embd + j]);
                                if (j < tts_n_embd - 1) {
                                    fprintf(f_merged_txt, " ");
                                }
                            }
                            fprintf(f_merged_txt, "\n");
                        }
                        fclose(f_merged_txt);
                        print_with_timestamp("TTS: saved merged embeddings (text) to %s\n", merged_txt_file.c_str());
                    }
                } else {
                    print_with_timestamp(
                        "TTS: skipped saving merged embeddings (computation failed or weights not available)\n");
                }
            }

            // Generate audio tokens using local TTS model (if merged_embeddings available)
            // or fall back to TTS server
            std::string wav_file_path;
            bool        is_final_chunk = llm_finish;
            bool        tts_success    = false;

            // Use local TTS model if merged_embeddings were successfully computed
            if (merged_success && !merged_embeddings.empty()) {
                std::vector<int32_t> audio_tokens;

                // ğŸ”§ [å•åŒå·¥é€‚é…] æ ¹æ® duplex_mode é€‰æ‹©ä¸åŒçš„å‡½æ•°
                bool tts_gen_success = false;
                // ğŸ”§ [ä¸ Python å¯¹é½] ä¼ é€’ is_final_text_chunkï¼Œç”¨äº flush buffer
                tts_gen_success      = generate_audio_tokens_local_simplex(
                    ctx_omni, params, merged_embeddings, n_tokens_filtered, tts_n_embd, current_chunk_idx, audio_tokens,
                    tts_wav_output_dir, is_final_text_chunk);
                if (tts_gen_success) {
                    tts_success = true;

                    // Save audio tokens for external token2wav processing (backup)
                    // token2wav expects relative token IDs (0-6561)
                    std::string tokens_txt_file =
                        tts_wav_output_dir + "/audio_tokens_chunk_" + std::to_string(current_chunk_idx) + ".txt";
                    FILE * f_tokens = fopen(tokens_txt_file.c_str(), "w");
                    if (f_tokens) {
                        for (size_t i = 0; i < audio_tokens.size(); ++i) {
                            fprintf(f_tokens, "%d", audio_tokens[i]);
                            if (i < audio_tokens.size() - 1) {
                                fprintf(f_tokens, ",");
                            }
                        }
                        fprintf(f_tokens, "\n");
                        fclose(f_tokens);
                    }

                    // Accumulate all audio tokens for final WAV generation
                    all_audio_tokens.insert(all_audio_tokens.end(), audio_tokens.begin(), audio_tokens.end());

                    // ğŸ”§ [ä¸ Python æµå¼åŒå·¥å¯¹é½] tokens å·²åœ¨ generate_audio_tokens_local å†…éƒ¨æµå¼æ¨é€
                    // T2W ç«¯çš„ buffer ä¼šæŒç»­ç´¯ç§¯ï¼Œå¹¶æŒ‰æ»‘åŠ¨çª—å£å¤„ç†ï¼Œä¿ç•™ lookahead
                    // Python é€»è¾‘ï¼šbuffer æ»‘åŠ¨ CHUNK_SIZE (25)ï¼Œä¿ç•™ pre_lookahead (3)

                    // Also save audio tokens to file for the chunk (for debugging)
                    // This is separate from the token2wav sliding window
                } else {
                    LOG_ERR("TTS Local: failed for chunk %d\n", current_chunk_idx);
                }
            }

            // Always increment chunk_idx after processing
            // This ensures each chunk gets its own directory and data is not overwritten
            ++chunk_idx;

            // Clear processed text
            llm_text.clear();
            response.clear();

            // If this is the final chunk, mark as finished and merge all WAV files
            if (llm_finish) {
                // ğŸ”§ [ä¸ Python å¯¹é½] LLM å®Œæˆæ—¶ï¼Œflush å‰©ä½™çš„ tts_token_buffer
                // å› ä¸º is_final_text_chunk çš„åˆ¤æ–­å¯èƒ½ä¸å‡†ç¡®ï¼ˆé˜Ÿåˆ—æ—¶åºé—®é¢˜ï¼‰
                if (!ctx_omni->tts_token_buffer.empty() && ctx_omni->t2w_thread_info) {
                    print_with_timestamp("TTS: llm_finish=true, flushing remaining %zu tokens from tts_token_buffer\n",
                                         ctx_omni->tts_token_buffer.size());

                    T2WOut * t2w_out = new T2WOut();
                    if (t2w_out) {
                        t2w_out->audio_tokens.assign(ctx_omni->tts_token_buffer.begin(),
                                                     ctx_omni->tts_token_buffer.end());
                        t2w_out->is_final  = false;  // è¿˜ä¸æ˜¯æœ€åä¸€ä¸ªï¼Œåé¢è¿˜æœ‰ turn_end çš„ is_final
                        t2w_out->round_idx = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•

                        {
                            std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                            ctx_omni->t2w_thread_info->queue.push(t2w_out);
                        }
                        ctx_omni->t2w_thread_info->cv.notify_one();
                    }
                    ctx_omni->tts_token_buffer.clear();
                }

                tts_finish            = true;
                ctx_omni->speek_done  = true;
                ctx_omni->warmup_done = true;  // ç¬¬ä¸€è½®å¯¹è¯ç»“æŸï¼Œåç»­ prefill éœ€è¦ç­‰å¾…
                speek_cv.notify_all();
                print_with_timestamp("TTS: finished processing all chunks\n");

                // Merge all WAV files into a single file
                merge_wav_files(tts_wav_output_dir, chunk_idx + 1);
                // Python: end_of_turn = last_id in turn_terminator_token_ids

                // ğŸ”§ ä¿å­˜å½“å‰ round_idx ç”¨äº T2Wï¼ˆé€’å¢å‰çš„å€¼ï¼‰
                int current_round_idx = ctx_omni->simplex_round_idx;

                // ğŸ”§ [å•å·¥æ¨¡å¼] å…ˆé€’å¢ round ç´¢å¼•ï¼Œå†å‘é€ is_final
                // è¿™æ · T2W çº¿ç¨‹åœ¨å¤„ç†å®Œ is_final åèƒ½ç«‹å³æ£€æµ‹åˆ°æ–°çš„ round_idx
                // é¿å…ç«æ€æ¡ä»¶å¯¼è‡´ä¸‹ä¸€è½®æ•°æ®å†™å…¥æ—§ç›®å½•
                if (!ctx_omni->duplex_mode) {
                    ctx_omni->simplex_round_idx++;
                    print_with_timestamp("TTS: å•å·¥æ¨¡å¼è½®æ¬¡ç»“æŸï¼Œä¸‹ä¸€è½® round_idx=%d\n", ctx_omni->simplex_round_idx);
                }

                // ğŸ”§ å‘é€ is_final=true åˆ° T2W é˜Ÿåˆ—ï¼Œé€šçŸ¥ T2W é‡ç½® buffer
                // æ³¨æ„ï¼šT2W ç«¯åªåœ¨åŒå·¥æ¨¡å¼ä¸‹è°ƒç”¨ Token2WavSession::reset()
                // å•å·¥æ¨¡å¼ä¸‹åªé‡ç½® token_buffer ä¸ºé™éŸ³ tokensï¼Œä¸è°ƒç”¨ reset()
                // ğŸ”§ [ä¿®å¤æœ€åä¸€ä¸ªå­—æ²¡è¯´å®Œ] ç§»é™¤ !all_audio_tokens.empty() æ¡ä»¶
                // åŸå› ï¼šis_final=true å¿…é¡»å‘é€ï¼Œå¦åˆ™ T2W ä¸ä¼š flush æœ€åçš„ buffer
                if (ctx_omni->t2w_thread_info) {
                    T2WOut * t2w_out = new T2WOut();
                    t2w_out->audio_tokens.clear();           // ç©ºtokensï¼Œåªæ˜¯é€šçŸ¥final
                    t2w_out->is_final  = true;
                    t2w_out->round_idx = current_round_idx;  // ğŸ”§ ä½¿ç”¨é€’å¢å‰çš„å€¼
                    {
                        std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                        ctx_omni->t2w_thread_info->queue.push(t2w_out);
                    }
                    ctx_omni->t2w_thread_info->cv.notify_one();
                    print_with_timestamp("TTS: sent is_final=true to T2W queue (turn end)\n");
                }
                ctx_omni->tts_n_past_accumulated = 0;
                ctx_omni->tts_all_generated_tokens.clear();
                // ğŸ”§ [ä¿®å¤ç«æ€æ¡ä»¶] ä¸åœ¨è¿™é‡Œé‡ç½® tts_condition_saved
                // åŸå› ï¼šæ–°ä¸€è½®çš„ generate_audio_tokens_local ä¼šåœ¨ chunk_idx == 0 æ—¶é‡æ–°è®¾ç½®
                // å¦‚æœåœ¨è¿™é‡Œé‡ç½®ï¼Œå¯èƒ½ä¸æ–°ä¸€è½®çš„ TTS å¤„ç†äº§ç”Ÿç«æ€æ¡ä»¶
                // æ—§ç‰ˆå•å·¥ä»£ç ä¹Ÿæ²¡æœ‰åœ¨è¿™é‡Œé‡ç½®
                if (ctx_omni->duplex_mode) {
                    ctx_omni->tts_condition_saved = false;
                }

                chunk_idx  = 0;
                tts_n_past = 0;
                audio_tokens.clear();
                all_audio_tokens.clear();
                llm_finish = false;
                tts_finish = false;
                // ğŸ”§ [ç§»é™¤] wav_turn_base çš„é€’å¢ç§»åˆ° T2W çº¿ç¨‹çš„ is_final å¤„ç†ä¸­
                // åŸå› ï¼šé¿å…ç«æ€æ¡ä»¶ï¼Œç¡®ä¿ T2W å…ˆå¤„ç†å®Œå½“å‰è½®æ¬¡çš„æ‰€æœ‰æ•°æ®å†é€’å¢
                // ctx_omni->wav_turn_base += 1000;  // å·²ç§»åˆ° T2W çº¿ç¨‹
            }

            continue;  // Skip the rest of the TTS processing
        } else {
            // Clear processed text and continue
            llm_text.clear();
            response.clear();
            continue;
        }

// OLD TTS PROCESSING CODE BELOW (DISABLED)
// All code below is disabled and replaced by TTS service calls above
#if 0
        // å‡†å¤‡TTSè¾“å…¥ï¼šä½¿ç”¨åˆå¹¶åçš„embeddingï¼ˆhidden_text_mergeæ¨¡å¼ï¼‰
        const int tts_n_embd = llama_n_embd(llama_get_model(ctx_omni->ctx_tts_llama));
        std::vector<float> tts_condition_embeddings;  // åˆå¹¶åçš„embedding
        std::vector<llama_token> input_tokens;  // Fallback: å¦‚æœæ— æ³•ç”Ÿæˆembeddingï¼Œä½¿ç”¨token IDs
        
        if (has_llm_data) {
            // æ­¥éª¤1: ä½¿ç”¨TTSçš„emb_textå±‚å¤„ç†LLM token IDs
            int n_tokens = (int)current_chunk_token_ids.size();
            std::vector<float> llm_embeds(n_tokens * tts_n_embd, 0.0f);
            bool emb_text_success = true;
            
            for (int i = 0; i < n_tokens; i++) {
                llama_token token_id = current_chunk_token_ids[i];
                float * emb = llm_embeds.data() + i * tts_n_embd;
                if (!tts_emb_text(ctx_omni, token_id, emb, tts_n_embd)) {
                    emb_text_success = false;
                    break;
                }
            }
            
            if (emb_text_success) {
                // æ­¥éª¤2: ä½¿ç”¨projector_semanticæŠ•å½±LLM hidden states
                // éªŒè¯hidden statesçš„shape
                
                // æ‰“å°å‰å‡ ä¸ªhidden stateçš„å€¼ç”¨äºè°ƒè¯•
                if (current_chunk_hidden_states.size() >= 5) {
                }
                
                std::vector<float> projected_hidden(n_tokens * tts_n_embd, 0.0f);
                bool projector_success = tts_projector_semantic(ctx_omni,
                                                                 current_chunk_hidden_states.data(),
                                                                 n_tokens,
                                                                 current_chunk_n_embd,
                                                                 projected_hidden.data(),
                                                                 tts_n_embd);
                
                if (projector_success) {
                    // æ‰“å°æŠ•å½±åçš„å‰å‡ ä¸ªå€¼
                    if (projected_hidden.size() >= 5) {
                    }
                    
                    // æ­¥éª¤3: å½’ä¸€åŒ–projected hidden states
                    normalize_l2_per_token(projected_hidden.data(), n_tokens, tts_n_embd);
                    
                    // æ‰“å°å½’ä¸€åŒ–åçš„å‰å‡ ä¸ªå€¼
                    if (projected_hidden.size() >= 5) {
                    }
                    
                    // æ­¥éª¤4: åˆå¹¶: tts_embeds = llm_embeds + hidden_embeds
                    // ğŸ”§ [å®‰å…¨æ£€æŸ¥] é˜²æ­¢åˆ›å»ºè¿‡å¤§çš„ vector å¯¼è‡´å´©æºƒ
                    size_t cond_size = (size_t)n_tokens * tts_n_embd;
                    if (n_tokens <= 0 || n_tokens > 10000 || 
                        tts_n_embd <= 0 || tts_n_embd > 10000 ||
                        cond_size > 100000000) {  // 100M elements max
                        LOG_ERR("TTS: invalid condition size: n_tokens=%d, tts_n_embd=%d, cond_size=%zu\n",
                                n_tokens, tts_n_embd, cond_size);
                        break;  // è·³è¿‡è¿™ä¸ª chunk
                    }
                    tts_condition_embeddings.resize(cond_size);
                    for (size_t i = 0; i < cond_size; i++) {
                        tts_condition_embeddings[i] = llm_embeds[i] + projected_hidden[i];
                    }
                    
                    // æ‰“å°åˆå¹¶åçš„å‰å‡ ä¸ªå€¼
                    if (tts_condition_embeddings.size() >= 5) {
                    }
                    
                    // Save LLM debug data: text, hidden states, and merged embeddings
                    {
                        // Create chunk-specific directory
                        std::string chunk_dir = llm_debug_output_dir + "/chunk_" + std::to_string(chunk_idx);
                        create_dir(chunk_dir);
                        
                        // 1. Save LLM text output
                        std::string text_file = chunk_dir + "/llm_text.txt";
                        FILE *f_text = fopen(text_file.c_str(), "w");
                        if (f_text) {
                            fprintf(f_text, "%s", response.c_str());
                            fclose(f_text);
                        }
                        
                        // 2. Save LLM token IDs
                        std::string token_ids_file = chunk_dir + "/llm_token_ids.txt";
                        FILE *f_tokens = fopen(token_ids_file.c_str(), "w");
                        if (f_tokens) {
                            fprintf(f_tokens, "Token IDs (%zu):\n", current_chunk_token_ids.size());
                            for (size_t i = 0; i < current_chunk_token_ids.size(); ++i) {
                                fprintf(f_tokens, "%d", current_chunk_token_ids[i]);
                                if (i < current_chunk_token_ids.size() - 1) fprintf(f_tokens, " ");
                            }
                            fprintf(f_tokens, "\n");
                            fclose(f_tokens);
                        }
                        
                        // 3. Save LLM hidden states (binary format for precision)
                        std::string hidden_file = chunk_dir + "/llm_hidden_states.bin";
                        FILE *f_hidden = fopen(hidden_file.c_str(), "wb");
                        if (f_hidden) {
                            // Write header: n_tokens, n_embd
                            int32_t header[2] = {n_tokens, current_chunk_n_embd};
                            fwrite(header, sizeof(int32_t), 2, f_hidden);
                            // Write hidden states data
                            fwrite(current_chunk_hidden_states.data(), sizeof(float), current_chunk_hidden_states.size(), f_hidden);
                            fclose(f_hidden);
                        }
                        
                        // 4. Save LLM hidden states as text (for easy inspection)
                        std::string hidden_txt_file = chunk_dir + "/llm_hidden_states.txt";
                        FILE *f_hidden_txt = fopen(hidden_txt_file.c_str(), "w");
                        if (f_hidden_txt) {
                            fprintf(f_hidden_txt, "Hidden States (shape: [%d, %d]):\n", n_tokens, current_chunk_n_embd);
                            for (int i = 0; i < n_tokens; ++i) {
                                fprintf(f_hidden_txt, "Token %d: ", i);
                                for (int j = 0; j < current_chunk_n_embd; ++j) {
                                    fprintf(f_hidden_txt, "%.6f", current_chunk_hidden_states[i * current_chunk_n_embd + j]);
                                    if (j < current_chunk_n_embd - 1) fprintf(f_hidden_txt, " ");
                                }
                                fprintf(f_hidden_txt, "\n");
                            }
                            fclose(f_hidden_txt);
                        }
                        
                        // 5. Save merged embeddings (binary format)
                        std::string merged_file = chunk_dir + "/merged_embeddings.bin";
                        FILE *f_merged = fopen(merged_file.c_str(), "wb");
                        if (f_merged) {
                            // Write header: n_tokens, tts_n_embd
                            int32_t header[2] = {n_tokens, tts_n_embd};
                            fwrite(header, sizeof(int32_t), 2, f_merged);
                            // Write merged embeddings data
                            fwrite(tts_condition_embeddings.data(), sizeof(float), tts_condition_embeddings.size(), f_merged);
                            fclose(f_merged);
                        }
                        
                        // 6. Save merged embeddings as text (for easy inspection)
                        std::string merged_txt_file = chunk_dir + "/merged_embeddings.txt";
                        FILE *f_merged_txt = fopen(merged_txt_file.c_str(), "w");
                        if (f_merged_txt) {
                            fprintf(f_merged_txt, "Merged Embeddings (shape: [%d, %d]):\n", n_tokens, tts_n_embd);
                            for (int i = 0; i < n_tokens; ++i) {
                                fprintf(f_merged_txt, "Token %d: ", i);
                                for (int j = 0; j < tts_n_embd; ++j) {
                                    fprintf(f_merged_txt, "%.6f", tts_condition_embeddings[i * tts_n_embd + j]);
                                    if (j < tts_n_embd - 1) fprintf(f_merged_txt, " ");
                                }
                                fprintf(f_merged_txt, "\n");
                            }
                            fclose(f_merged_txt);
                        }
                        
                        // 7. Save intermediate results: llm_embeds and projected_hidden
                        std::string llm_embeds_file = chunk_dir + "/llm_embeds.txt";
                        FILE *f_llm_embeds = fopen(llm_embeds_file.c_str(), "w");
                        if (f_llm_embeds) {
                            fprintf(f_llm_embeds, "LLM Embeddings from emb_text (shape: [%d, %d]):\n", n_tokens, tts_n_embd);
                            for (int i = 0; i < n_tokens; ++i) {
                                fprintf(f_llm_embeds, "Token %d: ", i);
                                for (int j = 0; j < tts_n_embd; ++j) {
                                    fprintf(f_llm_embeds, "%.6f", llm_embeds[i * tts_n_embd + j]);
                                    if (j < tts_n_embd - 1) fprintf(f_llm_embeds, " ");
                                }
                                fprintf(f_llm_embeds, "\n");
                            }
                            fclose(f_llm_embeds);
                        }
                        
                        std::string projected_file = chunk_dir + "/projected_hidden.txt";
                        FILE *f_projected = fopen(projected_file.c_str(), "w");
                        if (f_projected) {
                            fprintf(f_projected, "Projected Hidden States (shape: [%d, %d], after normalization):\n", n_tokens, tts_n_embd);
                            for (int i = 0; i < n_tokens; ++i) {
                                fprintf(f_projected, "Token %d: ", i);
                                for (int j = 0; j < tts_n_embd; ++j) {
                                    fprintf(f_projected, "%.6f", projected_hidden[i * tts_n_embd + j]);
                                    if (j < tts_n_embd - 1) fprintf(f_projected, " ");
                                }
                                fprintf(f_projected, "\n");
                            }
                            fclose(f_projected);
                        }
                    }
                    
                    // ğŸ”§ [ä¿®å¤] ä¸åœ¨ merge embed é˜¶æ®µæ·»åŠ  audio_bos
                    // audio_bos å°†åœ¨ prefill ä¹‹å‰åŠ¨æ€æ·»åŠ 
                } else {
                    emb_text_success = false;
                }
            }
            
            if (!emb_text_success) {
                // Fallback: ä½¿ç”¨token IDs
                input_tokens.insert(input_tokens.end(), current_chunk_token_ids.begin(), current_chunk_token_ids.end());
                input_tokens.push_back(audio_bos_token_id);
            }
        } else {
            // æ²¡æœ‰LLMæ•°æ®ï¼Œä½¿ç”¨text_tokensä½œä¸ºfallback
            input_tokens.insert(input_tokens.end(), text_tokens.begin(), text_tokens.end());
            input_tokens.push_back(audio_bos_token_id);
        }
        
        // 3. Reset TTS KV cache ONLY when starting a completely new round (speek_done was true and we're starting fresh)
        // IMPORTANT: Python's TTSStreamingGenerator maintains past_key_values across chunks:
        //   - First call: past_key_values = None (reset)
        //   - Subsequent chunks: past_key_values = self.past_key_values (continue)
        //   - Only reset on end_of_turn or new round
        // We should NOT clear KV cache for each new chunk from LLM if LLM is still generating
        // Only clear when speek_done was true (indicating a new round)
        fflush(stdout);
        
        // Only reset if we're starting a new round (speek_done was true, meaning previous round finished)
        // AND we have previous state (tts_n_past > 0)
        // This matches Python behavior: reset only on end_of_turn or new round
        static bool last_speek_done = false;
        bool should_reset = (last_speek_done && ctx_omni->speek_done == false && tts_n_past > 0);
        last_speek_done = ctx_omni->speek_done;
        
        if (should_reset) {
            fflush(stdout);
            // Clear KV cache to start fresh for new round
            llama_memory_t mem = llama_get_memory(ctx_omni->ctx_tts_llama);
            if (mem) {
                llama_memory_seq_rm(mem, 0, 0, -1);
            } else {
            }
            fflush(stdout);
            tts_n_past = 0;
        } else {
            fflush(stdout);
        }
        
        // 4. Evaluate input (ä½¿ç”¨embeddingæˆ–token IDs)
        // Python: condition = torch.cat([condition, self.audio_bos_embeds], dim=1)
        // Python: condition_length = current_condition.shape[1]
        // Python: pos_ids = torch.arange(self.text_start_pos, self.text_start_pos + condition_length)
        // Python: self.text_start_pos += condition_length + len(chunk_generated_tokens)
        if (!tts_condition_embeddings.empty()) {
            // ğŸ”§ [ä¿®å¤] åœ¨ prefill ä¹‹å‰åŠ¨æ€æ·»åŠ  audio_bos embedding
            // Python ä¸­ audio_bos æ˜¯åœ¨ TTS ç±»å†…éƒ¨ï¼ˆTTSStreamingGenerator.generate_with_bufferï¼‰æ·»åŠ çš„
            // æ¯ä¸ª chunk éƒ½ä¼šåŠ  audio_bos: condition = torch.cat([condition, self.audio_bos_embeds], dim=1)
            std::vector<float> audio_bos_embed(tts_n_embd, 0.0f);
            if (tts_emb_text(ctx_omni, audio_bos_token_id, audio_bos_embed.data(), tts_n_embd)) {
                // Append audio_bos to tts_condition_embeddings
                tts_condition_embeddings.insert(tts_condition_embeddings.end(), 
                                                audio_bos_embed.begin(), audio_bos_embed.end());
                print_with_timestamp("TTS: åœ¨ prefill å‰æ·»åŠ  audio_bos (chunk_idx=%d, new_size=%zu)\n", 
                                    chunk_idx, tts_condition_embeddings.size() / tts_n_embd);
            } else {
                LOG_ERR("TTS: failed to get audio_bos embedding for prefill\n");
            }
            
            // ä½¿ç”¨åˆå¹¶åçš„embeddingä½œä¸ºè¾“å…¥ï¼ˆæ­£ç¡®çš„å®ç°æ–¹å¼ï¼‰
            int condition_length = (int)(tts_condition_embeddings.size() / tts_n_embd);
            fflush(stdout);
            
            // ä½¿ç”¨prefill_emb_with_hiddenç±»ä¼¼çš„é€»è¾‘ï¼Œä½†é’ˆå¯¹TTSæ¨¡å‹
            // Python: prefillæ—¶ï¼Œposition_idsä»text_start_poså¼€å§‹ï¼Œåˆ°text_start_pos + condition_length
            // C++: batch.pos[j] = tts_n_past + jï¼Œå…¶ä¸­tts_n_pastå¯¹åº”text_start_pos
            int n_pos = condition_length;
            int text_start_pos_before = tts_n_past;  // ä¿å­˜prefillå‰çš„text_start_pos
            if (!prefill_with_emb_tts(ctx_omni, params, tts_condition_embeddings.data(), n_pos, params->n_batch, &tts_n_past)) {
                LOG_ERR("Failed to evaluate TTS input embeddings\n");
                // Clear the processed text to prevent infinite loop
                llm_text.clear();
                response.clear();
                chunk_idx = 0;
                tts_n_past = 0;
                audio_tokens.clear();
                // ğŸ”§ [å¤šè½®å¯¹è¯ä¿®å¤] æ¸…ç† TTS ç´¯ç§¯çŠ¶æ€
                ctx_omni->tts_n_past_accumulated = 0;
                ctx_omni->tts_all_generated_tokens.clear();
                ctx_omni->tts_condition_saved = false;
                fflush(stdout);
                continue;
            }
                int condition_length_processed = tts_n_past - text_start_pos_before;
        } else {
            // Fallback: ä½¿ç”¨token IDsä½œä¸ºè¾“å…¥
            fflush(stdout);
            fflush(stdout);
            if (!eval_tokens_tts(ctx_omni, params, input_tokens, params->n_batch, &tts_n_past)) {
                LOG_ERR("Failed to evaluate TTS input tokens\n");
                // Clear the processed text to prevent infinite loop
                llm_text.clear();
                response.clear();
                chunk_idx = 0;
                tts_n_past = 0;
                audio_tokens.clear();
                // ğŸ”§ [å¤šè½®å¯¹è¯ä¿®å¤] æ¸…ç† TTS ç´¯ç§¯çŠ¶æ€
                ctx_omni->tts_n_past_accumulated = 0;
                ctx_omni->tts_all_generated_tokens.clear();
                ctx_omni->tts_condition_saved = false;
                fflush(stdout);
                continue;
            }
        }
        
        // 4. Generate audio tokens using TTS model
        // Following Python flow: decode 1 token at a time, accumulate to buffer, yield when buffer reaches 25 tokens
        audio_tokens.clear();
        bool audio_gen_finish = false;
        int audio_token_count = 0;
        
        // Limit audio tokens per chunk: 25 tokens per chunk (each chunk corresponds to ~10 LLM tokens)
        // æ¯ä¸€è½®çš„é™åˆ¶ï¼šLLMç”Ÿæˆ10ä¸ªtoken â†’ TTSç”Ÿæˆ25ä¸ªtoken
        // æ¥ä¸‹æ¥LLMå†ç”Ÿæˆ10ä¸ªtoken â†’ TTSå†ç”Ÿæˆ25ä¸ªtokenï¼Œä»¥æ­¤ç±»æ¨
        int text_token_count = (int)text_tokens.size();
        // Fixed at 25 tokens per chunk (matching Python's audio_token_chunk_size=25)
        int max_audio_tokens_for_text = 25;
        
        // Buffer for accumulating audio tokens (yield when reaching 25 tokens, matching Python chunk_size=25)
        const int audio_token_chunk_size = 25;  // Yield size matching Python
        std::vector<llama_token> audio_token_buffer;
        
        // ğŸ”§ [å·®å¼‚3ä¿®å¤] å½“å‰ chunk çš„ tokensï¼Œç”¨äº repetition penalty
        std::vector<llama_token> chunk_generated_tokens_tts;
        
        // Generate audio tokens one by one (matching Python decode flow)
        while (audio_token_count < max_audio_tokens_for_text && !audio_gen_finish && !ctx_omni->speek_done) {
            fflush(stdout);
            
            // Decode 1 audio token at a time (matching Python: each decode generates 1 token)
            // ğŸ”§ [å·®å¼‚2&3ä¿®å¤] ä¼ å…¥ï¼š
            // - all_audio_tokens: ç”¨äºåˆ¤æ–­ is_first_token_overall
            // - chunk_generated_tokens_tts: ç”¨äº repetition penaltyï¼ˆåªç”¨å½“å‰ chunk çš„ tokensï¼‰
            // - audio_token_count: token_index_in_chunkï¼Œç”¨äºåˆ¤æ–­ is_chunk_first_token
            // - force_no_eos: falseï¼ˆè¿™ä¸ªè·¯å¾„å·²æœ‰ 25 tokens çš„é™åˆ¶ï¼Œä¸éœ€è¦é¢å¤–é˜»æ­¢ EOSï¼‰
            llama_token audio_token = sample_tts_token_simplex(ctx_omni->ctx_tts_sampler, ctx_omni, params, &tts_n_past, &all_audio_tokens, &chunk_generated_tokens_tts, audio_token_count, false);
            fflush(stdout);
            
            audio_token_buffer.push_back(audio_token);
            audio_tokens.push_back(audio_token);
            all_audio_tokens.push_back(audio_token);
            chunk_generated_tokens_tts.push_back(audio_token);  // ğŸ”§ [å·®å¼‚3ä¿®å¤]
            audio_token_count++;
            
            // Check for end of audio generation
            bool is_audio = is_audio_token(audio_token, audio_bos_token_id, num_audio_tokens);
            int relative_idx = audio_token - audio_bos_token_id;
            fflush(stdout);
            
            // Check for audio EOS token (relative index 6561, absolute 158248)
            // Note: EOS token should only end audio generation for current chunk, not set speek_done
            // speek_done should only be set when llm_finish is true
            if (audio_token == audio_eos_token_id || relative_idx == 6561) {
                fflush(stdout);
                audio_gen_finish = true;
                // Only set tts_finish if LLM has also finished, otherwise continue to next chunk
                if (llm_finish) {
                    tts_finish = true;
                }
                break;
            }
            
            // Yield when buffer reaches chunk_size (25 tokens), matching Python yield logic
            if (audio_token_buffer.size() >= audio_token_chunk_size) {
                fflush(stdout);
                
                // Push audio tokens to T2W queue for token2wav processing
                if (ctx_omni->t2w_thread_info) {
                    T2WOut *t2w_out = new T2WOut();
                    t2w_out->audio_tokens = audio_token_buffer;  // Copy the 25 tokens
                    t2w_out->is_final = false;  // Not final, more chunks may come
                    t2w_out->round_idx = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•
                    
                    {
                        std::unique_lock<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                        // Check if queue has space
                        while (ctx_omni->t2w_thread_info->queue.size() >= ctx_omni->t2w_thread_info->MAX_QUEUE_SIZE) {
                            // Wait for space in queue (with timeout to avoid deadlock)
                            lock.unlock();
                            std::this_thread::sleep_for(std::chrono::milliseconds(10));
                            lock.lock();
                        }
                        ctx_omni->t2w_thread_info->queue.push(t2w_out);
                    }
                    ctx_omni->t2w_thread_info->cv.notify_one();
                }
                
                // Yield this chunk (create unit_buffer and save)
                // Note: In Python, each yield creates a chunk, but here we create one buffer per 25-token chunk
                struct unit_buffer *res = new unit_buffer();
                res->text = response;
                res->unit_n_past = ctx_omni->n_past;
                res->completed = false;  // Not completed yet, more tokens may come
                
                // TODO: Convert audio tokens to audio waveform
                // For now, create a placeholder buffer
                res->buffer.resize(audio_token_chunk_size * 100);  // Placeholder size
                
                if (!res->buffer.empty()) {
                    // è¯»å†™ä½¿ç”¨ mutex ä¿æŠ¤
                    std::unique_lock<std::mutex> lock(buffer_mutex);
                    ctx_omni->omni_output->output.push_back(res);
                    ctx_omni->omni_output->idx += 1;
                } else {
                    delete res;
                }
                
                // Clear buffer after yield, matching Python behavior
                audio_token_buffer.clear();
            }
        }
        
        // If we exited the loop because we reached max_audio_tokens_for_text (25 tokens per chunk),
        // mark audio_gen_finish as true to indicate this chunk is complete
        // This allows the next iteration to process the next chunk from LLM (if LLM is still generating)
        if (!audio_gen_finish && audio_token_count >= max_audio_tokens_for_text && !ctx_omni->speek_done) {
            fflush(stdout);
            audio_gen_finish = true;
        }
        fflush(stdout);
        
        // Save audio tokens to file for debugging/analysis
        // Note: Save relative indices (0-6561) for token2wav compatibility
        if (!audio_tokens.empty()) {
            // Always save to fixed output directory
            const int audio_bos_token_id = 151687;
            std::string token_file = tts_output_dir + "/tts_audio_tokens_chunk_" + std::to_string(chunk_idx) + ".txt";
            FILE *f = fopen(token_file.c_str(), "w");
            if (f) {
                fprintf(f, "Text: %s\n", response.c_str());
                fprintf(f, "Audio tokens (%zu) [relative_index]:\n", audio_tokens.size());
                for (size_t i = 0; i < audio_tokens.size(); ++i) {
                    int absolute_id = audio_tokens[i];
                    int relative_idx = absolute_id - audio_bos_token_id;
                    // Verify token is in valid range
                    if (absolute_id < audio_bos_token_id || relative_idx >= 6562) {
                        LOG_ERR("TTS: WARNING - token %d (relative_idx=%d) is outside valid range [%d, %d)\n", 
                                absolute_id, relative_idx, audio_bos_token_id, audio_bos_token_id + 6562);
                        // Still save relative index, but mark as invalid
                        relative_idx = -1;  // Mark as invalid
                    }
                    // Save relative index only (for token2wav compatibility)
                    fprintf(f, "%d", relative_idx);
                    if (i < audio_tokens.size() - 1) fprintf(f, ",");
                }
                fprintf(f, "\n");
                fclose(f);
            } else {
                LOG_ERR("Failed to open file for writing: %s\n", token_file.c_str());
            }
        }
        
        // Create final unit_buffer for remaining tokens in buffer (if any)
        if (!audio_token_buffer.empty()) {
            // Push remaining tokens to T2W queue (final chunk)
            if (ctx_omni->t2w_thread_info) {
                T2WOut *t2w_out = new T2WOut();
                t2w_out->audio_tokens = audio_token_buffer;  // Copy remaining tokens
                t2w_out->is_final = (audio_gen_finish || llm_finish);  // Mark as final if generation finished
                t2w_out->round_idx = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•
                
                {
                    std::unique_lock<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                    // Check if queue has space
                    while (ctx_omni->t2w_thread_info->queue.size() >= ctx_omni->t2w_thread_info->MAX_QUEUE_SIZE) {
                        lock.unlock();
                        std::this_thread::sleep_for(std::chrono::milliseconds(10));
                        lock.lock();
                    }
                    ctx_omni->t2w_thread_info->queue.push(t2w_out);
                }
                ctx_omni->t2w_thread_info->cv.notify_one();
            }
            
            struct unit_buffer *res = new unit_buffer();
            res->text = response;
            res->unit_n_past = ctx_omni->n_past;
            res->completed = (audio_gen_finish || llm_finish);
            
            // TODO: Convert audio tokens to audio waveform
            res->buffer.resize(audio_token_buffer.size() * 100);  // Placeholder size
            
            if (!res->buffer.empty()) {
                // è¯»å†™ä½¿ç”¨ mutex ä¿æŠ¤
                std::unique_lock<std::mutex> lock(buffer_mutex);
                ctx_omni->omni_output->output.push_back(res);
                ctx_omni->omni_output->idx += 1;
            } else {
                delete res;
            }
        }
        
        // Clear processed text after generating audio tokens for this chunk
        // This ensures we wait for new text in the next iteration instead of reprocessing the same text
        // Python: self.text_start_pos += condition_length + len(chunk_generated_tokens)
        // C++: tts_n_past is already updated during prefill (condition_length) and decode (len(chunk_generated_tokens))
        // So tts_n_past already equals text_start_pos after this chunk
        int condition_length_final = (int)(tts_condition_embeddings.empty() ? input_tokens.size() : (tts_condition_embeddings.size() / tts_n_embd));
        int chunk_generated_tokens_count = (int)audio_tokens.size();
        fflush(stdout);
        
        llm_text.clear();
        response.clear();
        ++chunk_idx;
        
        if (ctx_omni->speek_done) {
            // å¯èƒ½æ˜¯å¤–éƒ¨å¼ºè¡Œæ‰“æ–­äº†ï¼Œæ¸…é™¤å†…éƒ¨æ‰€æœ‰çŠ¶æ€
            printf("speek done setted by outside, clear all internal states\n");
            tts_finish = true;
            // Reset TTS model state by clearing KV cache
            // Note: This might need llama_kv_cache_clear or similar function
            tts_n_past = 0;
        }
        
        // Only finish and set speek_done when BOTH LLM and TTS have finished
        // If only audio_gen_finish is true but llm_finish is false, continue to next chunk
        if (llm_finish && (tts_finish || audio_gen_finish)) {
            // Save all collected audio tokens to a summary file
            if (!all_audio_tokens.empty()) {
                // Always save to fixed output directory
                // Note: Save relative indices (0-6561) for token2wav compatibility
                const int audio_bos_token_id = 151687;
                std::string summary_file = tts_output_dir + "/tts_all_audio_tokens_summary.txt";
                FILE *f = fopen(summary_file.c_str(), "w");
                if (f) {
                    fprintf(f, "Total audio tokens: %zu\n", all_audio_tokens.size());
                    fprintf(f, "Audio token range: relative [0, %d) (absolute [%d, %d))\n", 
                            6562, audio_bos_token_id, audio_bos_token_id + 6562);
                    fprintf(f, "Audio tokens [relative_index]:\n");
                    int invalid_count = 0;
                    for (size_t i = 0; i < all_audio_tokens.size(); ++i) {
                        int absolute_id = all_audio_tokens[i];
                        int relative_idx = absolute_id - audio_bos_token_id;
                        // Verify token is in valid range
                        if (absolute_id < audio_bos_token_id || relative_idx >= 6562 || relative_idx < 0) {
                            LOG_ERR("TTS: WARNING - token %d (relative_idx=%d) is outside valid range [%d, %d)\n", 
                                    absolute_id, relative_idx, audio_bos_token_id, audio_bos_token_id + 6562);
                            relative_idx = -1;  // Mark as invalid
                            invalid_count++;
                        }
                        // Save relative index only (for token2wav compatibility)
                        fprintf(f, "%d", relative_idx);
                        if (i < all_audio_tokens.size() - 1) {
                            if ((i + 1) % 20 == 0) fprintf(f, "\n");
                            else fprintf(f, " ");
                        }
                    }
                    fprintf(f, "\n");
                    if (invalid_count > 0) {
                        fprintf(f, "WARNING: Found %d tokens outside valid range [%d, %d)\n", 
                                invalid_count, audio_bos_token_id, audio_bos_token_id + 6562);
                    }
                    fclose(f);
                    fflush(stdout);
                } else {
                    LOG_ERR("Failed to open summary file for writing: %s\n", summary_file.c_str());
                }
            }
            
            // ğŸ”§ [ä¸ Python æµå¼åŒå·¥å¯¹é½] å‘é€ is_final=true åˆ° T2W é˜Ÿåˆ—ï¼Œflush å‰©ä½™ buffer
            // Python: is_last_chunk=True æ—¶ä¼š flush æ‰€æœ‰å‰©ä½™ tokens
            // T2W ç«¯ buffer å·²ç»ç´¯ç§¯äº†æ‰€æœ‰ tokensï¼Œè¿™é‡Œåªæ˜¯é€šçŸ¥å®ƒ flush
            if (ctx_omni->t2w_thread_info && !all_audio_tokens.empty()) {
                T2WOut *t2w_out = new T2WOut();
                t2w_out->audio_tokens.clear();  // ç©ºtokensï¼Œåªæ˜¯é€šçŸ¥final
                t2w_out->is_final = true;
                t2w_out->round_idx = ctx_omni->simplex_round_idx;  // ğŸ”§ ä¼ é€’è½®æ¬¡ç´¢å¼•
                
                {
                    std::lock_guard<std::mutex> lock(ctx_omni->t2w_thread_info->mtx);
                    ctx_omni->t2w_thread_info->queue.push(t2w_out);
                }
                ctx_omni->t2w_thread_info->cv.notify_one();
            }
            
            // æ—§ä»£ç ï¼ˆå·²ç¦ç”¨ï¼Œæ”¹ç”¨T2Wçº¿ç¨‹å¤„ç†ï¼‰
            /*
            if (ctx_omni->token2wav_initialized && ctx_omni->token2wav_session && 
                !ctx_omni->token2wav_buffer.empty()) {
                // ... æ—§çš„åŒæ­¥å¤„ç†ä»£ç  ...
            }
            */
            
            // å…¼å®¹æ—§ä»£ç çš„å˜é‡å®šä¹‰ï¼ˆé¿å…ç¼–è¯‘é”™è¯¯ï¼‰
            bool _unused_final_wav_placeholder = false;
            if (_unused_final_wav_placeholder && ctx_omni->token2wav_initialized && ctx_omni->token2wav_session && 
                !ctx_omni->token2wav_buffer.empty()) {
                std::vector<float> final_wav;
                if (ctx_omni->token2wav_session->feed_window(ctx_omni->token2wav_buffer, true, final_wav)) {
                    if (!final_wav.empty()) {
                        const int sample_rate = omni::flow::Token2Wav::kSampleRate;
                        std::string wav_path = tts_wav_output_dir + "/wav_" + 
                                               std::to_string(ctx_omni->token2wav_wav_idx) + ".wav";
                        
                        // Convert float to int16 and write WAV
                        const int16_t num_channels = 1;
                        const int16_t bits_per_sample = 16;
                        const int16_t block_align = num_channels * (bits_per_sample / 8);
                        const int32_t byte_rate = sample_rate * block_align;
                        
                        std::vector<int16_t> pcm(final_wav.size());
                        for (size_t i = 0; i < final_wav.size(); ++i) {
                            float x = final_wav[i];
                            if (!std::isfinite(x)) x = 0.0f;
                            x = std::max(-1.0f, std::min(1.0f, x));
                            float y = x * 32767.0f;
                            if (y >= 32767.0f) pcm[i] = 32767;
                            else if (y <= -32768.0f) pcm[i] = -32768;
                            else pcm[i] = (int16_t)y;
                        }
                        
                        uint32_t data_bytes = (uint32_t)(pcm.size() * sizeof(int16_t));
                        uint32_t riff_size = 36u + data_bytes;
                        
                        FILE* f_wav = fopen(wav_path.c_str(), "wb");
                        if (f_wav) {
                            fwrite("RIFF", 1, 4, f_wav);
                            fwrite(&riff_size, 4, 1, f_wav);
                            fwrite("WAVE", 1, 4, f_wav);
                            fwrite("fmt ", 1, 4, f_wav);
                            uint32_t fmt_size = 16;
                            uint16_t audio_format = 1;
                            fwrite(&fmt_size, 4, 1, f_wav);
                            fwrite(&audio_format, 2, 1, f_wav);
                            fwrite(&num_channels, 2, 1, f_wav);
                            fwrite(&sample_rate, 4, 1, f_wav);
                            fwrite(&byte_rate, 4, 1, f_wav);
                            fwrite(&block_align, 2, 1, f_wav);
                            fwrite(&bits_per_sample, 2, 1, f_wav);
                            fwrite("data", 1, 4, f_wav);
                            fwrite(&data_bytes, 4, 1, f_wav);
                            fwrite(pcm.data(), 1, data_bytes, f_wav);
                            fclose(f_wav);
                        }
                        ctx_omni->token2wav_wav_idx++;
                    }
                }
                
                // Reset buffer for next round (re-initialize with 3 silence tokens)
                ctx_omni->token2wav_buffer.clear();
                ctx_omni->token2wav_buffer = {4218, 4218, 4218};
                ctx_omni->token2wav_wav_idx = 0;
            }
            
            tts_finish = false;
            chunk_idx = 0;
            llm_finish = false;
            tts_n_past = 0;  // Reset TTS model state
            audio_tokens.clear();
            all_audio_tokens.clear();  // Clear for next round
            printf("\ntts finished\n");

            ctx_omni->speek_done = true;
            ctx_omni->warmup_done = true;  // ç¬¬ä¸€è½®å¯¹è¯ç»“æŸï¼Œåç»­ prefill éœ€è¦ç­‰å¾…
            speek_cv.notify_all();
        } else if (audio_gen_finish && !llm_finish) {
            // Current chunk finished (either reached 25 tokens or EOS token) but LLM is still generating
            // Reset audio_gen_finish to allow processing next chunk from LLM
            // This ensures: LLMç”Ÿæˆ10ä¸ªtoken â†’ TTSç”Ÿæˆ25ä¸ªtoken â†’ LLMå†ç”Ÿæˆ10ä¸ªtoken â†’ TTSå†ç”Ÿæˆ25ä¸ªtoken
            fflush(stdout);
            audio_gen_finish = false;  // Reset for next chunk
            // Note: llm_text and response are already cleared above, so we'll wait for next chunk in the next iteration
        }
#endif  // End of disabled old TTS processing code
    }
}

// ======================= Python Token2Wav æœåŠ¡ç®¡ç†å‡½æ•° =======================

// å¯åŠ¨ Python Token2Wav æœåŠ¡è¿›ç¨‹
static bool start_python_t2w_service(struct omni_context * ctx_omni) {
    if (ctx_omni->python_t2w_initialized) {
        return true;  // å·²ç»å¯åŠ¨
    }

    // æ„å»º Python è„šæœ¬è·¯å¾„
    std::string script_path = ctx_omni->python_t2w_script_dir + "/token2wav_service.py";

    // æ£€æŸ¥è„šæœ¬æ˜¯å¦å­˜åœ¨
    FILE * check = fopen(script_path.c_str(), "r");
    if (!check) {
        LOG_ERR("Python T2W: è„šæœ¬ä¸å­˜åœ¨: %s\n", script_path.c_str());
        return false;
    }
    fclose(check);

    print_with_timestamp("Python T2W: å¯åŠ¨æœåŠ¡è¿›ç¨‹ %s\n", script_path.c_str());

    // åˆ›å»ºç®¡é“
#ifdef _WIN32
    // Windows: use CreateProcess with pipes for bidirectional communication
    SECURITY_ATTRIBUTES sa;
    sa.nLength              = sizeof(SECURITY_ATTRIBUTES);
    sa.bInheritHandle       = TRUE;
    sa.lpSecurityDescriptor = NULL;

    HANDLE hStdinRead, hStdinWrite, hStdoutRead, hStdoutWrite;

    if (!CreatePipe(&hStdinRead, &hStdinWrite, &sa, 0)) {
        LOG_ERR("Python T2W: CreatePipe (stdin) å¤±è´¥\n");
        return false;
    }
    SetHandleInformation(hStdinWrite, HANDLE_FLAG_INHERIT, 0);

    if (!CreatePipe(&hStdoutRead, &hStdoutWrite, &sa, 0)) {
        LOG_ERR("Python T2W: CreatePipe (stdout) å¤±è´¥\n");
        CloseHandle(hStdinRead);
        CloseHandle(hStdinWrite);
        return false;
    }
    SetHandleInformation(hStdoutRead, HANDLE_FLAG_INHERIT, 0);

    STARTUPINFOA        si;
    PROCESS_INFORMATION pi;
    ZeroMemory(&si, sizeof(si));
    si.cb         = sizeof(si);
    si.hStdInput  = hStdinRead;
    si.hStdOutput = hStdoutWrite;
    si.hStdError  = GetStdHandle(STD_ERROR_HANDLE);
    si.dwFlags |= STARTF_USESTDHANDLES;

    ZeroMemory(&pi, sizeof(pi));

    // Set environment if needed
    if (!ctx_omni->python_t2w_gpu_id.empty()) {
        _putenv_s("CUDA_VISIBLE_DEVICES", ctx_omni->python_t2w_gpu_id.c_str());
    }

    std::string win_cmd = "python \"" + script_path + "\"";
    char        cmd_buf[2048];
    strncpy(cmd_buf, win_cmd.c_str(), sizeof(cmd_buf) - 1);
    cmd_buf[sizeof(cmd_buf) - 1] = '\0';

    if (!CreateProcessA(NULL, cmd_buf, NULL, NULL, TRUE, 0, NULL, NULL, &si, &pi)) {
        LOG_ERR("Python T2W: CreateProcess å¤±è´¥, error=%lu\n", GetLastError());
        CloseHandle(hStdinRead);
        CloseHandle(hStdinWrite);
        CloseHandle(hStdoutRead);
        CloseHandle(hStdoutWrite);
        return false;
    }

    CloseHandle(hStdinRead);
    CloseHandle(hStdoutWrite);
    CloseHandle(pi.hThread);

    ctx_omni->python_t2w_pid = (int) (intptr_t) pi.hProcess;

    // Convert HANDLEs to FILE*
    int stdin_fd  = _open_osfhandle((intptr_t) hStdinWrite, 0);
    int stdout_fd = _open_osfhandle((intptr_t) hStdoutRead, 0);

    if (stdin_fd < 0 || stdout_fd < 0) {
        LOG_ERR("Python T2W: _open_osfhandle å¤±è´¥\n");
        TerminateProcess(pi.hProcess, 1);
        CloseHandle(pi.hProcess);
        return false;
    }

    ctx_omni->python_t2w_stdin  = _fdopen(stdin_fd, "w");
    ctx_omni->python_t2w_stdout = _fdopen(stdout_fd, "r");

#else
    // POSIX implementation using fork/pipe
    int stdin_pipe[2];
    int stdout_pipe[2];

    if (pipe(stdin_pipe) != 0 || pipe(stdout_pipe) != 0) {
        LOG_ERR("Python T2W: åˆ›å»ºç®¡é“å¤±è´¥\n");
        return false;
    }

    pid_t pid = fork();
    if (pid < 0) {
        LOG_ERR("Python T2W: fork å¤±è´¥\n");
        return false;
    }

    if (pid == 0) {
        // å­è¿›ç¨‹
        close(stdin_pipe[1]);   // å…³é—­å†™ç«¯
        close(stdout_pipe[0]);  // å…³é—­è¯»ç«¯

        dup2(stdin_pipe[0], STDIN_FILENO);
        dup2(stdout_pipe[1], STDOUT_FILENO);

        close(stdin_pipe[0]);
        close(stdout_pipe[1]);

        // ğŸ”§ è®¾ç½® CUDA_VISIBLE_DEVICES ç¯å¢ƒå˜é‡ï¼ˆå¿…é¡»åœ¨ import torch ä¹‹å‰ï¼‰
        // è¿™æ · Python å­è¿›ç¨‹åªèƒ½çœ‹åˆ°æŒ‡å®šçš„ GPU
        if (!ctx_omni->python_t2w_gpu_id.empty()) {
            setenv("CUDA_VISIBLE_DEVICES", ctx_omni->python_t2w_gpu_id.c_str(), 1);
        }

        // æ‰§è¡Œ Python è„šæœ¬ (ä½¿ç”¨ conda Python)
        execlp("/Users/tianchi/software/miniconda3/bin/python", "python", script_path.c_str(), (char *) NULL);

        // å¦‚æœ execlp å¤±è´¥
        _exit(1);
    }

    // çˆ¶è¿›ç¨‹
    close(stdin_pipe[0]);   // å…³é—­è¯»ç«¯
    close(stdout_pipe[1]);  // å…³é—­å†™ç«¯

    ctx_omni->python_t2w_pid    = pid;
    ctx_omni->python_t2w_stdin  = fdopen(stdin_pipe[1], "w");
    ctx_omni->python_t2w_stdout = fdopen(stdout_pipe[0], "r");
#endif

    if (!ctx_omni->python_t2w_stdin || !ctx_omni->python_t2w_stdout) {
        LOG_ERR("Python T2W: fdopen å¤±è´¥\n");
        stop_python_t2w_service(ctx_omni);
        return false;
    }

    // è®¾ç½®ä¸ºè¡Œç¼“å†²
    setvbuf(ctx_omni->python_t2w_stdin, NULL, _IOLBF, 0);
    setvbuf(ctx_omni->python_t2w_stdout, NULL, _IOLBF, 0);

    // ç­‰å¾…æœåŠ¡å°±ç»ª
    char buffer[4096];
    if (fgets(buffer, sizeof(buffer), ctx_omni->python_t2w_stdout)) {
        print_with_timestamp("Python T2W: æœåŠ¡å“åº”: %s", buffer);
        // æ£€æŸ¥æ˜¯å¦å°±ç»ª
        if (strstr(buffer, "\"status\":\"ready\"") || strstr(buffer, "\"status\": \"ready\"")) {
            ctx_omni->python_t2w_initialized = true;
            print_with_timestamp("Python T2W: æœåŠ¡å°±ç»ª\n");
            return true;
        }
    }

    LOG_ERR("Python T2W: æœåŠ¡æœªèƒ½æ­£å¸¸å¯åŠ¨\n");
    stop_python_t2w_service(ctx_omni);
    return false;
}

// åœæ­¢ Python Token2Wav æœåŠ¡è¿›ç¨‹
static void stop_python_t2w_service(struct omni_context * ctx_omni) {
    if (ctx_omni->python_t2w_stdin) {
        // å‘é€é€€å‡ºå‘½ä»¤
        fprintf(ctx_omni->python_t2w_stdin, "{\"cmd\":\"quit\"}\n");
        fflush(ctx_omni->python_t2w_stdin);
        fclose(ctx_omni->python_t2w_stdin);
        ctx_omni->python_t2w_stdin = nullptr;
    }

    if (ctx_omni->python_t2w_stdout) {
        fclose(ctx_omni->python_t2w_stdout);
        ctx_omni->python_t2w_stdout = nullptr;
    }

    if (ctx_omni->python_t2w_pid > 0) {
        // ç­‰å¾…å­è¿›ç¨‹é€€å‡º
#ifdef _WIN32
        HANDLE hProcess = (HANDLE) (intptr_t) ctx_omni->python_t2w_pid;
        // Wait briefly for process to exit gracefully
        if (WaitForSingleObject(hProcess, 500) == WAIT_TIMEOUT) {
            // Force terminate if still running
            TerminateProcess(hProcess, 1);
            WaitForSingleObject(hProcess, 1000);
        }
        CloseHandle(hProcess);
#else
        int status;
        waitpid(ctx_omni->python_t2w_pid, &status, WNOHANG);

        // å¦‚æœè¿˜æ²¡é€€å‡ºï¼Œå‘é€ SIGTERM
        if (kill(ctx_omni->python_t2w_pid, 0) == 0) {
            kill(ctx_omni->python_t2w_pid, SIGTERM);
            usleep(100000);  // ç­‰å¾… 100ms

            // å¦‚æœè¿˜æ²¡é€€å‡ºï¼Œå‘é€ SIGKILL
            if (kill(ctx_omni->python_t2w_pid, 0) == 0) {
                kill(ctx_omni->python_t2w_pid, SIGKILL);
            }
        }

        waitpid(ctx_omni->python_t2w_pid, &status, 0);
#endif
        ctx_omni->python_t2w_pid = -1;
    }

    ctx_omni->python_t2w_initialized = false;
    print_with_timestamp("Python T2W: æœåŠ¡å·²åœæ­¢\n");
}

// å‘é€å‘½ä»¤åˆ° Python æœåŠ¡å¹¶è·å–å“åº”
static bool send_python_t2w_command(struct omni_context * ctx_omni,
                                    const std::string &   cmd_json,
                                    std::string &         response) {
    if (!ctx_omni->python_t2w_initialized || !ctx_omni->python_t2w_stdin || !ctx_omni->python_t2w_stdout) {
        return false;
    }

    // å‘é€å‘½ä»¤
    fprintf(ctx_omni->python_t2w_stdin, "%s\n", cmd_json.c_str());
    fflush(ctx_omni->python_t2w_stdin);

    // è¯»å–å“åº”
    char buffer[8192];
    if (fgets(buffer, sizeof(buffer), ctx_omni->python_t2w_stdout)) {
        response = buffer;
        // å»æ‰æœ«å°¾æ¢è¡Œ
        while (!response.empty() && (response.back() == '\n' || response.back() == '\r')) {
            response.pop_back();
        }
        return true;
    }

    return false;
}

// åˆå§‹åŒ– Python Token2Wav æ¨¡å‹
static bool init_python_t2w_model(struct omni_context * ctx_omni, const std::string & device) {
    if (!ctx_omni->python_t2w_initialized) {
        if (!start_python_t2w_service(ctx_omni)) {
            return false;
        }
    }

    // ğŸ”§ è®¾å¤‡æ ¼å¼è½¬æ¢: "gpu:0" -> "cuda:0", "gpu" -> "cuda:0", "cpu" -> "cpu"
    // ç”±äº CUDA_VISIBLE_DEVICES å·²ç»åœ¨ fork æ—¶è®¾ç½®ï¼ŒPython åªèƒ½çœ‹åˆ°ä¸€å¼ å¡ï¼Œæ‰€ä»¥å§‹ç»ˆä½¿ç”¨ cuda:0
    std::string python_device = "cuda:0";
    if (device.find("cpu") != std::string::npos) {
        python_device = "cpu";
    }

    // å‘é€ init å‘½ä»¤
    // ğŸ”§ ä½¿ç”¨ float16 ä»¥èŠ‚çœæ˜¾å­˜ï¼ˆå·²åœ¨ token2wav_service.py ä¸­ä¿®å¤ dtype bugï¼‰
    char cmd[1024];
    snprintf(cmd, sizeof(cmd),
             "{\"cmd\":\"init\",\"model_dir\":\"%s\",\"device\":\"%s\",\"float16\":true,\"n_timesteps\":5}",
             ctx_omni->python_t2w_model_dir.c_str(), python_device.c_str());

    std::string response;
    if (!send_python_t2w_command(ctx_omni, cmd, response)) {
        LOG_ERR("Python T2W: init å‘½ä»¤å‘é€å¤±è´¥\n");
        return false;
    }

    print_with_timestamp("Python T2W init å“åº”: %s\n", response.c_str());
    return response.find("\"status\":\"ok\"") != std::string::npos ||
           response.find("\"status\": \"ok\"") != std::string::npos;
}

// è®¾ç½®å‚è€ƒéŸ³é¢‘
static bool set_python_t2w_ref_audio(struct omni_context * ctx_omni, const std::string & ref_audio_path) {
    char cmd[1024];
    snprintf(cmd, sizeof(cmd), "{\"cmd\":\"set_ref_audio\",\"ref_audio_path\":\"%s\"}", ref_audio_path.c_str());

    std::string response;
    if (!send_python_t2w_command(ctx_omni, cmd, response)) {
        LOG_ERR("Python T2W: set_ref_audio å‘½ä»¤å‘é€å¤±è´¥\n");
        return false;
    }

    print_with_timestamp("Python T2W set_ref_audio å“åº”: %s\n", response.c_str());
    return response.find("\"status\":\"ok\"") != std::string::npos ||
           response.find("\"status\": \"ok\"") != std::string::npos;
}

// å¤„ç† tokens å¹¶ç”Ÿæˆ WAV
static bool process_python_t2w_tokens(struct omni_context *        ctx_omni,
                                      const std::vector<int32_t> & tokens,
                                      bool                         last_chunk,
                                      const std::string &          output_path,
                                      double &                     inference_time_ms,
                                      double &                     audio_duration) {
    // æ„å»º tokens JSON æ•°ç»„
    std::string tokens_json = "[";
    for (size_t i = 0; i < tokens.size(); i++) {
        if (i > 0) {
            tokens_json += ",";
        }
        tokens_json += std::to_string(tokens[i]);
    }
    tokens_json += "]";

    char cmd[8192];
    snprintf(cmd, sizeof(cmd), "{\"cmd\":\"process\",\"tokens\":%s,\"last_chunk\":%s,\"output_path\":\"%s\"}",
             tokens_json.c_str(), last_chunk ? "true" : "false", output_path.c_str());

    std::string response;
    if (!send_python_t2w_command(ctx_omni, cmd, response)) {
        LOG_ERR("Python T2W: process å‘½ä»¤å‘é€å¤±è´¥\n");
        return false;
    }

    // è§£æå“åº”ä¸­çš„æ—¶é—´ä¿¡æ¯
    // ç®€å•è§£æï¼Œä¸ä½¿ç”¨ JSON åº“
    size_t pos = response.find("\"inference_time_ms\":");
    if (pos != std::string::npos) {
        inference_time_ms = atof(response.c_str() + pos + 20);
    }
    pos = response.find("\"audio_duration\":");
    if (pos != std::string::npos) {
        audio_duration = atof(response.c_str() + pos + 17);
    }

    return response.find("\"status\":\"ok\"") != std::string::npos ||
           response.find("\"status\": \"ok\"") != std::string::npos;
}

// é‡ç½® Python T2W ç¼“å­˜
static bool reset_python_t2w_cache(struct omni_context * ctx_omni) {
    std::string response;
    if (!send_python_t2w_command(ctx_omni, "{\"cmd\":\"reset\"}", response)) {
        LOG_ERR("Python T2W: reset å‘½ä»¤å‘é€å¤±è´¥\n");
        return false;
    }
    return response.find("\"status\":\"ok\"") != std::string::npos ||
           response.find("\"status\": \"ok\"") != std::string::npos;
}

// ======================= Token2Wav çº¿ç¨‹å‡½æ•° =======================

// Python Token2Wav thread function
void t2w_thread_func_python(struct omni_context * ctx_omni, common_params * params) {
    print_with_timestamp("T2W thread (Python) started\n");
    fflush(stdout);

    auto & queue = ctx_omni->t2w_thread_info->queue;
    auto & mtx   = ctx_omni->t2w_thread_info->mtx;
    auto & cv    = ctx_omni->t2w_thread_info->cv;

    // Token2Wav sliding window parameters
    constexpr int32_t CHUNK_SIZE    = 25;                          // Main chunk size (25 tokens = 1s audio)
    constexpr int32_t PRE_LOOKAHEAD = 3;                           // Lookahead for overlap
    constexpr int32_t WINDOW_SIZE   = CHUNK_SIZE + PRE_LOOKAHEAD;  // 28

    // Buffer to accumulate tokens (for sliding window)
    std::vector<int32_t> token_buffer = { 4218, 4218, 4218 };

    // ä½¿ç”¨å¯é…ç½®çš„ base_output_dir
    const std::string & base_output_dir = ctx_omni->base_output_dir;

    // Helper function to get round-specific output directory
    auto get_wav_output_dir = [&]() -> std::string {
        if (!ctx_omni->duplex_mode) {
            char round_dir[512];
            snprintf(round_dir, sizeof(round_dir), "%s/round_%03d/tts_wav", base_output_dir.c_str(),
                     ctx_omni->simplex_round_idx);
            return std::string(round_dir);
        } else {
            return base_output_dir + "/tts_wav";
        }
    };

    int         last_round_idx     = ctx_omni->simplex_round_idx;
    std::string tts_wav_output_dir = get_wav_output_dir();
    int         wav_idx            = 0;
    const int   sample_rate        = 24000;  // Python Token2Wav è¾“å‡ºé‡‡æ ·ç‡

    // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    {
        cross_platform_mkdir_p(tts_wav_output_dir);
    }

    while (t2w_thread_running) {
        // æ£€æµ‹æ‰“æ–­äº‹ä»¶
        if (ctx_omni->break_event.load()) {
            std::lock_guard<std::mutex> lock(mtx);
            while (!queue.empty()) {
                T2WOut * t2w_out = queue.front();
                queue.pop();
                delete t2w_out;
            }
            ctx_omni->break_event = false;
            token_buffer          = { 4218, 4218, 4218 };
            wav_idx               = 0;

            if (!ctx_omni->duplex_mode) {
                ctx_omni->wav_turn_base += 1000;
            }

            if (!ctx_omni->duplex_mode && ctx_omni->simplex_round_idx != last_round_idx) {
                last_round_idx     = ctx_omni->simplex_round_idx;
                tts_wav_output_dir = get_wav_output_dir();
                cross_platform_mkdir_p(tts_wav_output_dir);
            }

            // é‡ç½® Python ç¼“å­˜
            reset_python_t2w_cache(ctx_omni);
            continue;
        }

        std::unique_lock<std::mutex> lock(mtx);
        cv.wait(lock, [&] { return !queue.empty() || !t2w_thread_running; });

        if (!t2w_thread_running && queue.empty()) {
            break;
        }

        if (ctx_omni->break_event.load()) {
            lock.unlock();
            continue;
        }

        // Get all available tokens from queue
        std::vector<llama_token> new_tokens;
        bool                     is_final           = false;
        bool                     is_chunk_end       = false;
        int                      received_round_idx = -1;  // ğŸ”§ ä»é˜Ÿåˆ—ä¸­è·å–çš„ round_idx

        while (!queue.empty()) {
            T2WOut * t2w_out = queue.front();
            queue.pop();
            new_tokens.insert(new_tokens.end(), t2w_out->audio_tokens.begin(), t2w_out->audio_tokens.end());
            is_final     = is_final || t2w_out->is_final;
            is_chunk_end = is_chunk_end || t2w_out->is_chunk_end;
            // ğŸ”§ ä½¿ç”¨æœ€æ–°çš„ round_idxï¼ˆæœ€åä¸€ä¸ªæœ‰æ•ˆçš„å€¼ï¼‰
            if (t2w_out->round_idx >= 0) {
                received_round_idx = t2w_out->round_idx;
            }
            delete t2w_out;
        }

        lock.unlock();

        if (new_tokens.empty() && !is_chunk_end && !is_final) {
            continue;
        }

        // ğŸ”§ [é€šè¿‡ T2WOut ä¼ é€’ round_idx] ä½¿ç”¨ä¼ å…¥çš„ round_idx ç¡®å®šè¾“å‡ºç›®å½•
        // è¿™æ¯”ä» ctx_omni->simplex_round_idx è¯»å–æ›´å¯é ï¼Œé¿å…ç«æ€æ¡ä»¶
        if (!ctx_omni->duplex_mode && received_round_idx >= 0 && received_round_idx != last_round_idx) {
            print_with_timestamp("T2W(Python): round_idx å˜åŒ– %d -> %dï¼ˆæ¥è‡ªT2WOutï¼‰ï¼Œæ›´æ–°è¾“å‡ºç›®å½•\n", last_round_idx,
                                 received_round_idx);
            last_round_idx     = received_round_idx;
            tts_wav_output_dir = get_wav_output_dir();
            cross_platform_mkdir_p(tts_wav_output_dir);
            // é‡ç½® wav ç´¢å¼•ï¼Œå› ä¸ºæ˜¯æ–°çš„è½®æ¬¡
            wav_idx = 0;
        }

        // Add new tokens to buffer
        token_buffer.insert(token_buffer.end(), new_tokens.begin(), new_tokens.end());

        // æ£€æŸ¥ Python æœåŠ¡æ˜¯å¦åˆå§‹åŒ–
        if (!ctx_omni->python_t2w_initialized) {
            continue;
        }

        bool   need_flush            = false;
        size_t min_process_threshold = WINDOW_SIZE;

        if (!ctx_omni->duplex_mode) {
            need_flush = is_final || is_chunk_end;
        } else {
            need_flush = is_final;
        }

        // ğŸ”§ [ä¿®å¤åŒå·¥æ¨¡å¼æœ€åä¸€ä¸ªå­—æ²¡è¯´å®Œ] å½“ is_final=true ä½† token_buffer ä¸ºç©ºæ—¶
        // ä¹Ÿéœ€è¦è°ƒç”¨ reset_python_t2w_cacheï¼Œå¦åˆ™ T2W çš„æµå¼ç¼“å­˜ä¸ä¼šè¢«é‡ç½®
        // è¿™ä¼šå¯¼è‡´ä¸‹ä¸€ä¸ª turn çš„éŸ³é¢‘å’Œä¸Šä¸€ä¸ª turn çš„å°¾éŸ³æ··åœ¨ä¸€èµ·
        if (is_final && token_buffer.empty()) {
            print_with_timestamp("T2W(Python): is_final=true but token_buffer empty, calling reset directly\n");
            reset_python_t2w_cache(ctx_omni);
            // ä¸éœ€è¦å¤„ç† token_bufferï¼Œç›´æ¥ç»§ç»­ç­‰å¾…ä¸‹ä¸€ä¸ªæ¶ˆæ¯
            continue;
        }

        // Process windows using sliding window
        while (token_buffer.size() >= min_process_threshold || (need_flush && !token_buffer.empty())) {
            size_t process_size   = std::min(token_buffer.size(), (size_t) WINDOW_SIZE);
            bool   is_last_window = need_flush && (token_buffer.size() <= WINDOW_SIZE);

            std::vector<int32_t> window(token_buffer.begin(), token_buffer.begin() + process_size);

            // ç”Ÿæˆ WAV è¾“å‡ºè·¯å¾„
            std::string wav_path =
                tts_wav_output_dir + "/wav_" + std::to_string(ctx_omni->wav_turn_base + wav_idx) + ".wav";

            double inference_time_ms = 0;
            double audio_duration    = 0;

            if (process_python_t2w_tokens(ctx_omni, window, is_last_window, wav_path, inference_time_ms,
                                          audio_duration)) {
                if (audio_duration > 0) {
                    auto wav_complete_time = std::chrono::high_resolution_clock::now();
                    auto elapsed_ms        = std::chrono::duration_cast<std::chrono::milliseconds>(
                                          wav_complete_time - ctx_omni->stream_decode_start_time)
                                          .count();

                    if (wav_idx == 0) {
                        print_with_timestamp("ğŸ‰ é¦–å“æ—¶é—´ (First Audio Response): %lldms\n", (long long) elapsed_ms);
                    }

                    float rtf = (float) (inference_time_ms / 1000.0) / audio_duration;
                    print_with_timestamp(
                        "T2W(Python): wav_%d.wav | %.2fs audio | %.1fms inference | RTF=%.2f | t=%lldms\n",
                        ctx_omni->wav_turn_base + wav_idx, audio_duration, inference_time_ms, rtf,
                        (long long) elapsed_ms);
                    wav_idx++;

                    // æ³¨æ„ï¼šä¸è¦åœ¨ä¸­é€”é‡ç½®ç¼“å­˜ï¼Python åŸç‰ˆåœ¨æ•´ä¸ªå¯¹è¯ä¸­ä¿æŒç¼“å­˜è¿ç»­
                    // åªåœ¨å¯¹è¯/è½®æ¬¡ç»“æŸæ—¶ï¼ˆis_final=trueï¼‰æ‰é‡ç½®ç¼“å­˜
                    // ä½¿ç”¨ç‹¬ç«‹ GPU åï¼Œæ˜¾å­˜ä¸å†æ˜¯é—®é¢˜
                }
            } else {
                LOG_ERR("T2W(Python): process å¤±è´¥\n");
            }

            // Slide window
            if (!ctx_omni->duplex_mode) {
                if (token_buffer.size() > CHUNK_SIZE) {
                    token_buffer.erase(token_buffer.begin(), token_buffer.begin() + CHUNK_SIZE);
                } else {
                    token_buffer.clear();
                }
            } else {
                size_t slide_amount;
                if (is_last_window) {
                    slide_amount = token_buffer.size();
                } else if (token_buffer.size() > CHUNK_SIZE) {
                    slide_amount = CHUNK_SIZE;
                } else if (token_buffer.size() > PRE_LOOKAHEAD) {
                    slide_amount = token_buffer.size() - PRE_LOOKAHEAD;
                } else {
                    slide_amount = 0;
                }

                if (slide_amount > 0 && slide_amount <= token_buffer.size()) {
                    token_buffer.erase(token_buffer.begin(), token_buffer.begin() + slide_amount);
                } else if (slide_amount > token_buffer.size()) {
                    token_buffer.clear();
                }
            }

            if (is_last_window) {
                if (is_final) {
                    // å†™å…¥ç»“æŸæ ‡è®°
                    std::string done_flag_path = tts_wav_output_dir + "/generation_done.flag";
                    FILE *      flag_file      = fopen(done_flag_path.c_str(), "w");
                    if (flag_file) {
                        int last_wav_idx = (wav_idx > 0) ? (ctx_omni->wav_turn_base + wav_idx - 1) : 0;
                        fprintf(flag_file, "%d\n", last_wav_idx);
                        fclose(flag_file);
                    }

                    token_buffer = { 4218, 4218, 4218 };

                    // é‡ç½® Python ç¼“å­˜
                    reset_python_t2w_cache(ctx_omni);

                    if (!ctx_omni->duplex_mode) {
                        wav_idx = 0;
                        ctx_omni->wav_turn_base += 1000;
                    }

                    if (!ctx_omni->duplex_mode && ctx_omni->simplex_round_idx != last_round_idx) {
                        last_round_idx     = ctx_omni->simplex_round_idx;
                        tts_wav_output_dir = get_wav_output_dir();
                        cross_platform_mkdir_p(tts_wav_output_dir);
                    }
                }
                break;
            }
        }
    }

    print_with_timestamp("T2W(Python) çº¿ç¨‹: åœæ­¢\n");
    fflush(stdout);
}

// C++ Token2Wav thread function (åŸå®ç°ï¼Œä¿ç•™ä½œä¸ºå¤‡é€‰)
// ==============================================================================
// T2W Thread Function (C++ Token2Wav)
// ==============================================================================
//
// ğŸ“Œ å…³äºè½®æ¬¡ç®¡ç†çš„è¯´æ˜ï¼ˆå•å·¥æ¨¡å¼ä¸“ç”¨ï¼‰ï¼š
//
// å•å·¥æ¨¡å¼ä¸‹ï¼Œæ¯è½®å¯¹è¯çš„ WAV è¾“å‡ºä¿å­˜åœ¨ä¸åŒçš„ round_XXX ç›®å½•ä¸­ã€‚
// ç»Ÿä¸€ä½¿ç”¨ ctx_omni->simplex_round_idx ä½œä¸ºè½®æ¬¡ç´¢å¼•çš„å”¯ä¸€æ¥æºã€‚
//
// å˜é‡è¯´æ˜ï¼š
// 1. ctx_omni->simplex_round_idxï¼ˆå…¨å±€å˜é‡ï¼Œå”¯ä¸€æ¥æºï¼‰
//    - å­˜å‚¨åœ¨ omni_context ç»“æ„ä½“ä¸­çš„ã€Œå½“å‰è½®æ¬¡ç´¢å¼•ã€
//    - æ›´æ–°æ—¶æœºï¼š
//      a) stream_decode å¼€å§‹æ—¶ï¼Œé€šè¿‡ä¼ å…¥çš„ round_idx å‚æ•°åŒæ­¥
//      b) TTS çº¿ç¨‹åœ¨æ¯è½®ç»“æŸæ—¶é€’å¢ï¼ˆåœ¨å‘é€ is_final=true ä¹‹å‰ï¼‰
//    - åˆå§‹å€¼ä¸º 0ï¼Œæ¯è½®å¯¹è¯ç»“æŸå +1
//
// 2. last_round_idxï¼ˆT2W çº¿ç¨‹æœ¬åœ°å˜é‡ï¼‰
//    - T2W çº¿ç¨‹å†…éƒ¨è®°å½•çš„ã€Œä¸Šä¸€æ¬¡ä½¿ç”¨çš„è½®æ¬¡ç´¢å¼•ã€
//    - ç”¨äºæ£€æµ‹ simplex_round_idx æ˜¯å¦å‘ç”Ÿå˜åŒ–
//    - å½“ simplex_round_idx != last_round_idx æ—¶ï¼Œè¯´æ˜è¿›å…¥äº†æ–°è½®æ¬¡ï¼Œéœ€è¦æ›´æ–°è¾“å‡ºç›®å½•
//
// è½®æ¬¡åŒæ­¥æµç¨‹ï¼š
//   Pythonè°ƒç”¨ stream_decode(round_idx) -> åŒæ­¥ simplex_round_idx
//                                              â†“
//   T2Wçº¿ç¨‹æ£€æµ‹åˆ° simplex_round_idx != last_round_idx -> æ›´æ–° tts_wav_output_dir
// ==============================================================================
void t2w_thread_func_cpp(struct omni_context * ctx_omni, common_params * params) {
    print_with_timestamp("T2W thread (C++) started\n");
    fflush(stdout);

    auto & queue = ctx_omni->t2w_thread_info->queue;
    auto & mtx   = ctx_omni->t2w_thread_info->mtx;
    auto & cv    = ctx_omni->t2w_thread_info->cv;

    // Token2Wav sliding window parameters
    constexpr int32_t CHUNK_SIZE    = 25;                          // Main chunk size (25 tokens = 1s audio)
    constexpr int32_t PRE_LOOKAHEAD = 3;                           // Lookahead for overlap
    constexpr int32_t WINDOW_SIZE   = CHUNK_SIZE + PRE_LOOKAHEAD;  // 28

    // Buffer to accumulate tokens (for sliding window)
    // Python: buffer = [4218] * 3  # é¢„å…ˆæ”¾å…¥3ä¸ªå‰ç¼€é™éŸ³token
    std::vector<int32_t> token_buffer = { 4218, 4218, 4218 };

    // ğŸ”§ [å¤šå®ä¾‹æ”¯æŒ] ä½¿ç”¨å¯é…ç½®çš„ base_output_dir
    const std::string & base_output_dir = ctx_omni->base_output_dir;

    // ğŸ”§ [å•å·¥æ¨¡å¼] Helper function to get round-specific output directory
    auto get_wav_output_dir = [&]() -> std::string {
        if (!ctx_omni->duplex_mode) {
            // å•å·¥æ¨¡å¼ï¼šä½¿ç”¨ round_XXX å­ç›®å½•
            char round_dir[512];
            snprintf(round_dir, sizeof(round_dir), "%s/round_%03d/tts_wav", base_output_dir.c_str(),
                     ctx_omni->simplex_round_idx);
            return std::string(round_dir);
        } else {
            // åŒå·¥æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨ base_output_dir
            return base_output_dir + "/tts_wav";
        }
    };

    // ğŸ“Œ last_round_idxï¼šT2W çº¿ç¨‹æœ¬åœ°è®°å½•çš„ã€Œä¸Šä¸€æ¬¡ä½¿ç”¨çš„è½®æ¬¡ã€
    // ç”¨äºæ£€æµ‹ simplex_round_idx æ˜¯å¦å˜åŒ–ï¼Œå¦‚æœå˜åŒ–åˆ™æ›´æ–°è¾“å‡ºç›®å½•
    // ğŸ”§ [ä¿®å¤ç¬¬ä¸€è½®æ— è¾“å‡º] åˆå§‹åŒ–ä¸º -1ï¼Œç¡®ä¿ç¬¬ä¸€è½®ä¹Ÿä¼šè§¦å‘ç›®å½•åˆ›å»º
    int last_round_idx = -1;

    // WAV output settings (ä¸ tts_thread_func ä¿æŒä¸€è‡´)
    std::string tts_wav_output_dir = get_wav_output_dir();
    int         wav_idx            = 0;
    const int   sample_rate        = omni::flow::Token2Wav::kSampleRate;

    while (t2w_thread_running) {
        // ğŸ”§ [P0-æ‰“æ–­æ£€æµ‹] æ£€æµ‹ break_event å¹¶æ¸…ç©ºé˜Ÿåˆ—
        if (ctx_omni->break_event.load()) {
            std::lock_guard<std::mutex> lock(mtx);
            while (!queue.empty()) {
                T2WOut * t2w_out = queue.front();
                queue.pop();
                delete t2w_out;
            }
            // é‡ç½® break_event åç»§ç»­ç­‰å¾…æ–°ä»»åŠ¡
            ctx_omni->break_event = false;
            token_buffer          = { 4218, 4218, 4218 };  // é‡ç½® buffer
            wav_idx               = 0;                     // é‡ç½® wav index

            // ğŸ”§ [ä¿®å¤ç«æ€æ¡ä»¶] åœ¨ T2W çº¿ç¨‹å¤„ç†å®Œæ‰“æ–­åé€’å¢ wav_turn_base
            // åŸå› ï¼šç¡®ä¿å½“å‰è½®æ¬¡çš„æ‰€æœ‰ wav æ–‡ä»¶ä½¿ç”¨æ—§çš„ç¼–å·ï¼Œç„¶åå†åˆ‡æ¢åˆ°æ–°ç¼–å·
            if (!ctx_omni->duplex_mode) {
                ctx_omni->wav_turn_base += 1000;
            }

            // ğŸ”§ [å•å·¥æ¨¡å¼] æ‰“æ–­åæ›´æ–°è¾“å‡ºç›®å½•ï¼ˆTTS çº¿ç¨‹å·²ç»é€’å¢äº† simplex_round_idxï¼‰
            if (!ctx_omni->duplex_mode && ctx_omni->simplex_round_idx != last_round_idx) {
                last_round_idx     = ctx_omni->simplex_round_idx;
                tts_wav_output_dir = get_wav_output_dir();
                print_with_timestamp("T2Wçº¿ç¨‹: æ‰“æ–­åæ›´æ–°è¾“å‡ºç›®å½•ä¸º %s\n", tts_wav_output_dir.c_str());
            }
            continue;
        }

        std::unique_lock<std::mutex> lock(mtx);

        // Wait for queue to have data or thread to stop
        cv.wait(lock, [&] { return !queue.empty() || !t2w_thread_running || ctx_omni->break_event.load(); });

        if (!t2w_thread_running && queue.empty()) {
            break;
        }

        // ğŸ”§ [P0-æ‰“æ–­æ£€æµ‹] æ£€æµ‹åˆ° break_event æ—¶è·³è¿‡å½“å‰æ•°æ®
        if (ctx_omni->break_event.load()) {
            lock.unlock();
            continue;
        }

        // Get all available tokens from queue
        std::vector<llama_token> new_tokens;
        bool                     is_final           = false;
        bool                     is_chunk_end       = false;  // æ ‡è®° TTS chunk ç»“æŸ
        int                      received_round_idx = -1;     // ğŸ”§ ä¿å­˜ä¼ å…¥çš„ round_idx

        while (!queue.empty()) {
            T2WOut * t2w_out = queue.front();
            queue.pop();

            new_tokens.insert(new_tokens.end(), t2w_out->audio_tokens.begin(), t2w_out->audio_tokens.end());
            is_final     = is_final || t2w_out->is_final;          // ä»»ä½•ä¸€ä¸ªæ˜¯ final å°±æ˜¯ final
            is_chunk_end = is_chunk_end || t2w_out->is_chunk_end;  // ä»»ä½•ä¸€ä¸ªæ˜¯ chunk_end å°±æ˜¯ chunk_end
            // ğŸ”§ ä¿å­˜æœ€åä¸€ä¸ªæœ‰æ•ˆçš„ round_idxï¼ˆä¼˜å…ˆä½¿ç”¨éè´Ÿå€¼ï¼‰
            if (t2w_out->round_idx >= 0) {
                received_round_idx = t2w_out->round_idx;
            }
            delete t2w_out;
        }

        lock.unlock();

        if (new_tokens.empty() && !is_chunk_end && !is_final) {
            continue;
        }

        // ğŸ“Œ [è½®æ¬¡åˆ‡æ¢æ£€æµ‹] ä½¿ç”¨ T2WOut ä¼ å…¥çš„ round_idx åˆ¤æ–­ï¼Œè€Œä¸æ˜¯ç›´æ¥è¯»å– ctx_omni->simplex_round_idx
        // åŸå› ï¼šTTS çº¿ç¨‹åœ¨å‘é€ is_final ä¹‹å‰ä¼šé€’å¢ simplex_round_idxï¼Œå¯¼è‡´ç«æ€æ¡ä»¶
        // ç°åœ¨ T2WOut.round_idx ä¿å­˜çš„æ˜¯é€’å¢å‰çš„å€¼ï¼Œç¡®ä¿ WAV å†™å…¥æ­£ç¡®çš„ç›®å½•
        int effective_round_idx = (received_round_idx >= 0) ? received_round_idx : ctx_omni->simplex_round_idx;

        if (!ctx_omni->duplex_mode && effective_round_idx != last_round_idx) {
            print_with_timestamp("T2Wçº¿ç¨‹(C++): è½®æ¬¡åˆ‡æ¢ (%d -> %d)ï¼Œæ›´æ–°è¾“å‡ºç›®å½•\n", last_round_idx,
                                 effective_round_idx);

            // æ›´æ–°æœ¬åœ°è®°å½•çš„è½®æ¬¡
            last_round_idx = effective_round_idx;

            // æ›´æ–°è¾“å‡ºç›®å½•ï¼ˆåŸºäº effective_round_idxï¼‰
            tts_wav_output_dir = base_output_dir + "/round_" +
                                 (effective_round_idx < 100 ? (effective_round_idx < 10 ? "00" : "0") : "") +
                                 std::to_string(effective_round_idx) + "/tts_wav";

            // é‡ç½®è½®æ¬¡ç›¸å…³çŠ¶æ€
            wav_idx                 = 0;                           // WAV æ–‡ä»¶ç¼–å·ä» 0 å¼€å§‹
            ctx_omni->wav_turn_base = effective_round_idx * 1000;  // æ›´æ–°å…¨å±€ WAV ç¼–å·åŸºæ•°
            token_buffer            = { 4218, 4218, 4218 };        // é‡ç½® token bufferï¼ˆ3ä¸ªé™éŸ³å‰ç¼€ï¼‰

            print_with_timestamp("T2Wçº¿ç¨‹(C++): æ–°è¾“å‡ºç›®å½• %s\n", tts_wav_output_dir.c_str());

            // ç¡®ä¿ç›®å½•å­˜åœ¨
            cross_platform_mkdir_p(tts_wav_output_dir);
        }

        // Add new tokens to buffer
        size_t buffer_before = token_buffer.size();
        token_buffer.insert(token_buffer.end(), new_tokens.begin(), new_tokens.end());

        // ğŸ”§ [DEBUG] æ‰“å°æ”¶åˆ°çš„ token IDs (åªæ‰“å°å‰10ä¸ªå’Œå3ä¸ª)
        if (new_tokens.size() > 0) {
            std::string tokens_str = "[";
            for (size_t i = 0; i < std::min(new_tokens.size(), (size_t) 10); i++) {
                tokens_str += std::to_string(new_tokens[i]);
                if (i < std::min(new_tokens.size(), (size_t) 10) - 1) {
                    tokens_str += ",";
                }
            }
            if (new_tokens.size() > 10) {
                tokens_str += "...";
                for (size_t i = new_tokens.size() - 3; i < new_tokens.size(); i++) {
                    tokens_str += "," + std::to_string(new_tokens[i]);
                }
            }
            tokens_str += "]";
        }

        // Check if token2wav is initialized
        if (!ctx_omni->token2wav_initialized || !ctx_omni->token2wav_session) {
            continue;
        }

        // å¤„ç†é€»è¾‘ï¼ˆå•å·¥/åŒå·¥åˆ†å¼€ï¼‰
        bool   need_flush            = false;
        size_t min_process_threshold = WINDOW_SIZE;

        if (!ctx_omni->duplex_mode) {
            need_flush = is_final || is_chunk_end;
        } else {
            need_flush = is_final;  // å®Œå…¨ flush åªåœ¨è½®æ¬¡ç»“æŸæ—¶
        }

        // Process windows using sliding window
        int process_count = 0;
        while (token_buffer.size() >= min_process_threshold || (need_flush && !token_buffer.empty())) {
            // Determine how many tokens to process
            size_t process_size   = std::min(token_buffer.size(), (size_t) WINDOW_SIZE);
            // ğŸ”§ is_last_window: å½“æ˜¯ final æˆ– chunk_endï¼Œä¸” buffer ä¸­çš„ tokens ä¸è¶³ä¸€ä¸ªå®Œæ•´ window æ—¶
            bool   is_last_window = need_flush && (token_buffer.size() <= WINDOW_SIZE);

            std::vector<int32_t> window(token_buffer.begin(), token_buffer.begin() + process_size);

            // Time the inference
            auto t2w_start = std::chrono::high_resolution_clock::now();

            std::vector<float> chunk_wav;
            if (ctx_omni->token2wav_session->feed_window(window, is_last_window, chunk_wav)) {
                auto   t2w_end = std::chrono::high_resolution_clock::now();
                double t2w_ms  = std::chrono::duration<double, std::milli>(t2w_end - t2w_start).count();

                if (!chunk_wav.empty()) {
                    // Write WAV file
                    std::string wav_path =
                        tts_wav_output_dir + "/wav_" + std::to_string(ctx_omni->wav_turn_base + wav_idx) + ".wav";

                    const int16_t num_channels    = 1;
                    const int16_t bits_per_sample = 16;
                    const int16_t block_align     = num_channels * (bits_per_sample / 8);
                    const int32_t byte_rate       = sample_rate * block_align;

                    std::vector<int16_t> pcm(chunk_wav.size());
                    for (size_t i = 0; i < chunk_wav.size(); ++i) {
                        float x = chunk_wav[i];
                        if (!std::isfinite(x)) {
                            x = 0.0f;
                        }
                        x      = std::max(-1.0f, std::min(1.0f, x));
                        pcm[i] = (int16_t) (x * 32767.0f);
                    }

                    uint32_t data_bytes = (uint32_t) (pcm.size() * sizeof(int16_t));
                    uint32_t riff_size  = 36u + data_bytes;

                    FILE * f_wav = fopen(wav_path.c_str(), "wb");
                    if (f_wav) {
                        fwrite("RIFF", 1, 4, f_wav);
                        fwrite(&riff_size, 4, 1, f_wav);
                        fwrite("WAVE", 1, 4, f_wav);
                        fwrite("fmt ", 1, 4, f_wav);
                        uint32_t fmt_size     = 16;
                        uint16_t audio_format = 1;
                        fwrite(&fmt_size, 4, 1, f_wav);
                        fwrite(&audio_format, 2, 1, f_wav);
                        fwrite(&num_channels, 2, 1, f_wav);
                        fwrite(&sample_rate, 4, 1, f_wav);
                        fwrite(&byte_rate, 4, 1, f_wav);
                        fwrite(&block_align, 2, 1, f_wav);
                        fwrite(&bits_per_sample, 2, 1, f_wav);
                        fwrite("data", 1, 4, f_wav);
                        fwrite(&data_bytes, 4, 1, f_wav);
                        fwrite(pcm.data(), 1, data_bytes, f_wav);
                        fclose(f_wav);

                        float audio_duration = chunk_wav.size() / (float) sample_rate;
                        float rtf            = (float) (t2w_ms / 1000.0) / audio_duration;

                        auto wav_complete_time = std::chrono::high_resolution_clock::now();
                        auto elapsed_ms        = std::chrono::duration_cast<std::chrono::milliseconds>(
                                              wav_complete_time - ctx_omni->stream_decode_start_time)
                                              .count();

                        if (wav_idx == 0) {
                            print_with_timestamp("ğŸ‰ é¦–å“æ—¶é—´ (First Audio Response): %lldms\n",
                                                 (long long) elapsed_ms);
                        }
                        print_with_timestamp(
                            "T2Wçº¿ç¨‹: wav_%d.wav | %.2fs audio | %.1fms inference | RTF=%.2f | t=%lldms\n",
                            ctx_omni->wav_turn_base + wav_idx, audio_duration, t2w_ms, rtf, (long long) elapsed_ms);
                        wav_idx++;
                    }
                }
            } else {
                LOG_ERR("T2Wçº¿ç¨‹: feed_window å¤±è´¥\n");
            }

            // Slide window by CHUNK_SIZE (25), keep last PRE_LOOKAHEAD (3) for overlap
            size_t buffer_before_slide = token_buffer.size();

            if (!ctx_omni->duplex_mode) {
                // ğŸ”§ [å•å·¥æ¨¡å¼] ä¿æŒåŸæœ‰é€»è¾‘ï¼Œç»å¯¹ä¸æ”¹åŠ¨
                // Slide window by CHUNK_SIZE (25), keep last PRE_LOOKAHEAD (3) for overlap
                if (token_buffer.size() > CHUNK_SIZE) {
                    token_buffer.erase(token_buffer.begin(), token_buffer.begin() + CHUNK_SIZE);
                } else {
                    token_buffer.clear();
                }
            } else {
                // ğŸ”§ [åŒå·¥æ¨¡å¼-ä¸ Python å¯¹é½]
                // Python: self.token2wav_buffer = self.token2wav_buffer[min(CHUNK_SIZE, chunk_to_process - self.pre_lookahead):]
                size_t slide_amount;
                if (is_last_window) {
                    // æœ€åä¸€ä¸ª windowï¼Œæ¸…ç©º buffer
                    slide_amount = token_buffer.size();
                } else if (token_buffer.size() > CHUNK_SIZE) {
                    // æ­£å¸¸æƒ…å†µï¼šæ»‘åŠ¨ CHUNK_SIZE
                    slide_amount = CHUNK_SIZE;
                } else if (token_buffer.size() > PRE_LOOKAHEAD) {
                    // æœ‰ chunk_eos æ—¶ï¼Œä¿ç•™ pre_lookahead
                    slide_amount = token_buffer.size() - PRE_LOOKAHEAD;
                } else {
                    slide_amount = 0;  // å¤ªå°‘äº†ï¼Œä¸æ»‘åŠ¨
                }

                if (slide_amount > 0 && slide_amount <= token_buffer.size()) {
                    token_buffer.erase(token_buffer.begin(), token_buffer.begin() + slide_amount);
                } else if (slide_amount > token_buffer.size()) {
                    token_buffer.clear();
                }
            }
            process_count++;

            if (is_last_window) {
                // ğŸ”§ [ä¸ Python å¯¹é½] åªæœ‰ is_finalï¼ˆè½®æ¬¡ç»“æŸï¼‰æ—¶æ‰é‡ç½®
                // Python: if is_last_chunk: stream(..., last_chunk=True); buffer = []
                // æ™®é€š chunk ç»“æŸæ—¶ï¼Œå‰©ä½™ tokens ä¿ç•™åœ¨ buffer ä¸­ç­‰å¾…ä¸‹ä¸€ä¸ª chunk
                if (is_final) {
                    // ğŸš€ [ä¼˜åŒ–] å†™å…¥ç»“æŸæ ‡è®°æ–‡ä»¶ï¼Œé€šçŸ¥ Python ç«‹å³ç»“æŸï¼ˆæ— éœ€ç­‰å¾…è¶…æ—¶ï¼‰
                    // æ ‡è®°æ–‡ä»¶åŒ…å«æœ€åä¸€ä¸ª wav çš„ç¼–å·ï¼Œæ–¹ä¾¿ Python éªŒè¯
                    {
                        std::string done_flag_path = tts_wav_output_dir + "/generation_done.flag";
                        FILE *      flag_file      = fopen(done_flag_path.c_str(), "w");
                        if (flag_file) {
                            // å†™å…¥æœ€åä¸€ä¸ª wav çš„ç¼–å·ï¼ˆwav_idx - 1ï¼Œå› ä¸º wav_idx å·²ç»æŒ‡å‘ä¸‹ä¸€ä¸ªï¼‰
                            int last_wav_idx = (wav_idx > 0) ? (ctx_omni->wav_turn_base + wav_idx - 1) : 0;
                            fprintf(flag_file, "%d\n", last_wav_idx);
                            fclose(flag_file);
                            print_with_timestamp("T2Wçº¿ç¨‹: å†™å…¥ç»“æŸæ ‡è®° %s (last_wav=%d)\n", done_flag_path.c_str(),
                                                 last_wav_idx);
                        }
                    }

                    // ğŸ”§ [å…³é”®] ä¸è°ƒç”¨ Token2WavSession::reset()
                    // åŸå› ï¼šreset() ä¼šæŠŠ stream_started_=falseï¼Œå¯¼è‡´ä¸‹ä¸€è½® feed_window å¤±è´¥
                    // å•å·¥å’ŒåŒå·¥æ¨¡å¼éƒ½åªé‡ç½® token_bufferï¼Œä¿æŒ Token2Wav çš„ stream çŠ¶æ€
                    // é‡æ–°åˆå§‹åŒ–bufferï¼ˆ3ä¸ªé™éŸ³tokenä½œä¸ºå‰ç¼€ï¼‰
                    token_buffer = { 4218, 4218, 4218 };

                    // ğŸ”§ [ä¿®å¤ç«æ€æ¡ä»¶] åœ¨ T2W çº¿ç¨‹å¤„ç†å®Œ is_final åé€’å¢ wav_turn_base
                    // åŸå› ï¼šç¡®ä¿å½“å‰è½®æ¬¡çš„æ‰€æœ‰ wav æ–‡ä»¶ä½¿ç”¨æ—§çš„ç¼–å·ï¼Œç„¶åå†åˆ‡æ¢åˆ°æ–°ç¼–å·
                    // è¿™æ ·é¿å…äº† TTS çº¿ç¨‹æå‰é€’å¢å¯¼è‡´æœ€åå‡ ä¸ª wav æ–‡ä»¶ç¼–å·è·³è·ƒçš„é—®é¢˜
                    if (!ctx_omni->duplex_mode) {
                        wav_idx = 0;  // ğŸ”§ [å•å·¥æ¨¡å¼] é‡ç½® wav_idx ç”¨äºä¸‹ä¸€è½®
                        ctx_omni->wav_turn_base += 1000;
                    }

                    // ğŸ”§ [å•å·¥æ¨¡å¼] åœ¨ is_final åæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ç›®å½•
                    // simplex_round_idx å·²ç»åœ¨ TTS çº¿ç¨‹ä¸­é€’å¢
                    if (!ctx_omni->duplex_mode && ctx_omni->simplex_round_idx != last_round_idx) {
                        last_round_idx     = ctx_omni->simplex_round_idx;
                        tts_wav_output_dir = get_wav_output_dir();
                        print_with_timestamp("T2Wçº¿ç¨‹: è½®æ¬¡ç»“æŸåæ›´æ–°è¾“å‡ºç›®å½•ä¸º %s\n", tts_wav_output_dir.c_str());
                        // ç¡®ä¿ç›®å½•å­˜åœ¨
                        cross_platform_mkdir_p(tts_wav_output_dir);
                    }
                }
                // æ³¨æ„ï¼šis_chunk_end æ—¶ä¸é‡ç½® bufferï¼Œå‰©ä½™ tokens ä¿ç•™ç»™ä¸‹ä¸€ä¸ª chunk
                break;
            }
        }
    }

    print_with_timestamp("T2W(C++) çº¿ç¨‹: åœæ­¢\n");
    fflush(stdout);
}

// Token2Wav çº¿ç¨‹å…¥å£å‡½æ•°ï¼ˆæ ¹æ®é…ç½®é€‰æ‹© Python æˆ– C++ å®ç°ï¼‰
void t2w_thread_func(struct omni_context * ctx_omni, common_params * params) {
    if (ctx_omni->use_python_token2wav) {
        t2w_thread_func_python(ctx_omni, params);
    } else {
        t2w_thread_func_cpp(ctx_omni, params);
    }
}

bool stream_prefill(struct omni_context * ctx_omni,
                    std::string           aud_fname,
                    std::string           img_fname,
                    int                   index,
                    int                   max_slice_nums) {
    // åªæœ‰åœ¨æ–°ä¸€è½®å¼€å§‹æ—¶ (index == 0) æ‰éœ€è¦ç­‰å¾…ä¸Šä¸€è½® TTS å®Œæˆ
    // åŒä¸€è½®å†…çš„åç»­ prefill (index >= 1) ä¸éœ€è¦ç­‰å¾…
    if (ctx_omni->use_tts && index == 0 && ctx_omni->warmup_done.load() && !ctx_omni->duplex_mode) {
        // ğŸ”§ å¦‚æœ break_event å·²è§¦å‘ï¼Œè·³è¿‡ç­‰å¾…ï¼ˆä¸Šä¸€è½®å·²è¢«æ‰“æ–­ï¼‰
        if (ctx_omni->break_event.load()) {
            print_with_timestamp("TTS: break_event active, skipping wait for previous round\n");
            ctx_omni->speek_done = true;
            ctx_omni->break_event.store(false);
            speek_cv.notify_all();
        }
        print_with_timestamp("TTS: ç­‰å¾…ä¸Šä¸€è½®è¯­éŸ³ç”Ÿæˆå®Œæˆ\n");
        std::unique_lock<std::mutex> lock(speek_mtx);
        // æ·»åŠ è¶…æ—¶ç­‰å¾…ï¼Œé¿å…æ°¸ä¹…å¡ä½
        auto                         wait_result = speek_cv.wait_for(lock, std::chrono::seconds(5),
                                                                     [&] { return ctx_omni->speek_done || ctx_omni->break_event.load(); });
        if (!wait_result) {
            // å¼ºåˆ¶è®¾ç½®ä¸º true ä»¥ç»§ç»­
            ctx_omni->speek_done = true;
        }
        // ç­‰å¾…å®Œæˆåé‡ç½® speek_doneï¼Œä¸ºä¸‹ä¸€è½®åšå‡†å¤‡
        ctx_omni->speek_done = false;

        // ğŸ”§ [å¤šè½®å¯¹è¯ä¿®å¤] æ¸…ç† TTS é˜Ÿåˆ—ä¸­çš„æ®‹ç•™æ•°æ®ï¼Œé¿å…æ··æ·†
        if (ctx_omni->tts_thread_info && !ctx_omni->duplex_mode) {
            std::lock_guard<std::mutex> tts_lock(ctx_omni->tts_thread_info->mtx);
            auto &                      tts_queue = ctx_omni->tts_thread_info->queue;
            while (!tts_queue.empty()) {
                LLMOut * old_out = tts_queue.front();
                tts_queue.pop();
                delete old_out;
            }
            print_with_timestamp("stream_prefill: cleared TTS queue for new turn\n");
        }
    } else if (ctx_omni->use_tts && index == 0 && !ctx_omni->duplex_mode) {
        // å¦åˆ™ LLM è¾“å‡ºä¼šè¢«ä¸¢å¼ƒï¼ˆå› ä¸º speek_done åˆå§‹å€¼ä¸º trueï¼‰
        ctx_omni->speek_done = false;

        // ğŸ”§ [å¤šè½®å¯¹è¯ä¿®å¤] é¦–æ¬¡åˆå§‹åŒ–æ—¶ä¹Ÿè¦æ¸…ç†é˜Ÿåˆ—
        if (ctx_omni->tts_thread_info) {
            std::lock_guard<std::mutex> tts_lock(ctx_omni->tts_thread_info->mtx);
            auto &                      tts_queue = ctx_omni->tts_thread_info->queue;
            while (!tts_queue.empty()) {
                LLMOut * old_out = tts_queue.front();
                tts_queue.pop();
                delete old_out;
            }
        }
    } else if (ctx_omni->use_tts) {
    }

    // ctx_omni->need_speek = false;
    const int hidden_size = llama_n_embd(llama_get_model(ctx_omni->ctx_llama));

    std::string voice_clone_prompt = "";
    std::string assistant_prompt   = "";

    if (ctx_omni->media_type == 1) {  // audio
        // å¦‚æœ audio_voice_clone_prompt ä»¥ "<|" å¼€å¤´ï¼ˆç‰¹æ®Š tokenï¼‰ï¼Œä¸æ·»åŠ å‰ç¼€
        // è¿™å…è®¸å®Œå…¨æ§åˆ¶ prompt æ ¼å¼ï¼ˆä¾‹å¦‚ä½¿ç”¨ system è€Œä¸æ˜¯ userï¼‰
        if (ctx_omni->audio_voice_clone_prompt.substr(0, 2) == "<|") {
            voice_clone_prompt = ctx_omni->audio_voice_clone_prompt;
        } else {
            voice_clone_prompt = "<|im_start|>user\n" + ctx_omni->audio_voice_clone_prompt;
        }
        // å¦‚æœ audio_assistant_prompt ä»¥ "<|" å¼€å¤´ï¼ˆç‰¹æ®Š tokenï¼‰ï¼Œä¸æ·»åŠ å‰ç¼€
        if (ctx_omni->audio_assistant_prompt.substr(0, 2) == "<|") {
            assistant_prompt = ctx_omni->audio_assistant_prompt;
        } else {
            assistant_prompt = "<|im_start|>user\n" + ctx_omni->audio_assistant_prompt;
        }
    } else if (ctx_omni->media_type == 2) {  // omni
        if (ctx_omni->omni_voice_clone_prompt.substr(0, 2) == "<|") {
            voice_clone_prompt = ctx_omni->omni_voice_clone_prompt;
        } else {
            voice_clone_prompt = "<|im_start|>user\n" + ctx_omni->omni_voice_clone_prompt;
        }
        if (ctx_omni->omni_assistant_prompt.substr(0, 2) == "<|") {
            assistant_prompt = ctx_omni->omni_assistant_prompt;
        } else {
            assistant_prompt = "<|im_start|>user\n" + ctx_omni->omni_assistant_prompt;
        }
    }
    // è¿™æ˜¯å› ä¸º omni_init ä¸­å¯èƒ½ä¼šè°ƒç”¨ stream_prefill(voice_audio, "", 0)ï¼Œ
    // ç„¶åæµ‹è¯•è„šæœ¬åˆä¼šè°ƒç”¨ stream_prefill(audio_0, "", 0)
    // å¦‚æœä¸æ£€æŸ¥è¿™ä¸ªæ ‡å¿—ï¼Œç³»ç»Ÿ prompt ä¼šè¢«è¯„ä¼°ä¸¤æ¬¡ï¼Œå¯¼è‡´æ ¼å¼æ··ä¹±
    if (index == 0 && !ctx_omni->system_prompt_initialized) {
        print_with_timestamp("stream_prefill: n_past = %d\n voice_clone_prompt = %s\n assistant_prompt = %s\n",
                             ctx_omni->n_past, voice_clone_prompt.c_str(), assistant_prompt.c_str());
        // tc-todo
        // llama_kv_cache_clear(ctx_omni->ctx_llama);

        // ğŸ”§ [å¯¹é½ Python åŒå·¥æ¨¡å‹] åˆå§‹åŒ–æ ¼å¼
        // Python åŒå·¥æ¨¡å‹çš„ _init_duplex_sessionï¼š
        //   1. feed prefix_system_promptï¼ˆåŒ…å« <|audio_start|>ï¼‰
        //   2. feed ref_audio çš„ APM embedding
        //   3. feed suffix_system_promptï¼ˆåŒ…å« <|audio_end|><|im_end|>ï¼‰
        //
        // å®Œæ•´æ ¼å¼ï¼š
        //   <|im_start|>system\nStreaming Duplex Conversation! You are a helpful assistant.\n<|audio_start|>
        //   [ref_audio APM embedding]
        //   <|audio_end|><|im_end|>

        if (ctx_omni->duplex_mode && aud_fname.length() > 0) {
            // åŒå·¥æ¨¡å¼ï¼šå‚è€ƒéŸ³é¢‘éœ€è¦é€å…¥ LLM

            // Step 1: è¯„ä¼° prefix (voice_clone_promptï¼ŒåŒ…å« <|audio_start|>)
            eval_string(ctx_omni, ctx_omni->params, voice_clone_prompt.c_str(), ctx_omni->params->n_batch,
                        &ctx_omni->n_past, false);

            // Step 2: è·å–å¹¶ prefill å‚è€ƒéŸ³é¢‘çš„ APM embedding
            auto * audio_embeds = omni_audio_embed_make_with_filename(ctx_omni->ctx_audio,
                                                                      ctx_omni->params->cpuparams.n_threads, aud_fname);
            if (audio_embeds != nullptr && audio_embeds->n_pos > 0) {
                prefill_with_emb(ctx_omni, ctx_omni->params, audio_embeds->embed, audio_embeds->n_pos,
                                 ctx_omni->params->n_batch, &ctx_omni->n_past);
                omni_embed_free(audio_embeds);
            } else {
            }

            // Step 3: è¯„ä¼° suffix (assistant_promptï¼ŒåŒ…å« <|audio_end|><|im_end|>)
            eval_string(ctx_omni, ctx_omni->params, assistant_prompt.c_str(), ctx_omni->params->n_batch,
                        &ctx_omni->n_past, false);
        } else {
            // ğŸ”§ [ä¸ Python å¯¹é½] éåŒå·¥æ¨¡å¼ä¹Ÿéœ€è¦åœ¨ system prompt ä¸­æ’å…¥ ref_audio embedding
            // Python: sys_msgs = {"role": "system", "content": [vc_prompt_prefix, ref_audio, vc_prompt_suffix]}
            // æ ¼å¼: <|im_start|>system\n{vc_prompt_prefix}\n<|audio_start|>[ref_audio_embed]<|audio_end|>{vc_prompt_suffix}<|im_end|>\n

            // ç¡®å®š ref_audio è·¯å¾„ï¼šä¼˜å…ˆä½¿ç”¨é…ç½®çš„è·¯å¾„ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            std::string system_ref_audio = ctx_omni->ref_audio_path.empty() ?
                                               "tools/omni/assets/default_ref_audio/default_ref_audio.wav" :
                                               ctx_omni->ref_audio_path;
            print_with_timestamp("system prompt ref_audio: %s\n", system_ref_audio.c_str());

            // Step 1: è¯„ä¼° prefix (voice_clone_promptï¼ŒåŒ…å« <|audio_start|>)
            eval_string(ctx_omni, ctx_omni->params, voice_clone_prompt.c_str(), ctx_omni->params->n_batch,
                        &ctx_omni->n_past, false);

            // Step 2: è·å–å¹¶ prefill å‚è€ƒéŸ³é¢‘çš„ APM embedding
            auto * ref_audio_embeds = omni_audio_embed_make_with_filename(
                ctx_omni->ctx_audio, ctx_omni->params->cpuparams.n_threads, system_ref_audio);
            if (ref_audio_embeds != nullptr && ref_audio_embeds->n_pos > 0) {
                print_with_timestamp("system prompt ref_audio embedding: n_pos=%d\n", ref_audio_embeds->n_pos);
                prefill_with_emb(ctx_omni, ctx_omni->params, ref_audio_embeds->embed, ref_audio_embeds->n_pos,
                                 ctx_omni->params->n_batch, &ctx_omni->n_past);
                omni_embed_free(ref_audio_embeds);
            } else {
                print_with_timestamp("WARNING: failed to load system prompt ref_audio: %s\n", system_ref_audio.c_str());
            }

            // Step 3: è¯„ä¼° suffix (assistant_promptï¼ŒåŒ…å« <|audio_end|><|im_end|>)
            eval_string(ctx_omni, ctx_omni->params, assistant_prompt.c_str(), ctx_omni->params->n_batch,
                        &ctx_omni->n_past, false);
        }

        // æ ‡è®°ç³»ç»Ÿ prompt å·²åˆå§‹åŒ–
        ctx_omni->system_prompt_initialized = true;

        //æŠŠè¿™æ­¥å®Œæˆå†å¼€llmçº¿ç¨‹ä»¥é˜²å†²çª
        ctx_omni->n_keep = ctx_omni->n_past;
        print_with_timestamp("ğŸ”’ n_keep è®¾ç½®ä¸º %d (system prompt tokens)ï¼Œè¿™éƒ¨åˆ†æ°¸è¿œä¸ä¼šè¢«æ»‘åŠ¨çª—å£åˆ é™¤\n",
                             ctx_omni->n_keep);
        eval_prefix(ctx_omni, ctx_omni->params);

        // ğŸ”§ [è¯´æ˜] index=0 æ—¶ï¼Œaud_fname é€šå¸¸æ˜¯ ref_audioï¼ˆç”¨äº voice cloningï¼‰
        // ref_audio å·²ç»åœ¨ä¸Šé¢çš„ system prompt åˆå§‹åŒ–ä¸­è¢«æ­£ç¡® prefill äº†
        // è¿™é‡Œä¸éœ€è¦å†å¤„ç† aud_fnameï¼Œå› ä¸ºï¼š
        // 1. å¦‚æœ aud_fname æ˜¯ ref_audioï¼Œå®ƒå·²ç»ä½œä¸º system prompt çš„ä¸€éƒ¨åˆ†è¢«å¤„ç†äº†
        // 2. å¦‚æœ aud_fname æ˜¯ç”¨æˆ·éŸ³é¢‘ï¼Œç”¨æˆ·éŸ³é¢‘åº”è¯¥ä» index >= 1 å¼€å§‹ä¼ å…¥
        // æ‰€ä»¥ index=0 é˜¶æ®µåªè´Ÿè´£ system prompt åˆå§‹åŒ–ï¼Œä¸å¤„ç†é¢å¤–çš„éŸ³é¢‘è¾“å…¥
        print_with_timestamp("stream_prefill(index=0): system prompt åˆå§‹åŒ–å®Œæˆï¼Œref_audio å·²åœ¨å…¶ä¸­ prefill\n");

        // ğŸ”§ [#39 æ»‘åŠ¨çª—å£] æ³¨å†Œ system prompt ä¿æŠ¤é•¿åº¦
        sliding_window_register_system_prompt(ctx_omni);

        print_with_timestamp("n_past = %d\n", ctx_omni->n_past);

        if (ctx_omni->async) {
            //create llm thread
            print_with_timestamp("create llm & tts thread\n");
            if (!ctx_omni->llm_thread.joinable()) {
                llm_thread_running   = true;
                ctx_omni->llm_thread = std::thread(llm_thread_func, ctx_omni, ctx_omni->params);
                print_with_timestamp("create llm thread success\n");
            }
            if (ctx_omni->use_tts && !ctx_omni->tts_thread.joinable()) {
                tts_thread_running = true;
                // ğŸ”§ [åŒå·¥æ¨¡å¼] æ ¹æ® duplex_mode é€‰æ‹©ä¸åŒçš„ TTS çº¿ç¨‹å‡½æ•°
                if (ctx_omni->duplex_mode) {
                    ctx_omni->tts_thread = std::thread(tts_thread_func_duplex, ctx_omni, ctx_omni->params);
                    print_with_timestamp("create tts thread (duplex mode) success\n");
                } else {
                    ctx_omni->tts_thread = std::thread(tts_thread_func, ctx_omni, ctx_omni->params);
                    print_with_timestamp("create tts thread (simplex mode) success\n");
                }
            }

            // Start T2W thread if TTS is enabled and thread is not already running
            if (ctx_omni->use_tts && ctx_omni->t2w_thread_info && !ctx_omni->t2w_thread.joinable()) {
                t2w_thread_running   = true;
                ctx_omni->t2w_thread = std::thread(t2w_thread_func, ctx_omni, ctx_omni->params);
                print_with_timestamp("create t2w thread success\n");
            }
        }

    } else {
        if (!ctx_omni->async) {
            if (img_fname.length() > 0) {
                // ğŸ”§ [é«˜æ¸…æ¨¡å¼] ä½¿ç”¨ V2.6 slice schema
                // å¦‚æœæŒ‡å®šäº† max_slice_numsï¼Œä¸´æ—¶è®¾ç½®ï¼ˆç”¨äºé«˜æ¸…+é«˜åˆ·ç»„åˆæ¨¡å¼ï¼‰
                if (max_slice_nums >= 1 && ctx_omni->ctx_vision) {
                    vision_set_max_slice_nums(ctx_omni->ctx_vision, max_slice_nums);
                    LOG_INF("%s: [ä¸´æ—¶] max_slice_nums=%d for this prefill\n", __func__, max_slice_nums);
                }
                std::vector<std::vector<float>> vision_chunks;
                if (!omni_image_embed_make_chunks_with_filename(
                        ctx_omni->ctx_vision, ctx_omni->params->cpuparams.n_threads, img_fname, vision_chunks)) {
                    LOG_ERR("%s: failed to create vision embeddings for %s\n", __func__, img_fname.c_str());
                    return false;
                }

                int  n_chunks         = (int) vision_chunks.size();
                int  tokens_per_chunk = (int) vision_chunks[0].size() / hidden_size;
                bool has_slices       = (n_chunks > 1);

                std::string prefix = "<unit>";
                eval_string(ctx_omni, ctx_omni->params, prefix.c_str(), ctx_omni->params->n_batch, &ctx_omni->n_past,
                            false);

                // Overview
                eval_string(ctx_omni, ctx_omni->params, "<image>", ctx_omni->params->n_batch, &ctx_omni->n_past, false);
                prefill_with_emb(ctx_omni, ctx_omni->params, vision_chunks[0].data(), tokens_per_chunk,
                                 ctx_omni->params->n_batch, &ctx_omni->n_past);
                eval_string(ctx_omni, ctx_omni->params, "</image>", ctx_omni->params->n_batch, &ctx_omni->n_past,
                            false);

                // Slices (V2.6 schema)
                if (has_slices) {
                    for (int i = 1; i < n_chunks; i++) {
                        eval_string(ctx_omni, ctx_omni->params, "<slice>", ctx_omni->params->n_batch, &ctx_omni->n_past,
                                    false);
                        prefill_with_emb(ctx_omni, ctx_omni->params, vision_chunks[i].data(), tokens_per_chunk,
                                         ctx_omni->params->n_batch, &ctx_omni->n_past);
                        eval_string(ctx_omni, ctx_omni->params, "</slice>", ctx_omni->params->n_batch,
                                    &ctx_omni->n_past, false);
                    }
                    eval_string(ctx_omni, ctx_omni->params, "\n", ctx_omni->params->n_batch, &ctx_omni->n_past, false);
                }
                LOG_INF("%s: prefilled %d vision chunks (%d tokens each)\n", __func__, n_chunks, tokens_per_chunk);
            }
            if (aud_fname.length() > 0) {
                print_with_timestamp("stream_prefill(index=%d): processing user audio: %s\n", index, aud_fname.c_str());
                auto * embeds = omni_audio_embed_make_with_filename(ctx_omni->ctx_audio,
                                                                    ctx_omni->params->cpuparams.n_threads, aud_fname);
                // ğŸ”§ [ä¿®å¤] éŸ³é¢‘å¤ªçŸ­æ—¶ä¼šåœ¨ audition_audio_preprocess ä¸­è‡ªåŠ¨ pad é™éŸ³åˆ° 100ms
                // è¿™é‡Œåšå®‰å…¨æ£€æŸ¥ï¼Œå¦‚æœä»ç„¶å¤±è´¥åˆ™è·³è¿‡è¯¥å¸§éŸ³é¢‘
                if (embeds != nullptr && embeds->n_pos > 0) {
                    print_with_timestamp("stream_prefill(index=%d): user audio embedding: n_pos=%d\n", index,
                                         embeds->n_pos);
                    // ğŸ”§ æ·»åŠ éŸ³é¢‘æ ‡è®°ï¼Œä¸ index=0 ä¿æŒä¸€è‡´
                    eval_string(ctx_omni, ctx_omni->params, "<|audio_start|>", ctx_omni->params->n_batch,
                                &ctx_omni->n_past, false);
                    prefill_with_emb(ctx_omni, ctx_omni->params, embeds->embed, embeds->n_pos,
                                     ctx_omni->params->n_batch, &ctx_omni->n_past);
                    eval_string(ctx_omni, ctx_omni->params, "<|audio_end|>", ctx_omni->params->n_batch,
                                &ctx_omni->n_past, false);
                    omni_embed_free(embeds);
                } else {
                    LOG_WRN("%s: audio encoding failed, skipping audio for this frame\n", __func__);
                }
            }
        } else {
            // async æ¨¡å¼ï¼šå°† embeds åŠ å…¥é˜Ÿåˆ—ï¼Œç”± LLM çº¿ç¨‹å¤„ç†

            const int     hidden_size = llama_n_embd(llama_get_model(ctx_omni->ctx_llama));
            omni_embeds * omni_embeds = new struct omni_embeds();
            //video
            if (img_fname.length() > 0) {
                LOG_INF("%s: img_fname:%s\n", __func__, img_fname.c_str());
                // ğŸ”§ [é«˜æ¸…æ¨¡å¼] å¦‚æœæŒ‡å®šäº† max_slice_numsï¼Œä¸´æ—¶è®¾ç½®ï¼ˆç”¨äºé«˜æ¸…+é«˜åˆ·ç»„åˆæ¨¡å¼ï¼‰
                if (max_slice_nums >= 1 && ctx_omni->ctx_vision) {
                    vision_set_max_slice_nums(ctx_omni->ctx_vision, max_slice_nums);
                    LOG_INF("%s: [ä¸´æ—¶] max_slice_nums=%d for this prefill\n", __func__, max_slice_nums);
                }
                // ğŸ”§ [é«˜æ¸…æ¨¡å¼] ä½¿ç”¨æ–°çš„ chunks æ¥å£ï¼Œæ”¯æŒ V2.6 slice schema
                if (!omni_image_embed_make_chunks_with_filename(ctx_omni->ctx_vision,
                                                                ctx_omni->params->cpuparams.n_threads, img_fname,
                                                                omni_embeds->vision_embed)) {
                    LOG_ERR("%s: failed to create vision embeddings for %s\n", __func__, img_fname.c_str());
                    delete omni_embeds;
                    return false;
                }
                LOG_INF("%s: vision_embed has %d chunks\n", __func__, (int) omni_embeds->vision_embed.size());
            }
            //audio
            // åªæœ‰åœ¨éŸ³é¢‘è·¯å¾„éç©ºæ—¶æ‰å¤„ç†éŸ³é¢‘
            if (aud_fname.length() > 0) {
                LOG_INF("%s: aud_fname:%s\n", __func__, aud_fname.c_str());
                auto * audio_embeds = omni_audio_embed_make_with_filename(
                    ctx_omni->ctx_audio, ctx_omni->params->cpuparams.n_threads, aud_fname);
                // ğŸ”§ [ä¿®å¤] éŸ³é¢‘å¤ªçŸ­æ—¶ä¼šåœ¨ audition_audio_preprocess ä¸­è‡ªåŠ¨ pad é™éŸ³åˆ° 100ms
                // è¿™é‡Œåšå®‰å…¨æ£€æŸ¥ï¼Œå¦‚æœä»ç„¶å¤±è´¥åˆ™è·³è¿‡è¯¥å¸§éŸ³é¢‘ï¼ˆä¿æŒ audio_embed ä¸ºç©ºï¼‰
                if (audio_embeds != nullptr && audio_embeds->n_pos > 0) {
                    //save to buffer
                    LOG_INF("%s: audio_embeds->n_pos: %d ,hidden_size: %d\n", __func__, audio_embeds->n_pos,
                            hidden_size);
                    omni_embeds->audio_embed.resize(audio_embeds->n_pos * hidden_size);
                    std::memcpy(omni_embeds->audio_embed.data(), audio_embeds->embed,
                                omni_embeds->audio_embed.size() * sizeof(float));
                    omni_embed_free(audio_embeds);
                } else {
                    LOG_WRN("%s: audio encoding failed, skipping audio for this frame: %s\n", __func__,
                            aud_fname.c_str());
                }
            }
            omni_embeds->index = index;
            // ğŸ”§ [æ•´åˆ] <|im_start|>user\n å·²åœ¨ sys prompt æœ«å°¾æ·»åŠ ï¼Œåç»­è½®æ¬¡åœ¨ stream_decode ç»“æŸæ—¶æ·»åŠ 
            // ä¸å†éœ€è¦åœ¨è¿™é‡Œè®¾ç½® is_round_start æ ‡è®°

            std::unique_lock<std::mutex> lock(ctx_omni->llm_thread_info->mtx);
            ctx_omni->llm_thread_info->cv.wait(lock, [&] {
                return ctx_omni->llm_thread_info->queue.size() < ctx_omni->llm_thread_info->MAX_QUEUE_SIZE;
            });
            ctx_omni->llm_thread_info->queue.push(omni_embeds);

            //notify the llm
            lock.unlock();
            ctx_omni->llm_thread_info->cv.notify_all();
        }
    }
    // ğŸ”§ [è¯Šæ–­] æ‰“å° stream_prefill ç»“æŸæ—¶çš„çŠ¶æ€
    print_with_timestamp("\n\nc++ finish stream_prefill(index=%d). n_past=%d, n_keep=%d, n_ctx=%d\n\n", index,
                         ctx_omni->n_past, ctx_omni->n_keep, ctx_omni->params->n_ctx);
    return true;
}

bool stream_decode(struct omni_context * ctx_omni, std::string debug_dir, int round_idx) {
    // NOTE: ä¸å†è‡ªåŠ¨å½’æ¡£æ—§è¾“å‡ºç›®å½•ï¼Œå› ä¸ºè¿™ä¼šå¯¼è‡´åŒä¸€ session ä¸­æ¯è½®å¯¹è¯çš„è¾“å‡ºè¢«ç§»èµ°
    // å¦‚æœéœ€è¦å½’æ¡£ï¼Œå¯ä»¥åœ¨æ–° session å¼€å§‹æ—¶ï¼ˆomni_initï¼‰æ‰‹åŠ¨è°ƒç”¨
    // move_old_output_to_archive();

    // ğŸ”§ [è½®æ¬¡åŒæ­¥] å¦‚æœè°ƒç”¨æ–¹æŒ‡å®šäº† round_idxï¼Œç«‹å³åŒæ­¥ simplex_round_idx
    // è¿™è§£å†³äº† TTS çº¿ç¨‹å¼‚æ­¥é€’å¢ round_idx å¯¼è‡´çš„ç«æ€æ¡ä»¶é—®é¢˜
    // åœºæ™¯ï¼šPython ç«¯åœ¨ streaming_generate ç»“æŸåç«‹å³é€’å¢ current_round_numberï¼Œ
    //       ä½† C++ çš„ TTS çº¿ç¨‹å¯èƒ½è¿˜æ²¡å¤„ç†å®Œä¸Šä¸€è½®ï¼Œå¯¼è‡´ simplex_round_idx æ»å
    //
    // æ³¨æ„ï¼šæ–° session æ—¶çš„ KV cache æ¸…ç†åœ¨ update_session_config ä¸­å¤„ç†
    // è¿™é‡Œåªå¤„ç†åŒä¸€ session å†…çš„è½®æ¬¡åŒæ­¥
    if (round_idx >= 0 && !ctx_omni->duplex_mode) {
        if (ctx_omni->simplex_round_idx != round_idx) {
            print_with_timestamp("ğŸ“ [è½®æ¬¡åŒæ­¥] è°ƒç”¨æ–¹æŒ‡å®š round_idx=%dï¼Œå½“å‰ simplex_round_idx=%dï¼Œå¼ºåˆ¶åŒæ­¥\n",
                                 round_idx, ctx_omni->simplex_round_idx);
            ctx_omni->simplex_round_idx = round_idx;
            // åŒæ—¶æ›´æ–° wav_turn_base ä»¥ä¿æŒä¸€è‡´æ€§
            ctx_omni->wav_turn_base     = round_idx * 1000;
        }
    }

    // ğŸ”§ [å·²ç¦ç”¨] ä¸å†æ¸…ç©º llm_debug/chunk_* ç›®å½•
    // åŸå› ï¼šè¿™ä¸ªæ¸…ç©ºæ“ä½œå’Œ TTS çº¿ç¨‹çš„å†™å…¥æ“ä½œå­˜åœ¨ç«æ€æ¡ä»¶
    // åœºæ™¯ï¼š
    //   1. ç¬¬ä¸€è½® stream_decode å®Œæˆï¼ŒLLM è¿”å›ï¼Œä½† TTS çº¿ç¨‹è¿˜åœ¨å¤„ç† chunk_0-9
    //   2. ç¬¬äºŒè½® stream_decode å¼€å§‹ï¼ˆTTS è¿˜æ²¡é€’å¢ simplex_round_idxï¼‰
    //   3. ç¬¬äºŒè½® stream_decode æ¸…ç©ºäº† round_XXX/llm_debug/chunk_*
    //   4. å¯¼è‡´ TTS å·²ç»å†™å…¥çš„ chunk_0-9 è¢«åˆ é™¤ï¼Œåªå‰©ä¸‹åç»­çš„ chunk_10 ç­‰
    // ç°åœ¨æ¯ä¸ª round æœ‰ç‹¬ç«‹çš„ç›®å½•ï¼ˆround_000, round_001...ï¼‰ï¼Œä¸éœ€è¦æ¸…ç©ºæ—§æ•°æ®

    // Record start time (t=0) for WAV file naming
    ctx_omni->stream_decode_start_time = std::chrono::high_resolution_clock::now();

    // ğŸ”§ [è¯Šæ–­] æ‰“å° stream_decode å¼€å§‹æ—¶çš„å…³é”®çŠ¶æ€
    print_with_timestamp("ğŸ“ stream_decode å¼€å§‹: n_past=%d, n_keep=%d, n_ctx=%d, duplex_mode=%d\n", ctx_omni->n_past,
                         ctx_omni->n_keep, ctx_omni->params->n_ctx, ctx_omni->duplex_mode);

    // ğŸ”§ [åŒå·¥æ¨¡å¼] é‡ç½® ended_with_listen æ ‡å¿—
    // æ¯æ¬¡ decode å¼€å§‹æ—¶ï¼Œå‡è®¾ä¼šä»¥é listen ç»“æŸï¼ˆéœ€è¦æ¸…ç† KV cacheï¼‰
    // å¦‚æœ LLM çº¿ç¨‹æ£€æµ‹åˆ° <|listen|>ï¼Œä¼šè®¾ç½®ä¸º true

    // ğŸ”§ [ä¸ Python å¯¹é½] é‡ç½® llm_generation_done æ ‡å¿—
    // æ¯æ¬¡æ–°çš„ decode å¼€å§‹æ—¶é‡ç½®ï¼ŒTTS çº¿ç¨‹ä¼šæ£€æŸ¥æ­¤æ ‡å¿—æ¥å†³å®šæ˜¯å¦æ·»åŠ  text_eos_embed
    if (!ctx_omni->duplex_mode) {
        ctx_omni->llm_generation_done.store(false);
    }
    ctx_omni->ended_with_listen = false;

    // ğŸ”§ [å…³é”®ä¿®å¤] åœ¨ decode å¼€å§‹æ—¶é‡ç½® break_event
    // é—®é¢˜ï¼šbreak_event åªåœ¨ T2W çº¿ç¨‹ä¸­è¢«é‡ç½®ï¼Œä½† T2W å¯èƒ½è¿˜åœ¨ç­‰å¾…æ•°æ®
    //       å¯¼è‡´æ–°çš„ decode æ£€æµ‹åˆ° break_event=true åç«‹å³é€€å‡ºï¼Œä¸ç”Ÿæˆä»»ä½• token
    // è§£å†³ï¼šåœ¨ decode å¼€å§‹æ—¶ç«‹å³é‡ç½® break_eventï¼Œç¡®ä¿æ–°ä¸€è½®ç”Ÿæˆå¯ä»¥æ­£å¸¸è¿›è¡Œ
    if (ctx_omni->duplex_mode && ctx_omni->break_event.load()) {
        ctx_omni->break_event.store(false);
        print_with_timestamp("ğŸ“ stream_decode: reset break_event from true to false\n");
    }

    //eval_string(ctx_omni->ctx_llama, std::string("hello").c_str(), params->n_batch, &ctx_omni->n_past, false);

    // ğŸ”§ [ä¿®å¤å¤šè½®å¯¹è¯] æ¸…ç©ºä¸Šä¸€è½®çš„æ–‡æœ¬é˜Ÿåˆ—ï¼Œé‡ç½®çŠ¶æ€æ ‡å¿—
    if (ctx_omni->duplex_mode) {
        std::lock_guard<std::mutex> lock(ctx_omni->text_mtx);
        ctx_omni->text_queue.clear();
        ctx_omni->text_done_flag = false;
        ctx_omni->text_streaming = true;
    }

    if (ctx_omni->async && ctx_omni->duplex_mode) {
        ctx_omni->need_speek = true;
        //ctx_omni->llm_thread.join();
        ctx_omni->llm_thread_info->cv.notify_all();
        print_with_timestamp("wait prefill done\n");
    }

    //eval_string(ctx_omni->ctx_llama, std::string("hello").c_str(), params->n_batch, &ctx_omni->n_past, false);

    // ğŸ”§ [ä¿®å¤å¤šè½®å¯¹è¯] æ¸…ç©ºä¸Šä¸€è½®çš„æ–‡æœ¬é˜Ÿåˆ—ï¼Œé‡ç½®çŠ¶æ€æ ‡å¿—
    {
        std::lock_guard<std::mutex> lock(ctx_omni->text_mtx);
        ctx_omni->text_queue.clear();
        ctx_omni->text_done_flag = false;
        ctx_omni->text_streaming = true;
    }

    if (ctx_omni->async) {
        // ğŸ”§ ç¡®ä¿çº¿ç¨‹å·²å¯åŠ¨ï¼ˆå¦‚æœ prefill æ˜¯åŒæ­¥æ¨¡å¼æ‰§è¡Œçš„ï¼Œçº¿ç¨‹å¯èƒ½è¿˜æ²¡å¯åŠ¨ï¼‰
        if (!ctx_omni->tts_thread.joinable() && ctx_omni->use_tts) {
            tts_thread_running = true;
            if (ctx_omni->duplex_mode) {
                ctx_omni->tts_thread = std::thread(tts_thread_func_duplex, ctx_omni, ctx_omni->params);
                print_with_timestamp("stream_decode: create tts thread (duplex mode)\n");
            } else {
                ctx_omni->tts_thread = std::thread(tts_thread_func, ctx_omni, ctx_omni->params);
                print_with_timestamp("stream_decode: create tts thread (simplex mode)\n");
            }
        }
        if (!ctx_omni->t2w_thread.joinable() && ctx_omni->use_tts && ctx_omni->t2w_thread_info) {
            t2w_thread_running   = true;
            ctx_omni->t2w_thread = std::thread(t2w_thread_func, ctx_omni, ctx_omni->params);
            print_with_timestamp("stream_decode: create t2w thread\n");
        }

        ctx_omni->need_speek = true;
        //ctx_omni->llm_thread.join();
        ctx_omni->llm_thread_info->cv.notify_all();
        print_with_timestamp("wait prefill done\n");
        std::unique_lock<std::mutex> lock(ctx_omni->llm_thread_info->mtx);
        g_decode_cv.wait(lock, [] { return prefill_done; });
        prefill_done = false;
    }
    // åªæœ‰å¯ç”¨ TTS æ—¶æ‰è®¾ç½® speek_done ä¸º false
    if (ctx_omni->use_tts) {
        ctx_omni->speek_done = false;
    }

    // ğŸ”§ [å¯¹é½ Python MiniCPM-o-4_5-latest] æ ¹æ®æ¨¡å¼è®¾ç½®ä¸åŒçš„ assistant generation prompt
    //
    // === éåŒå·¥æ¨¡å¼ (Simplex) ===
    // Python default_tts_chat_template:
    //   {% if add_generation_prompt %}{{ '<|im_start|>assistant\n' + think_str + '<|tts_bos|>' }}{% endif %}
    // å…¶ä¸­ think_str = "<think>\n\n</think>\n\n"
    //
    // æ³¨æ„ï¼šstream_prefill å·²ç»æ·»åŠ äº† <|audio_start|>[audio]<|audio_end|>
    //       è¿™é‡Œåªéœ€è¦æ·»åŠ å…³é—­ç”¨æˆ·æ¶ˆæ¯çš„ <|im_end|> å’Œ assistant generation prompt
    //
    // å®Œæ•´çš„ assistant generation prompt (éåŒå·¥ TTS):
    //   <|im_end|>\n             (å…³é—­ç”¨æˆ·æ¶ˆæ¯ï¼Œstream_prefill å·²æ·»åŠ  <|audio_end|>)
    //   <|im_start|>assistant\n  (å¼€å§‹ assistant turn)
    //   <think>\n\n</think>\n\n  (think æ ‡è®°ï¼Œæ³¨æ„æ¢è¡Œç¬¦)
    //   <|tts_bos|>              (TTS å¼€å§‹æ ‡è®°)
    //
    // === åŒå·¥æ¨¡å¼ (Duplex) ===
    // åŒå·¥æ¨¡å¼ä½¿ç”¨ <unit> æ ‡è®°ï¼Œä¸ä½¿ç”¨æ ‡å‡† chat template
    // stream_prefill æ·»åŠ  <unit>[audio_embed] (æ—  audio_start/end)
    // æ¨¡å‹è‡ªåŠ¨è¾“å‡º <|speak|> æˆ– <|listen|> æ¥æ§åˆ¶å¯¹è¯æµç¨‹

    if (ctx_omni->duplex_mode) {
        // ğŸ”§ [åŒå·¥æ¨¡å¼] ä¸éœ€è¦æ·»åŠ  assistant prompt
        // åŒå·¥æ¨¡å‹ä¼šæ ¹æ®ä¸Šä¸‹æ–‡è‡ªåŠ¨å†³å®šè¯´è¯è¿˜æ˜¯ç»§ç»­ç›‘å¬
        // stream_prefill å·²æ·»åŠ  <unit>[audio_embed]
        // æ¨¡å‹ä¼šè¾“å‡º <|speak|>xxx<|chunk_eos|> æˆ– <|listen|><|chunk_eos|>
        print_with_timestamp("stream_decode: åŒå·¥æ¨¡å¼ï¼Œè·³è¿‡ assistant prompt\n");
    } else if (ctx_omni->use_tts) {
        // ğŸ”§ [éåŒå·¥ TTS æ¨¡å¼] éœ€è¦åŒ…å« <|tts_bos|>ï¼Œå‘Šè¯‰æ¨¡å‹å¼€å§‹ç”Ÿæˆ TTS æ–‡æœ¬
        // stream_prefill å·²æ·»åŠ  <|audio_start|>[audio]<|audio_end|>ï¼Œè¿™é‡Œå…³é—­ç”¨æˆ·æ¶ˆæ¯å¹¶æ·»åŠ  assistant prompt
        // æ ¼å¼: <|im_end|>\n<|im_start|>assistant\n<think>\n\n</think>\n\n<|tts_bos|>
        std::string prompt = "<|im_end|>\n<|im_start|>assistant\n<think>\n\n</think>\n\n<|tts_bos|>";
        print_with_timestamp("ğŸ“ [å•å·¥TTS] æ·»åŠ  assistant prompt: \"%s\", n_past=%d\n", prompt.c_str(),
                             ctx_omni->n_past);
        {
            eval_string(ctx_omni, ctx_omni->params, prompt.c_str(), ctx_omni->params->n_batch, &ctx_omni->n_past,
                        false);
        }
        print_with_timestamp("ğŸ“ [å•å·¥TTS] assistant prompt å®Œæˆ, n_past=%d\n", ctx_omni->n_past);
    } else {
        // ğŸ”§ [éåŒå·¥çº¯ LLM æ¨¡å¼] åªä½¿ç”¨æ ‡å‡†çš„ assistant promptï¼ˆæ—  TTS æ ‡è®°ï¼Œæ—  think æ ‡è®°ï¼‰
        // æ ¼å¼: <|im_end|>\n<|im_start|>assistant\n
        std::string prompt = "<|im_end|>\n<|im_start|>assistant\n";
        {
            eval_string(ctx_omni, ctx_omni->params, prompt.c_str(), ctx_omni->params->n_batch, &ctx_omni->n_past,
                        false);
        }
    }
    LOG_INF("<user>%s\n", ctx_omni->params->prompt.c_str());
    LOG_INF("<assistant>");
    const int max_tgt_len = ctx_omni->params->n_predict < 0 ? ctx_omni->params->n_ctx : ctx_omni->params->n_predict;
    print_with_timestamp("LLM decode: max_tgt_len = %d, n_predict = %d, n_ctx = %d\n", max_tgt_len,
                         ctx_omni->params->n_predict, ctx_omni->params->n_ctx);
    // LLM chunk size: æ¯chunkæ¨é€ç»™TTSçš„LLM tokensæ•°é‡
    // åŸå§‹Python: generate_chunk_size=10
    // æ³¨æ„ï¼šstep_sizeå½±å“TTSæ¡ä»¶é•¿åº¦ï¼Œå¯èƒ½å½±å“éŸ³è´¨
    // step_size=5: é¦–å“æ›´å¿«(612ms)ä½†å¯èƒ½å½±å“éŸ³è´¨
    // step_size=10: é¦–å“ç¨æ…¢(791ms)ä½†éŸ³è´¨æ›´ç¨³å®š
    int         step_size = 10;  // æ¢å¤åŸå§‹å€¼
    std::string response  = "";

    // tts streaming memory
    std::string              tts_txt   = "";
    int                      chunk_idx = 0;
    std::vector<llama_token> audio_input_ids;
    // TODO write to specific buffers
    std::vector<float>       tts_output;
    tts_output.resize(1 /* batch_size */ * (ctx_omni->params->n_ctx /* seq_len */ * 2) * 256);
    bool llm_finish             = false;
    bool llm_first_token_logged = false;

    // ğŸ”§ [ä¿®å¤åŒå·¥ç¼ºå­—é—®é¢˜] è®°å½•å½“å‰ chunk æ˜¯å¦æ˜¯ turn çš„ç»“æŸ
    // æ­¤å˜é‡éš LLMOut ä¸€èµ·ä¼ é€’ç»™ TTS çº¿ç¨‹ï¼Œé¿å…å…¨å±€çŠ¶æ€çš„æ—¶åºé—®é¢˜
    bool local_is_end_of_turn           = false;
    // ğŸ”§ [P0-æ‰“æ–­æ£€æµ‹] åŒå·¥æ¨¡å¼ä¸‹è®°å½•å½“å‰ chunk ç”Ÿæˆçš„ token æ•°
    int  current_chunk_tokens           = 0;
    // ğŸ”§ [ä¿®å¤çŸ­å›å¤] é‡ç½®å½“å‰è¯´è¯è½®æ¬¡çš„ token è®¡æ•°
    ctx_omni->current_speak_token_count = 0;

    for (int il = 0; il < max_tgt_len;) {
        // ğŸ”§ [P0-æ‰“æ–­æ£€æµ‹] å¤–å±‚å¾ªç¯ä¹Ÿæ£€æµ‹ break_event
        if (ctx_omni->break_event.load()) {
            llm_finish = true;
            break;
        }
        fflush(stdout);
        response = "";
        fflush(stdout);

        // æ³¨æ„: speek_done=true ç°åœ¨åªè¡¨ç¤º"TTS å®Œæˆï¼Œå¯æ¥å—æ–° prefill"
        // ä¸å†ç”¨äºæ§åˆ¶ LLM é€€å‡ºã€‚LLM åº”è¯¥æ­£å¸¸å®Œæˆç›´åˆ° EOS æˆ–è¾¾åˆ°æœ€å¤§é•¿åº¦ã€‚
        // æ‰“æ–­é€»è¾‘é€šè¿‡ need_speek æˆ–å…¶ä»–æœºåˆ¶å¤„ç†ã€‚
        fflush(stdout);

        int                      jl                     = 0;  // è®¡æ•°æœ‰æ•ˆçš„ TTS token æ•°é‡
        int                      total_tokens_generated = 0;  // è®¡æ•°æ€»å…±ç”Ÿæˆçš„ token æ•°é‡ï¼ˆåŒ…æ‹¬è¢«è¿‡æ»¤çš„ï¼‰
        // æ”¶é›†å½“å‰chunkçš„token IDså’Œhidden statesç”¨äºTTSæ¡ä»¶ç”Ÿæˆ
        // ğŸ”§ [ä¼˜åŒ–] åªæ”¶é›†æœ‰æ•ˆçš„ TTS tokenï¼Œç¡®ä¿æ¯æ¬¡ç»™ TTS çš„éƒ½æ˜¯ step_size ä¸ªæœ‰æ•ˆ token
        std::vector<llama_token> chunk_token_ids;
        std::vector<float>       chunk_hidden_states;
        int                      llm_n_embd = llama_n_embd(llama_get_model(ctx_omni->ctx_llama));

        // ğŸ”§ [ä¿®å¤åŒå·¥ç¼ºå­—é—®é¢˜] æ¯ä¸ª chunk å¼€å§‹æ—¶é‡ç½® is_end_of_turn çŠ¶æ€
        // åªæœ‰å½“æ£€æµ‹åˆ° TURN_EOS/TTS_EOS/EOS æ—¶æ‰ä¼šåœ¨ä¸‹é¢è®¾ç½®ä¸º true
        local_is_end_of_turn = false;

        // ğŸ”§ [å•åŒå·¥é€‚é…] chunk é™åˆ¶åªåœ¨åŒå·¥æ¨¡å¼ä¸‹ç”Ÿæ•ˆ
        // - åŒå·¥æ¨¡å¼: æ¯ä¸ª chunk æœ€å¤š max_new_speak_tokens_per_chunk ä¸ª tokensï¼Œä¾¿äºåŠæ—¶å“åº”æ‰“æ–­
        // - å•å·¥æ¨¡å¼: æ— é™åˆ¶ï¼ŒLLM ç”Ÿæˆç›´åˆ° EOS
        int  max_chunk_tokens    = ctx_omni->duplex_mode ? ctx_omni->max_new_speak_tokens_per_chunk : 0;
        bool chunk_limit_reached = (max_chunk_tokens > 0 && current_chunk_tokens >= max_chunk_tokens);
        {
            fflush(stdout);
            // ğŸ”§ [é‡è¦] å¾ªç¯ç›´åˆ°æ”¶é›†åˆ° step_size ä¸ªæœ‰æ•ˆ tokenï¼Œè€Œä¸æ˜¯ç”Ÿæˆ step_size ä¸ª token
            // ğŸ”§ [P0-æ‰“æ–­æ£€æµ‹] æ£€æµ‹ break_eventï¼Œæ”¯æŒåŒå·¥æ¨¡å¼ä¸‹çš„æ‰“æ–­
            // ğŸ”§ [P2-chunké™åˆ¶] æ£€æµ‹ max_new_speak_tokens_per_chunkï¼Œä¾¿äºåŠæ—¶å“åº”æ‰“æ–­
            while (jl < step_size && !llm_finish && !ctx_omni->break_event.load() && !chunk_limit_reached) {
                // streaming llm
                const char * tmp           = nullptr;
                float *      hidden_states = nullptr;

                llama_token sampled_token = 0;
                {
                    std::lock_guard<std::mutex> llama_lock(ctx_omni->llama_mtx);
                    // ä½¿ç”¨æ–°å‡½æ•°è·å–tokenæ–‡æœ¬ã€hidden stateå’Œtoken ID
                    tmp = llama_loop_with_hidden_and_token(ctx_omni, ctx_omni->params, ctx_omni->ctx_sampler,
                                                           ctx_omni->n_past, hidden_states, sampled_token);
                }

                total_tokens_generated++;

                // ğŸ”§ [è¿‡æ»¤é€»è¾‘] åªæ”¶é›†æœ‰æ•ˆçš„ TTS token
                // ç‰¹æ®Š tokenï¼ˆå¦‚ <think>, </think>, æ¢è¡Œç­‰ï¼‰ä¸è®¡å…¥ step_size
                if (tmp != nullptr && hidden_states != nullptr) {
                    if (is_valid_tts_token(sampled_token)) {
                        // æœ‰æ•ˆ tokenï¼šæ”¶é›†å¹¶è®¡å…¥è®¡æ•°
                        chunk_token_ids.push_back(sampled_token);
                        chunk_hidden_states.insert(chunk_hidden_states.end(), hidden_states,
                                                   hidden_states + llm_n_embd);
                        jl++;  // åªæœ‰æœ‰æ•ˆ token æ‰å¢åŠ è®¡æ•°

                        // ğŸ”§ [è°ƒè¯•] æ‰“å°æ”¶é›†çš„ token å’Œ hidden states æ‘˜è¦

                        // ğŸ”§ [P2-chunké™åˆ¶] æ›´æ–°å½“å‰ chunk çš„ token è®¡æ•°
                        current_chunk_tokens++;
                        // ğŸ”§ [ä¿®å¤çŸ­å›å¤] åŒæ­¥æ›´æ–°å…¨å±€è¯´è¯è®¡æ•°
                        ctx_omni->current_speak_token_count++;

                        // æ£€æŸ¥æ˜¯å¦è¾¾åˆ° chunk é™åˆ¶
                        if (max_chunk_tokens > 0 && current_chunk_tokens >= max_chunk_tokens) {
                            chunk_limit_reached = true;
                        }
                    } else {
                        // ğŸ”§ [è°ƒè¯•] æ‰“å°è¢«è¿‡æ»¤çš„ token
                    }
                }

                // if (hidden_states != nullptr) {
                //     int n_embd = llama_n_embd(llama_get_model(ctx_omni->ctx_llama));
                //     // æ‰“å°ç¬¬ä¸€ä¸ª embedding çš„å‰5ä¸ªæ•°å­—
                //     printf("First embedding (first 5): ");
                //     for (int i = 0; i < 5 && i < n_embd; i++) {
                //         printf("%.6f ", hidden_states[i]);
                //     }
                //     printf("\n");
                //     // æ‰“å°æœ€åä¸€ä¸ª embedding çš„å5ä¸ªæ•°å­— (è¿™é‡Œåªæœ‰1ä¸ªtokenï¼Œæ‰€ä»¥ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªæ˜¯åŒä¸€ä¸ª)
                //     printf("Last embedding (last 5): ");
                //     for (int i = n_embd - 5; i < n_embd; i++) {
                //         if (i >= 0) {
                //             printf("%.6f ", hidden_states[i]);
                //         }
                //     }
                //     printf("\n");
                //     free(hidden_states);
                // }
                if (!llm_first_token_logged) {
                    llm_first_token_logged = true;
                }
                if (tmp == nullptr) {
                    LOG_ERR("llama_loop returned nullptr!");
                    break;
                }

                // ğŸ”§ [è°ƒè¯•æ—¥å¿—] è®°å½•æ¯ä¸ªç”Ÿæˆçš„ token åˆ°æ–‡ä»¶

                // ğŸ”§ [ä½¿ç”¨ token ID æ£€æµ‹] ä½¿ç”¨ç¼“å­˜çš„ token ID è¿›è¡Œæ£€æµ‹ï¼Œæ¯”å­—ç¬¦ä¸²æ¯”è¾ƒæ›´é«˜æ•ˆ
                OmniTokenType token_type = get_token_type(ctx_omni, sampled_token);
                if (token_type != OmniTokenType::NORMAL) {
                }

                if (ctx_omni->duplex_mode) {
                    // ğŸ”§ [ä¸ Python å¯¹é½] turn_eos å¤„ç†ï¼š
                    // Python ä¸­ turn_eos ä¸è§¦å‘ LLM è·³å‡ºï¼Œå®ƒåªæ˜¯æ ‡è®° is_end_of_turnã€‚
                    // LLM ç»§ç»­ç”Ÿæˆç›´åˆ° chunk_eos/listen é€šè¿‡ is_end_token() æ­£å¸¸è·³å‡ºã€‚
                    // turn_eos æœ¬èº«ä½œä¸º special token è¢«è¿‡æ»¤æ‰ï¼ˆä¸åŠ å…¥æ–‡æœ¬ responseï¼‰ã€‚
                    // is_end_of_turn ä¼ é€’ç»™ TTS çº¿ç¨‹ï¼Œè®© TTS çŸ¥é“è¿™æ˜¯æœ€åä¸€ä¸ª chunkã€‚
                    if (token_type == OmniTokenType::TURN_EOS || token_type == OmniTokenType::TTS_EOS ||
                        token_type == OmniTokenType::EOS) {
                        local_is_end_of_turn         = true;
                        ctx_omni->current_turn_ended = true;
                        print_with_timestamp(
                            "LLM Duplex: turn_eos detected (type=%d), "
                            "set is_end_of_turn=true (not breaking, wait for chunk_eos)\n",
                            (int) token_type);
                        // ä¸ breakï¼Œä¸è®¾ llm_finishï¼Œç»§ç»­ç”Ÿæˆç›´åˆ° chunk_eos/listen
                    }
                }

                if (is_end_token(ctx_omni, sampled_token)) {
                    llm_finish = true;

                    // ğŸ”§ [ä¸ Python å¯¹é½] è®¾ç½® llm_generation_done æ ‡å¿—
                    // TTS çº¿ç¨‹ä¼šæ£€æŸ¥è¿™ä¸ªæ ‡å¿—æ¥å†³å®šæ˜¯å¦æ·»åŠ  text_eos_embed
                    if (!ctx_omni->duplex_mode) {
                        ctx_omni->llm_generation_done.store(true);
                    }
                    print_with_timestamp(
                        "LLM: detected end token (id=%d, type=%d), speak_count=%d, set llm_generation_done=true\n",
                        sampled_token, (int) token_type, ctx_omni->current_speak_token_count);

                    // ğŸ”§ [P1-åŒå·¥æ¨¡å¼] è®¾ç½® current_turn_ended çŠ¶æ€
                    // Python: end_of_turn = last_id in turn_terminator_token_ids (åªæœ‰ turn_eos)
                    // åªæœ‰ TURN_EOS å’Œ TTS_EOS æ‰æ ‡è®°è½®æ¬¡çœŸæ­£ç»“æŸ
                    // CHUNK_EOS/CHUNK_TTS_EOS åªæ˜¯ chunk ç»“æŸï¼Œè½®æ¬¡æœªç»“æŸ
                    // LISTEN åªæ˜¯æš‚æ—¶åˆ‡æ¢åˆ°å¬çŠ¶æ€ï¼Œç”¨æˆ·è¯´å®Œåæ¨¡å‹è¿˜è¦ç»§ç»­å›å¤
                    // è¿™æ · TTS KV cache æ‰èƒ½åœ¨å¤šè½® speak-listen-speak ä¸­ä¿æŒè¿ç»­
                    if (token_type == OmniTokenType::TURN_EOS || token_type == OmniTokenType::TTS_EOS ||
                        token_type == OmniTokenType::EOS) {
                        ctx_omni->current_turn_ended = true;
                    } else if (token_type == OmniTokenType::LISTEN) {
                        // LISTEN: ä¸è®¾ç½® current_turn_endedï¼Œä¿æŒ TTS çŠ¶æ€è¿ç»­
                    }

                    // ğŸ”§ [P1-åŒå·¥æ¨¡å¼] <|listen|> token ç‰¹æ®Šå¤„ç†ï¼š
                    // - åœ¨åŒå·¥æ¨¡å¼ä¸‹ï¼Œ<|listen|> è¡¨ç¤ºæ¨¡å‹ä¸»åŠ¨åˆ‡æ¢åˆ°å¬çŠ¶æ€
                    // - éœ€è¦é€šè¿‡ text_queue é€šçŸ¥ SSE å®¢æˆ·ç«¯
                    // - è®¾ç½® ended_with_listen æ ‡å¿—ï¼Œè®© stream_decode æœ«å°¾ä¸æ¸…ç† KV cache
                    if (token_type == OmniTokenType::LISTEN && ctx_omni->duplex_mode) {
                        // ğŸ”§ [å…³é”®] æ ‡è®°ä»¥ listen ç»“æŸï¼Œä¸æ¸…ç† KV cache
                        ctx_omni->ended_with_listen = true;

                        // æ¨é€ä¸€ä¸ªç‰¹æ®Šçš„ JSON æ ‡è®°åˆ° text_queueï¼ŒSSE ä¼šè½¬å‘ç»™å®¢æˆ·ç«¯
                        if (ctx_omni->async) {
                            std::lock_guard<std::mutex> tl(ctx_omni->text_mtx);
                            // ä½¿ç”¨ç‰¹æ®Šå‰ç¼€æ ‡è®°è¿™æ˜¯çŠ¶æ€æ¶ˆæ¯è€Œéæ–‡æœ¬
                            ctx_omni->text_queue.push_back("__IS_LISTEN__");
                            ctx_omni->text_cv.notify_all();
                        }
                    }

                    // Don't add end tokens to response
                    break;
                }

                // Copy tmp to a local string immediately to avoid issues with static string
                std::string tmp_str(tmp);
                response += tmp_str;
                fflush(stdout);
            }
            fflush(stdout);
            fflush(stdout);
        }
        fflush(stdout);

        // ğŸ”§ [P2-chunké™åˆ¶] å¦‚æœè¾¾åˆ° chunk é™åˆ¶ï¼Œç»“æŸå½“å‰ decode
        // è¿™ä¸ Python åŒå·¥ server è¡Œä¸ºä¸€è‡´ï¼šæ¯æ¬¡ generate åªè¿”å›ä¸€ä¸ª chunk
        // å®¢æˆ·ç«¯éœ€è¦å†æ¬¡è°ƒç”¨ stream_decode è·å–ä¸‹ä¸€ä¸ª chunk
        if (chunk_limit_reached) {
            // ğŸ”§ [P0-ä¿®å¤] ä¸ Python å¯¹é½ï¼šè¾¾åˆ° chunk é™åˆ¶æ—¶ï¼Œå¼ºåˆ¶æ·»åŠ  <|chunk_eos|> token
            // Python: self.decoder.feed(self.decoder.embed_token(self.chunk_eos_token_id))
            if (ctx_omni->special_token_chunk_eos >= 0) {
                std::lock_guard<std::mutex> llama_lock(ctx_omni->llama_mtx);
                // Feed chunk_eos token to model (update KV cache)
                std::vector<llama_token>    chunk_eos_tokens = { ctx_omni->special_token_chunk_eos };
                eval_tokens(ctx_omni, ctx_omni->params, chunk_eos_tokens, ctx_omni->params->n_batch, &ctx_omni->n_past);
            }
            // è¿™æ · SSE æµä¼šç»“æŸï¼Œå®¢æˆ·ç«¯å¯ä»¥å†æ¬¡è°ƒç”¨ decode
            llm_finish           = true;
            // æ³¨æ„ï¼šä¸é‡ç½® current_chunk_tokensï¼Œä¸‹æ¬¡ decode ä¼šä» 0 å¼€å§‹
            current_chunk_tokens = 0;
        }

        // add </unit> token after each chunk
        if (ctx_omni->duplex_mode && ctx_omni->special_token_unit_end >= 0) {
            std::lock_guard<std::mutex> llama_lock(ctx_omni->llama_mtx);
            // Feed </unit> token to model (update KV cache)
            std::vector<llama_token>    unit_end_tokens = { ctx_omni->special_token_unit_end };
            eval_tokens(ctx_omni, ctx_omni->params, unit_end_tokens, ctx_omni->params->n_batch, &ctx_omni->n_past);
        }
        fflush(stdout);
        if (!response.empty()) {
            fflush(stdout);
        } else {
            fflush(stdout);
        }
        fflush(stdout);
        if (il == 0) {
        }
        // ğŸ”§ ä½¿ç”¨æ€»ç”Ÿæˆçš„ token æ•°é‡æ›´æ–° ilï¼ˆç”¨äºå’Œ max_tgt_len æ¯”è¾ƒï¼‰
        il += total_tokens_generated;

        // ğŸ”§ [ç»Ÿä¸€å¤„ç†] ç§»é™¤å“åº”ä¸­çš„æ‰€æœ‰ç‰¹æ®Šç»“æŸ token
        // æ³¨æ„: <|speak|> ä¸æ˜¯ç»“æŸ tokenï¼Œè€Œæ˜¯å¼€å§‹è¯´è¯çš„æ ‡è®°ï¼Œåº”è¯¥è¢«ç§»é™¤ä½†ä¸æˆªæ–­åé¢å†…å®¹
        {
            static const std::vector<std::string> end_token_strings = {
                "<|tts_eos|>",      "</s>", "<|listen|>", "<|turn_eos|>", "<|chunk_eos|>",
                "<|chunk_tts_eos|>"
                // æ³¨æ„ï¼šç§»é™¤äº† <|speak|>ï¼Œå®ƒä¸æ˜¯ç»“æŸ token
            };

            // å¯¹äºç»“æŸ tokenï¼Œæˆªæ–­å…¶åçš„å†…å®¹
            for (const auto & delimiter : end_token_strings) {
                size_t end = response.find(delimiter);
                if (end != std::string::npos) {
                    response = response.substr(0, end);
                }
            }

            // ğŸ”§ [ç‰¹æ®Šå¤„ç†] <|speak|> æ˜¯å¼€å§‹æ ‡è®°ï¼Œç›´æ¥ç§»é™¤å®ƒï¼ˆä¸æˆªæ–­åé¢å†…å®¹ï¼‰
            size_t speak_pos = response.find("<|speak|>");
            while (speak_pos != std::string::npos) {
                response.erase(speak_pos, std::string("<|speak|>").length());
                speak_pos = response.find("<|speak|>");
            }
        }
        fflush(stdout);
        if (ctx_omni->async) {
            fflush(stdout);

            // push text fragment for server stream
            if (!response.empty()) {
                fflush(stdout);
                std::lock_guard<std::mutex> tl(ctx_omni->text_mtx);
                ctx_omni->text_queue.push_back(response);
                ctx_omni->text_cv.notify_all();
                fflush(stdout);
            }
            fflush(stdout);

            if (ctx_omni->use_tts && ctx_omni->tts_thread_info && (!response.empty() || llm_finish)) {
                // LLM chunk timing
                auto llm_chunk_time = std::chrono::high_resolution_clock::now();
                auto llm_elapsed_ms = std::chrono::duration_cast<std::chrono::milliseconds>(
                                          llm_chunk_time - ctx_omni->stream_decode_start_time)
                                          .count();
                fflush(stdout);
                LLMOut * llm_out        = new LLMOut();
                llm_out->text           = response;
                llm_out->n_past         = ctx_omni->n_past;
                llm_out->llm_finish     = llm_finish;
                llm_out->debug_dir      = debug_dir;
                // å¡«å……token IDså’Œhidden statesç”¨äºTTSæ¡ä»¶ç”Ÿæˆ
                llm_out->token_ids      = chunk_token_ids;
                llm_out->hidden_states  = chunk_hidden_states;
                llm_out->n_embd         = llm_n_embd;
                // ğŸ”§ [ä¿®å¤åŒå·¥ç¼ºå­—é—®é¢˜] ä¼ é€’ is_end_of_turn çŠ¶æ€
                // æ­¤çŠ¶æ€éšæ•°æ®ä¸€èµ·ä¼ é€’ï¼Œç¡®ä¿ TTS å¤„ç†çš„æ˜¯ä¸å½“å‰ chunk å¯¹åº”çš„çŠ¶æ€
                llm_out->is_end_of_turn = local_is_end_of_turn;

                // ğŸ”§ [è¯Šæ–­æ—¥å¿—] æ‰“å° LLM æ¨é€ç»™ TTS çš„æ•°æ®
                {
                    std::string token_ids_str = "";
                    for (size_t i = 0; i < chunk_token_ids.size() && i < 20; i++) {
                        token_ids_str += std::to_string(chunk_token_ids[i]);
                        if (i < chunk_token_ids.size() - 1 && i < 19) {
                            token_ids_str += " ";
                        }
                    }
                    if (chunk_token_ids.size() > 20) {
                        token_ids_str += "...";
                    }

                    print_with_timestamp(
                        "LLM->TTS: text='%s', n_tokens=%zu, hidden_size=%zu, n_embd=%d, token_ids=[%s]\n",
                        response.c_str(), chunk_token_ids.size(), chunk_hidden_states.size(), llm_n_embd,
                        token_ids_str.c_str());
                }

                fflush(stdout);
                fflush(stdout);
                std::unique_lock<std::mutex> lock(ctx_omni->tts_thread_info->mtx);
                fflush(stdout);
                ctx_omni->tts_thread_info->cv.wait(lock, [&] {
                    return ctx_omni->tts_thread_info->queue.size() < ctx_omni->tts_thread_info->MAX_QUEUE_SIZE;
                });
                fflush(stdout);
                fflush(stdout);
                // ğŸ”§ [å…³é”®ä¿®å¤ - ä¸ Python å¯¹é½] åœ¨åŒå·¥æ¨¡å¼ä¸‹ï¼ŒLLM å§‹ç»ˆæ¨é€æ•°æ®åˆ° TTS é˜Ÿåˆ—
                // å› ä¸ºåŒå·¥æ¨¡å¼ä¸‹æ¯ä¸ª chunk éƒ½éœ€è¦ç‹¬ç«‹å¤„ç†ï¼Œä¸èƒ½å› ä¸ºä¸Šä¸€ä¸ª chunk å®Œæˆï¼ˆspeek_done=trueï¼‰å°±ä¸¢å¼ƒæ–°æ•°æ®
                // Python åŒå·¥æ¨¡å‹ï¼šæ¯æ¬¡ streaming_generate è°ƒç”¨éƒ½ä¼šç‹¬ç«‹å¤„ç† LLM è¾“å‡ºå¹¶ç”Ÿæˆ TTS
                // åªæœ‰åœ¨éåŒå·¥æ¨¡å¼ä¸‹ï¼Œæ‰æ£€æŸ¥ speek_done æ¥é¿å…é‡å¤å¤„ç†
                if (!ctx_omni->speek_done || ctx_omni->duplex_mode) {
                    fflush(stdout);
                    ctx_omni->tts_thread_info->queue.push(llm_out);
                    fflush(stdout);
                    //notify the tts thread
                    ctx_omni->tts_thread_info->cv.notify_all();
                    fflush(stdout);
                } else {
                    // speek_done is true, delete llm_out to prevent memory leak
                    fflush(stdout);
                    delete llm_out;
                    llm_out = nullptr;
                    fflush(stdout);
                }
                fflush(stdout);
            }
            fflush(stdout);
            if (llm_finish) {
                break;
            }
            fflush(stdout);
        } else {
            fflush(stdout);
        }
        fflush(stdout);
    }
    fflush(stdout);
    // ğŸ”§ [P1-SSEå“åº”] æ¨é€è½®æ¬¡ç»“æŸæ ‡è®°
    // mark text done
    {
        std::lock_guard<std::mutex> tl(ctx_omni->text_mtx);
        // æ¨é€ end_of_turn æ ‡è®°ï¼Œè®©å®¢æˆ·ç«¯çŸ¥é“å½“å‰è½®æ¬¡ç»“æŸ
        if (!ctx_omni->duplex_mode || !ctx_omni->ended_with_listen) {
            ctx_omni->text_queue.push_back("__END_OF_TURN__");
        }

        ctx_omni->text_done_flag = true;
        ctx_omni->text_cv.notify_all();
        ctx_omni->text_streaming = false;
    }
    // Safety checks before cleanup
    if (ctx_omni == nullptr) {
        LOG_ERR("stream_decode: ctx_omni is nullptr in cleanup!");
        return false;
    }
    if (ctx_omni->ctx_llama == nullptr) {
        LOG_ERR("stream_decode: ctx_omni->ctx_llama is nullptr in cleanup!");
        return false;
    }
    if (ctx_omni->params == nullptr) {
        LOG_ERR("stream_decode: ctx_omni->params is nullptr in cleanup!");
        return false;
    }

    // ==================== è½®æ¬¡è¾¹ç•Œè®°å½•ä¸æ»‘çª—æ£€æŸ¥ ====================
    // ğŸ”§ [å•å·¥å¤šè½®å¯¹è¯] åœ¨ decode ç»“æŸæ—¶ï¼š
    // 1. å…ˆæ£€æŸ¥å¹¶æ‰§è¡Œæ»‘çª—ï¼ˆåŸºäºä¹‹å‰çš„è½®æ¬¡è¾¹ç•Œï¼‰
    // 2. å†è®°å½•å½“å‰è½®æ¬¡çš„ç»“æŸè¾¹ç•Œï¼ˆä½œä¸ºä¸‹ä¸€è½®çš„å¼€å§‹ä½ç½®ï¼‰
    if (!ctx_omni->duplex_mode) {
        // ğŸ”§ [æ»‘çª—æ£€æŸ¥] æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œæ»‘çª—ï¼Œç¡®ä¿ä¸‹ä¸€è½®æœ‰è¶³å¤Ÿç©ºé—´
        // å½“ n_past > n_ctx - reserved_space æ—¶æ‰§è¡Œæ»‘çª—
        const int reserved_space = 1024;  // é¢„ç•™ç©ºé—´
        const int n_ctx          = ctx_omni->params->n_ctx;

        if (ctx_omni->n_past > n_ctx - reserved_space) {
            print_with_timestamp("âš ï¸ Decode ç»“æŸæ»‘çª—æ£€æŸ¥: n_past=%d > n_ctx-reserved=%dï¼Œéœ€è¦æ»‘çª—\n", ctx_omni->n_past,
                                 n_ctx - reserved_space);

            // è°ƒç”¨æ»‘çª—å‡½æ•°ï¼Œä¼ å…¥ reserved_space ä½œä¸ºéœ€è¦è…¾å‡ºçš„ç©ºé—´
            kv_cache_slide_window(ctx_omni, ctx_omni->params, reserved_space);
        } else {
            print_with_timestamp("ğŸ“ Decode ç»“æŸ: n_past=%d, å‰©ä½™ç©ºé—´=%d, æ— éœ€æ»‘çª—\n", ctx_omni->n_past,
                                 n_ctx - ctx_omni->n_past);
        }

        // ğŸ”§ [è½®æ¬¡è¾¹ç•Œ] è®°å½•å½“å‰è½®æ¬¡çš„ç»“æŸä½ç½®ï¼ˆä¹Ÿæ˜¯ä¸‹ä¸€è½®çš„å¼€å§‹ä½ç½®ï¼‰
        // ä¸€ä¸ªå®Œæ•´è½®æ¬¡ = ç”¨æˆ·æé—®ï¼ˆå¯èƒ½å¤šä¸ª audio prefillï¼‰+ æ¨¡å‹å›ç­”
        // è¿™æ ·æŒ‰è½®æ¬¡åˆ é™¤æ—¶ï¼Œå¯ä»¥åˆ é™¤å®Œæ•´çš„"é—®ç­”å¯¹"
        ctx_omni->round_start_positions.push_back(ctx_omni->n_past);
        print_with_timestamp("ğŸ“ è½®æ¬¡ %zu ç»“æŸï¼Œè®°å½•è¾¹ç•Œäº n_past=%d\n", ctx_omni->round_start_positions.size(),
                             ctx_omni->n_past);

        // ğŸ”§ [æ•´åˆ] ä¸ºä¸‹ä¸€è½®å‡†å¤‡ <|im_end|>\n<|im_start|>user\n
        // ç¬¬ä¸€è½®çš„ <|im_start|>user\n åœ¨ sys prompt æœ«å°¾
        // åç»­è½®æ¬¡éœ€è¦åœ¨ decode ç»“æŸæ—¶æ·»åŠ ï¼Œç»“æŸå½“å‰ assistant å›å¤å¹¶å¼€å§‹æ–°ä¸€è½® user è¾“å…¥
        eval_string(ctx_omni, ctx_omni->params, "<|im_end|>\n<|im_start|>user\n", ctx_omni->params->n_batch,
                    &ctx_omni->n_past, false);
        print_with_timestamp("ğŸ“ ä¸ºä¸‹ä¸€è½®å‡†å¤‡: eval <|im_end|>\\n<|im_start|>user\\n, n_past=%d\n", ctx_omni->n_past);
    }

    // ğŸ”§ [åŒå·¥æ¨¡å¼] åœ¨åŒå·¥æ¨¡å¼ä¸‹æ°¸è¿œä¸æ¸…ç† KV cache
    // Python åŒå·¥æ¨¡å‹çš„ llm_past_key_values ä¸€ç›´ç´¯ç§¯ï¼Œåªåœ¨ reset_session() æ—¶æ¸…ç©º
    // C++ å·²æœ‰æ»‘åŠ¨çª—å£æœºåˆ¶ (kv_cache_slide_window)ï¼Œä¼šåœ¨ä¸Šä¸‹æ–‡æ»¡æ—¶è‡ªåŠ¨æ»‘åŠ¨
    if (ctx_omni->duplex_mode) {
        // ä¸è°ƒç”¨ clean_kvcache å’Œ eval_prefixï¼Œä¿ç•™å½“å‰ä¸Šä¸‹æ–‡
        // æ»‘åŠ¨çª—å£æœºåˆ¶ä¼šåœ¨ prefill_with_emb/eval_tokens æ—¶è‡ªåŠ¨è§¦å‘
    } else {
        // éåŒå·¥æ¨¡å¼ï¼ˆå•å·¥ï¼‰ï¼Œæ¯è½®å¯¹è¯åæ¸…ç† KV cache
        // clean_kvcache(ctx_omni);
        // eval_prefix(ctx_omni, ctx_omni->params);
    }

    return true;
}

bool stop_speek(struct omni_context * ctx_omni) {
    ctx_omni->speek_done = true;
    if (ctx_omni->use_tts && ctx_omni->tts_thread_info) {
        std::unique_lock<std::mutex> lock(ctx_omni->tts_thread_info->mtx);
        while (!ctx_omni->tts_thread_info->queue.empty()) {
            LLMOut * llm_out = ctx_omni->tts_thread_info->queue.front();
            if (llm_out) {
                delete llm_out;
                llm_out = nullptr;
            }
            ctx_omni->tts_thread_info->queue.pop();
        }
        ctx_omni->tts_thread_info->cv.notify_all();
    }
    return true;
}

bool clean_kvcache(struct omni_context * ctx_omni) {
    if (ctx_omni->clean_kvcache) {
        print_with_timestamp("ğŸ§¹ clean_kvcache: æ¸…ç† KV cache, åˆ é™¤èŒƒå›´=[%d, %d), n_keep=%d\n", ctx_omni->n_keep,
                             ctx_omni->n_past, ctx_omni->n_keep);

        // è·å– memory å¯¹è±¡å¹¶æ¸…ç† KV cache
        llama_memory_t mem = llama_get_memory(ctx_omni->ctx_llama);
        if (mem) {
            // åˆ é™¤ [n_keep, n_past) èŒƒå›´çš„æ‰€æœ‰ tokenï¼Œä¿ç•™ system prompt ç­‰
            bool rm_ok = llama_memory_seq_rm(mem, 0, ctx_omni->n_keep, ctx_omni->n_past);
            if (!rm_ok) {
                print_with_timestamp("ğŸ§¹ clean_kvcache: llama_memory_seq_rm å¤±è´¥\n");
            } else {
                print_with_timestamp("ğŸ§¹ clean_kvcache: llama_memory_seq_rm æˆåŠŸ\n");
            }
        } else {
            print_with_timestamp("ğŸ§¹ clean_kvcache: æ— æ³•è·å– memory å¯¹è±¡\n");
        }

        // é‡ç½® n_past åˆ° n_keep
        int old_n_past   = ctx_omni->n_past;
        ctx_omni->n_past = ctx_omni->n_keep;
        print_with_timestamp("ğŸ§¹ clean_kvcache: n_past ä» %d é‡ç½®åˆ° %d\n", old_n_past, ctx_omni->n_past);

        // ğŸ”§ [#39 æ»‘åŠ¨çª—å£] é‡ç½®æ»‘çª—çŠ¶æ€
        sliding_window_reset(ctx_omni);
        // ä½†ä¿ç•™ system_preserve_lengthï¼Œå› ä¸º n_keep éƒ¨åˆ†ä»ç„¶ä¿ç•™
        ctx_omni->system_preserve_length = ctx_omni->n_keep;
        print_with_timestamp("ğŸ§¹ clean_kvcache: æ»‘çª—çŠ¶æ€å·²é‡ç½®, system_preserve_length=%d\n",
                             ctx_omni->system_preserve_length);
    } else {
        print_with_timestamp("ğŸ§¹ clean_kvcache: clean_kvcache=false, è·³è¿‡æ¸…ç†\n");
    }

    return true;
}
