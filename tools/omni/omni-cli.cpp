#include "omni-impl.h"
#include "omni.h"

#include "arg.h"
#include "log.h"
#include "sampling.h"
#include "llama.h"
#include "ggml.h"
#include "console.h"
#include "chat.h"

#include <iostream>
#include <chrono>
#include <vector>
#include <limits.h>
#include <cinttypes>
#include <algorithm>
#include <cstdio>
#include <cstdlib>
#include <cstring>
#include <vector>

#if defined (__unix__) || (defined (__APPLE__) && defined (__MACH__))
#include <signal.h>
#include <unistd.h>
#elif defined (_WIN32)
#define WIN32_LEAN_AND_MEAN
#ifndef NOMINMAX
#define NOMINMAX
#endif
#include <windows.h>
#include <signal.h>
#endif

// volatile, because of signal being an interrupt
static volatile bool g_is_generating = false;
static volatile bool g_is_interrupted = false;

/**
 * Please note that this is NOT a production-ready stuff.
 * It is a playground for trying multimodal support in llama.cpp.
 * For contributors: please keep this code simple and easy to understand.
 */

static void show_usage(const char * prog_name) {
    printf(
        "MiniCPM-o Omni CLI - Multimodal inference tool\n\n"
        "Usage: %s -m <llm_model_path> [options]\n\n"
        "Required:\n"
        "  -m <path>           Path to LLM GGUF model (e.g., MiniCPM-o-4_5-Q4_K_M.gguf)\n"
        "                      Other model paths will be auto-detected from directory structure:\n"
        "                        {dir}/vision/MiniCPM-o-4_5-vision-F16.gguf\n"
        "                        {dir}/audio/MiniCPM-o-4_5-audio-F16.gguf\n"
        "                        {dir}/tts/MiniCPM-o-4_5-tts-F16.gguf\n"
        "                        {dir}/tts/MiniCPM-o-4_5-projector-F16.gguf\n\n"
        "Options:\n"
        "  --vision <path>     Override vision model path\n"
        "  --audio <path>      Override audio model path\n"
        "  --tts <path>        Override TTS model path\n"
        "  --projector <path>  Override projector model path\n"
        "  --ref-audio <path>  Reference audio for voice cloning (default: tools/omni/assets/default_ref_audio/default_ref_audio.wav)\n"
        "  -c, --ctx-size <n>  Context size (default: 4096)\n"
        "  -ngl <n>            Number of GPU layers (default: 99)\n"
        "  --no-tts            Disable TTS output\n"
        "  --omni              Enable omni mode (audio + vision, media_type=2)\n"
        "  --vision-backend <mode>  Vision compute backend: 'metal' (default) or 'coreml' (ANE)\n"
        "  --vision-coreml <path>   Path to CoreML model (.mlmodelc), required when backend=coreml\n"
        "  --test <prefix> <n> Run test case with data prefix and count\n"
        "  -h, --help          Show this help message\n\n"
        "Example:\n"
        "  %s -m ./models/MiniCPM-o-4_5-gguf/MiniCPM-o-4_5-Q4_K_M.gguf\n"
        "  %s -m ./models/MiniCPM-o-4_5-gguf/MiniCPM-o-4_5-F16.gguf --no-tts\n"
        "  %s -m ./models/MiniCPM-o-4_5-gguf/MiniCPM-o-4_5-Q4_K_M.gguf --omni --test tools/omni/assets/test_case/omni_test_case/omni_test_case_ 9\n",
        prog_name, prog_name, prog_name, prog_name
    );
}

#if defined (__unix__) || (defined (__APPLE__) && defined (__MACH__)) || defined (_WIN32)
static void sigint_handler(int signo) {
    if (signo == SIGINT) {
        if (g_is_generating) {
            g_is_generating = false;
        } else {
            console::cleanup();
            if (g_is_interrupted) {
                _exit(1);
            }
            g_is_interrupted = true;
        }
    }
}
#endif

// ä» LLM æ¨¡å‹è·¯å¾„æ¨æ–­å…¶ä»–æ¨¡å‹è·¯å¾„
// ç›®å½•ç»“æ„:
// MiniCPM-o-4_5-gguf/
// â”œâ”€â”€ MiniCPM-o-4_5-{é‡åŒ–}.gguf          (LLM)
// â”œâ”€â”€ audio/
// â”‚   â””â”€â”€ MiniCPM-o-4_5-audio-F16.gguf
// â”œâ”€â”€ tts/
// â”‚   â”œâ”€â”€ MiniCPM-o-4_5-projector-F16.gguf
// â”‚   â””â”€â”€ MiniCPM-o-4_5-tts-F16.gguf
// â””â”€â”€ vision/
//     â””â”€â”€ MiniCPM-o-4_5-vision-F16.gguf
struct OmniModelPaths {
    std::string llm;         // LLM æ¨¡å‹è·¯å¾„
    std::string vision;      // è§†è§‰æ¨¡å‹è·¯å¾„
    std::string audio;       // éŸ³é¢‘æ¨¡å‹è·¯å¾„
    std::string tts;         // TTS æ¨¡å‹è·¯å¾„
    std::string projector;   // Projector æ¨¡å‹è·¯å¾„
    std::string base_dir;    // æ¨¡å‹æ ¹ç›®å½•
};

static std::string get_parent_dir(const std::string & path) {
    size_t last_slash = path.find_last_of("/\\");
    if (last_slash != std::string::npos) {
        return path.substr(0, last_slash);
    }
    return ".";
}

static bool file_exists(const std::string & path) {
    FILE * f = fopen(path.c_str(), "rb");
    if (f) {
        fclose(f);
        return true;
    }
    return false;
}

static OmniModelPaths resolve_model_paths(const std::string & llm_path) {
    OmniModelPaths paths;
    paths.llm = llm_path;
    paths.base_dir = get_parent_dir(llm_path);
    
    // è‡ªåŠ¨æ¨æ–­å…¶ä»–æ¨¡å‹è·¯å¾„
    paths.vision = paths.base_dir + "/vision/MiniCPM-o-4_5-vision-F16.gguf";
    paths.audio = paths.base_dir + "/audio/MiniCPM-o-4_5-audio-F16.gguf";
    paths.tts = paths.base_dir + "/tts/MiniCPM-o-4_5-tts-F16.gguf";
    paths.projector = paths.base_dir + "/tts/MiniCPM-o-4_5-projector-F16.gguf";
    
    return paths;
}

static void print_model_paths(const OmniModelPaths & paths) {
    printf("=== Model Paths ===\n");
    printf("  Base dir:   %s\n", paths.base_dir.c_str());
    printf("  LLM:        %s %s\n", paths.llm.c_str(), file_exists(paths.llm) ? "[OK]" : "[NOT FOUND]");
    printf("  Vision:     %s %s\n", paths.vision.c_str(), file_exists(paths.vision) ? "[OK]" : "[NOT FOUND]");
    printf("  Audio:      %s %s\n", paths.audio.c_str(), file_exists(paths.audio) ? "[OK]" : "[NOT FOUND]");
    printf("  TTS:        %s %s\n", paths.tts.c_str(), file_exists(paths.tts) ? "[OK]" : "[NOT FOUND]");
    printf("  Projector:  %s %s\n", paths.projector.c_str(), file_exists(paths.projector) ? "[OK]" : "[NOT FOUND]");
    printf("===================\n");
}

void test_case(struct omni_context *ctx_omni, common_params& params, std::string data_path_prefix, int cnt){
    // ğŸ”§ å•å·¥æ¨¡å¼ï¼šå…ˆ prefill æ‰€æœ‰è¾“å…¥ï¼Œç„¶å decode ä¸€æ¬¡ç”Ÿæˆå®Œæ•´å›å¤
    // ä½¿ç”¨åŒæ­¥æ¨¡å¼ prefillï¼Œé¿å… async æ¨¡å¼ä¸‹çš„ç«æ€æ¡ä»¶
    ctx_omni->system_prompt_initialized = false;
    bool orig_async = ctx_omni->async;
    ctx_omni->async = false;  // ä½¿ç”¨åŒæ­¥æ¨¡å¼ prefillï¼Œç¡®ä¿æ‰€æœ‰æ•°æ®è¢«å¤„ç†
    
    for (int il = 0; il < cnt; ++il) {
        char idx_str[16];
        snprintf(idx_str, sizeof(idx_str), "%04d", il);  // æ ¼å¼åŒ–ä¸º4ä½æ•°å­—ï¼Œå¦‚ 0000, 0001
        std::string aud_fname = data_path_prefix + idx_str + ".wav";

        // omni æ¨¡å¼ï¼šè‡ªåŠ¨æ£€æµ‹åŒå .jpg å›¾ç‰‡
        std::string img_fname;
        std::string img_candidate = data_path_prefix + idx_str + ".jpg";
        if (file_exists(img_candidate)) {
            img_fname = img_candidate;
        }

        auto t0 = std::chrono::high_resolution_clock::now();
        // index ä» 0 å¼€å§‹ï¼Œç¬¬ä¸€æ¬¡ prefill (index=0) åˆå§‹åŒ–ç³»ç»Ÿ prompt
        // åç»­ prefill åœ¨åŒæ­¥æ¨¡å¼ä¸‹ç›´æ¥æ·»åŠ åˆ° KV cache
        stream_prefill(ctx_omni, aud_fname, img_fname, il);
        auto t1 = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double> elapsed_seconds = t1 - t0;
        double dt = elapsed_seconds.count();
        if (img_fname.empty()) {
            std::cout << "prefill " << il << " (audio) : " << dt << " s" << std::endl;
        } else {
            std::cout << "prefill " << il << " (audio+vision) : " << dt << " s" << std::endl;
        }
    }
    
    // æ‰€æœ‰æ•°æ®åŒæ­¥ prefill å®Œæˆåï¼Œæ¢å¤ async æ¨¡å¼å¹¶è°ƒç”¨ decode
    // æ³¨æ„ï¼šåŒæ­¥ prefill ä¸ä¼šå¯åŠ¨çº¿ç¨‹ï¼Œéœ€è¦ç”¨ async=true çš„æ–¹å¼è°ƒç”¨ decode
    // stream_decode å†…éƒ¨ä¼šæ£€æŸ¥ async å¹¶å¯åŠ¨ TTS/T2W çº¿ç¨‹
    ctx_omni->async = orig_async;
    stream_decode(ctx_omni, "./");
}

int main(int argc, char ** argv) {
    ggml_time_init();

    // å‘½ä»¤è¡Œå‚æ•°
    std::string llm_path;
    std::string vision_path_override;
    std::string audio_path_override;
    std::string tts_path_override;
    std::string projector_path_override;
    std::string vision_backend = "metal";  // vision backend: "metal" (default) or "coreml"
    std::string vision_coreml_model_path;  // CoreML model path (required when vision_backend=coreml)
    std::string ref_audio_path = "tools/omni/assets/default_ref_audio/default_ref_audio.wav";
    int n_ctx = 4096;
    int n_gpu_layers = 99;  // GPU å±‚æ•°ï¼Œé»˜è®¤ 99
    int media_type = 1;     // 1=audio only, 2=omni (audio+vision)
    bool use_tts = true;
    bool run_test = false;
    std::string test_audio_prefix;
    int test_count = 0;
    
    // è§£æå‘½ä»¤è¡Œå‚æ•°
    for (int i = 1; i < argc; i++) {
        std::string arg = argv[i];
        
        if (arg == "-h" || arg == "--help") {
            show_usage(argv[0]);
            return 0;
        }
        else if (arg == "-m" && i + 1 < argc) {
            llm_path = argv[++i];
        }
        else if (arg == "--vision" && i + 1 < argc) {
            vision_path_override = argv[++i];
        }
        else if (arg == "--audio" && i + 1 < argc) {
            audio_path_override = argv[++i];
        }
        else if (arg == "--tts" && i + 1 < argc) {
            tts_path_override = argv[++i];
        }
        else if (arg == "--projector" && i + 1 < argc) {
            projector_path_override = argv[++i];
        }
        else if (arg == "--ref-audio" && i + 1 < argc) {
            ref_audio_path = argv[++i];
        }
        else if ((arg == "-c" || arg == "--ctx-size") && i + 1 < argc) {
            n_ctx = std::atoi(argv[++i]);
        }
        else if (arg == "-ngl" && i + 1 < argc) {
            n_gpu_layers = std::atoi(argv[++i]);
        }
        else if (arg == "--no-tts") {
            use_tts = false;
        }
        else if (arg == "--omni") {
            media_type = 2;
        }
        else if (arg == "--vision-backend" && i + 1 < argc) {
            vision_backend = argv[++i];
            if (vision_backend != "metal" && vision_backend != "coreml") {
                fprintf(stderr, "Error: --vision-backend must be 'metal' or 'coreml', got '%s'\n", vision_backend.c_str());
                return 1;
            }
        }
        else if (arg == "--vision-coreml" && i + 1 < argc) {
            vision_coreml_model_path = argv[++i];
        }
        else if (arg == "--test" && i + 2 < argc) {
            run_test = true;
            test_audio_prefix = argv[++i];
            test_count = std::atoi(argv[++i]);
        }
        else {
            fprintf(stderr, "Unknown argument: %s\n", arg.c_str());
            show_usage(argv[0]);
            return 1;
        }
    }
    
    // æ£€æŸ¥å¿…éœ€å‚æ•°
    if (llm_path.empty()) {
        fprintf(stderr, "Error: -m <llm_model_path> is required\n\n");
        show_usage(argv[0]);
        return 1;
    }
    
    // è§£ææ¨¡å‹è·¯å¾„
    OmniModelPaths paths = resolve_model_paths(llm_path);
    
    // åº”ç”¨è¦†ç›–è·¯å¾„
    if (!vision_path_override.empty()) paths.vision = vision_path_override;
    if (!audio_path_override.empty()) paths.audio = audio_path_override;
    if (!tts_path_override.empty()) paths.tts = tts_path_override;
    if (!projector_path_override.empty()) paths.projector = projector_path_override;
    
    // æ‰“å°æ¨¡å‹è·¯å¾„
    print_model_paths(paths);
    
    // æ£€æŸ¥å¿…éœ€æ–‡ä»¶
    if (!file_exists(paths.llm)) {
        fprintf(stderr, "Error: LLM model not found: %s\n", paths.llm.c_str());
        return 1;
    }
    if (!file_exists(paths.audio)) {
        fprintf(stderr, "Error: Audio model not found: %s\n", paths.audio.c_str());
        return 1;
    }
    if (use_tts && !file_exists(paths.tts)) {
        fprintf(stderr, "Warning: TTS model not found: %s, disabling TTS\n", paths.tts.c_str());
        use_tts = false;
    }
    
    // è®¾ç½®å‚æ•°
    common_params params;
    params.model.path = paths.llm;
    params.vpm_model = paths.vision;
    params.apm_model = paths.audio;
    params.tts_model = paths.tts;
    // åªæœ‰æ˜¾å¼é€‰æ‹© coreml åç«¯æ—¶æ‰è®¾ç½® CoreML æ¨¡å‹è·¯å¾„
    if (vision_backend == "coreml") {
        if (vision_coreml_model_path.empty()) {
            fprintf(stderr, "Error: --vision-backend coreml requires --vision-coreml <path>\n");
            return 1;
        }
        params.vision_coreml_model_path = vision_coreml_model_path;
    }
    params.n_ctx = n_ctx;
    params.n_gpu_layers = n_gpu_layers;
    
    // Projector è·¯å¾„éœ€è¦é€šè¿‡ tts_bin_dir ä¼ é€’
    // omni.cpp ä¸­ projector è·¯å¾„è®¡ç®—: gguf_root_dir + "/projector.gguf"
    // å…¶ä¸­ gguf_root_dir = tts_bin_dir çš„çˆ¶ç›®å½•
    // ä½†æˆ‘ä»¬çš„ç»“æ„æ˜¯ projector åœ¨ tts/ ç›®å½•ä¸‹
    // æ‰€ä»¥éœ€è¦ä¿®æ”¹ omni.cpp æˆ–è€…åˆ›å»ºç¬¦å·é“¾æ¥
    // è¿™é‡Œæš‚æ—¶ä½¿ç”¨ tts ç›®å½•ä½œä¸º tts_bin_dir
    std::string tts_bin_dir = get_parent_dir(paths.tts);
    
    common_init();
    
    printf("=== Initializing Omni Context ===\n");
    printf("  Media type: %d (%s)\n", media_type, media_type == 2 ? "omni: audio+vision" : "audio only");
    printf("  TTS enabled: %s\n", use_tts ? "yes" : "no");
    printf("  Context size: %d\n", n_ctx);
    printf("  GPU layers: %d\n", n_gpu_layers);
    printf("  Vision backend: %s\n", vision_backend.c_str());
    if (vision_backend == "coreml") {
        printf("  Vision CoreML: %s\n", vision_coreml_model_path.c_str());
    }
    printf("  TTS bin dir: %s\n", tts_bin_dir.c_str());
    printf("  Ref audio: %s\n", ref_audio_path.c_str());
    
    // ğŸ”§ Token2Wav ä½¿ç”¨ GPUï¼ˆMetalï¼‰ï¼Œå·²ç”¨ ggml_add+ggml_repeat æ›¿ä»£ä¸æ”¯æŒçš„ ggml_add1
    auto ctx_omni = omni_init(&params, media_type, use_tts, tts_bin_dir, -1, "gpu:0");
    if (ctx_omni == nullptr) {
        fprintf(stderr, "Error: Failed to initialize omni context\n");
        return 1;
    }
    ctx_omni->async = true;
    ctx_omni->ref_audio_path = ref_audio_path;  // è®¾ç½®å‚è€ƒéŸ³é¢‘è·¯å¾„

    if (run_test) {
        printf("=== Running test case ===\n");
        printf("  Audio prefix: %s\n", test_audio_prefix.c_str());
        printf("  Count: %d\n", test_count);
        test_case(ctx_omni, params, test_audio_prefix, test_count);
    } else {
        // é»˜è®¤æµ‹è¯•ç”¨ä¾‹
        test_case(ctx_omni, params, std::string("tools/omni/assets/test_case/audio_test_case/audio_test_case_"), 2);
    }

    // ç­‰å¾… T2W å®Œæˆæ‰€æœ‰éŸ³é¢‘ç”Ÿæˆåå†åœæ­¢çº¿ç¨‹
    if(ctx_omni->async && ctx_omni->use_tts) {
        std::string done_flag = std::string(ctx_omni->base_output_dir) + "/round_000/tts_wav/generation_done.flag";
        fprintf(stderr, "Waiting for audio generation to complete...\n");
        for (int i = 0; i < 1200; ++i) {  // æœ€å¤šç­‰ 120 ç§’
            FILE * f = fopen(done_flag.c_str(), "r");
            if (f) { fclose(f); fprintf(stderr, "Audio generation completed.\n"); break; }
            usleep(100000);  // 100ms
        }
    }

    if(ctx_omni->async) {
        omni_stop_threads(ctx_omni);
        if(ctx_omni->llm_thread.joinable()) { ctx_omni->llm_thread.join(); printf("llm thread end\n"); }
        if(ctx_omni->use_tts && ctx_omni->tts_thread.joinable()) { ctx_omni->tts_thread.join(); printf("tts thread end\n"); }
        if(ctx_omni->use_tts && ctx_omni->t2w_thread.joinable()) { ctx_omni->t2w_thread.join(); printf("t2w thread end\n"); }
    }

    llama_perf_context_print(ctx_omni->ctx_llama);

    omni_free(ctx_omni);
    return 0;
}
